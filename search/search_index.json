{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"FreeTensor A language and compiler for irregular tensor programs. GitHub User Guide API Reference Publication License Features by Example Write a simple vector addition with loops that compiles to native code: import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) If you are not willing to compile the program once for each different n , you can set n as another function argument (but you may lose some performance). In FreeTensor, all variables are tensors, where scalars are 0-D tensors. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) If building with CUDA, you can also run the program on a GPU. This time, a \" schedule \" (an explicit program transformation) is needed, and memory types of variables should be properly set. import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.Device(ft.GPU(), 0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! nid: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Some common tensor operations, including tensor addition (broadcasting is supported), are pre-defined functions in FreeTensor. They are defiend in freetensor.libop , and they can also be invoked using operator overloading. These functions are pure Python functions, which will be inlined into your code, and will enjoy a joint optimization. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = a + b # Or y = ft.add(a, b) return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) FreeTensor also supports reverse-mode Automatic Differentiation: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy())","title":"Home"},{"location":"#freetensor","text":"A language and compiler for irregular tensor programs. GitHub User Guide API Reference Publication License","title":"FreeTensor"},{"location":"#features-by-example","text":"Write a simple vector addition with loops that compiles to native code: import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) If you are not willing to compile the program once for each different n , you can set n as another function argument (but you may lose some performance). In FreeTensor, all variables are tensors, where scalars are 0-D tensors. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) If building with CUDA, you can also run the program on a GPU. This time, a \" schedule \" (an explicit program transformation) is needed, and memory types of variables should be properly set. import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.Device(ft.GPU(), 0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! nid: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Some common tensor operations, including tensor addition (broadcasting is supported), are pre-defined functions in FreeTensor. They are defiend in freetensor.libop , and they can also be invoked using operator overloading. These functions are pure Python functions, which will be inlined into your code, and will enjoy a joint optimization. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = a + b # Or y = ft.add(a, b) return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) FreeTensor also supports reverse-mode Automatic Differentiation: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy())","title":"Features by Example"},{"location":"api/","text":"Python API core special auto_schedule AutoSchedule ( AutoSchedule ) Source code in freetensor/core/auto_schedule.py class AutoSchedule ( ffi . AutoSchedule ): def __init__ ( self , schedule , target , device , * , population = 64 , explore_ratio = 0.1 , tag = \"\" , min_block_size = 0 , rule_set = None , verbose = 0 ): ''' Automatic scheduler Parameters ---------- schedule : Schedule A Schedule object to apply schedules onto target : Target The type of devices to compile to population : int How many programs to test in each iteration explore_ratio : float Portion of random programs in the population. Higher ratio focuses on exploration, while lower ratio focuses on exploitation rule_set : Optional[set] Explicitly control over what rules to use. None for defualt rules verbose : int Verbosity level. 0 = print nothing, 1 = print tuning progress, 2 = print extra info mation of each rule ''' self . population = population self . n_explore = int ( population * explore_ratio ) self . n_exploit = population - self . n_explore self . model = None self . xgb_params = {} self . save_file_name = tag + \"_xgb.model\" if os . path . isfile ( self . save_file_name ): self . model = xgb . Booster () self . model . load_model ( self . save_file_name ) self . verbose = verbose def predict_func ( features ): return self . predict ( features ) def update_func ( features , times ): return self . update ( features , times ) super ( AutoSchedule , self ) . __init__ ( schedule , target , device , predict_func , update_func , tag , min_block_size , rule_set , verbose ) def set_params ( self , * args , ** kws ): super ( AutoSchedule , self ) . set_params ( args , kws ) def run ( self , iteration ): for i in range ( iteration ): if self . verbose >= 1 : print ( \"Iteration\" , i ) self . search_one_round ( self . population , self . n_exploit , self . n_explore ) return self . get_best_schedule () def predict ( self , features ): if not self . model : return [ 1 ] * len ( features ) return self . model . predict ( xgb . DMatrix ( np . array ( features ), missing =- 1 )) def update ( self , features , times ): dtrain = xgb . DMatrix ( np . array ( features ), np . array ( times ), missing =- 1 ) self . model = xgb . train ( self . xgb_params , dtrain , xgb_model = self . model ) self . model . save_model ( self . save_file_name ) __init__ ( self , schedule , target , device , * , population = 64 , explore_ratio = 0.1 , tag = '' , min_block_size = 0 , rule_set = None , verbose = 0 ) special Automatic scheduler Parameters: schedule ( Schedule ) \u2013 A Schedule object to apply schedules onto target ( Target ) \u2013 The type of devices to compile to population ( int ) \u2013 How many programs to test in each iteration explore_ratio ( float ) \u2013 Portion of random programs in the population. Higher ratio focuses on exploration, while lower ratio focuses on exploitation rule_set ( Optional[set] ) \u2013 Explicitly control over what rules to use. None for defualt rules verbose ( int ) \u2013 Verbosity level. 0 = print nothing, 1 = print tuning progress, 2 = print extra info mation of each rule Source code in freetensor/core/auto_schedule.py def __init__ ( self , schedule , target , device , * , population = 64 , explore_ratio = 0.1 , tag = \"\" , min_block_size = 0 , rule_set = None , verbose = 0 ): ''' Automatic scheduler Parameters ---------- schedule : Schedule A Schedule object to apply schedules onto target : Target The type of devices to compile to population : int How many programs to test in each iteration explore_ratio : float Portion of random programs in the population. Higher ratio focuses on exploration, while lower ratio focuses on exploitation rule_set : Optional[set] Explicitly control over what rules to use. None for defualt rules verbose : int Verbosity level. 0 = print nothing, 1 = print tuning progress, 2 = print extra info mation of each rule ''' self . population = population self . n_explore = int ( population * explore_ratio ) self . n_exploit = population - self . n_explore self . model = None self . xgb_params = {} self . save_file_name = tag + \"_xgb.model\" if os . path . isfile ( self . save_file_name ): self . model = xgb . Booster () self . model . load_model ( self . save_file_name ) self . verbose = verbose def predict_func ( features ): return self . predict ( features ) def update_func ( features , times ): return self . update ( features , times ) super ( AutoSchedule , self ) . __init__ ( schedule , target , device , predict_func , update_func , tag , min_block_size , rule_set , verbose ) set_params ( self , * args , ** kws ) set_params(self: freetensor_ffi.AutoSchedule, args: List[freetensor_ffi.Array], kws: Dict[str, freetensor_ffi.Array] = {}) -> None Source code in freetensor/core/auto_schedule.py def set_params ( self , * args , ** kws ): super ( AutoSchedule , self ) . set_params ( args , kws ) autograd ArgRetDict Look an object using either a function argument or return value's name or its position Source code in freetensor/core/autograd.py class ArgRetDict : ''' Look an object using either a function argument or return value's name or its position ''' def __init__ ( self , func , d ): self . func = func self . d = d def __getitem__ ( self , key ): if type ( key ) is Return : key = key . get_name ( self . func ) return self . d [ key ] Return Alias of a return value of a function Return(n) represents the n-th return value (counted from 0) Return() can be used if there is only one return value Source code in freetensor/core/autograd.py class Return : ''' Alias of a return value of a function `Return(n)` represents the n-th return value (counted from 0) `Return()` can be used if there is only one return value ''' def __init__ ( self , n : Optional [ int ] = None ): self . n = n def get_name ( self , func ): assert len ( func . returns ) > 0 , f \" { func . name } has no return value\" if self . n is not None : return func . returns [ self . n ] . name else : assert len ( func . returns ) == 1 , f \" { func . name } has more than one return value, and you need to specify the number of a return value\" return func . returns [ 0 ] . name grad ( func , requires , provides , tapes =< GradTapeMode . NoReuseOnly : 2 > , verbose = None ) Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad is an out-of-place version. The resulting gradient are returned from the backward function. Parameters: func ( Func ) \u2013 The original function requires ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of input variables that need gradients provides ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of output variables whose gradients are known. A return value of a function can be specified with a Return object tapes ( Union[Sequence, freetensor_ffi.GradTapeMode] ) \u2013 Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns: tuple \u2013 ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in freetensor/core/autograd.py def grad ( func : ffi . Func , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad` is an out-of-place version. The resulting gradient are returned from the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad , func , requires , provides , tapes , verbose = verbose ) grad_ ( func , requires , provides , tapes =< GradTapeMode . NoReuseOnly : 2 > , verbose = None ) Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad_ is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters: func ( Func ) \u2013 The original function requires ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of input variables that need gradients provides ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of output variables whose gradients are known. A return value of a function can be specified with a Return object tapes ( Union[Sequence, freetensor_ffi.GradTapeMode] ) \u2013 Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns: tuple \u2013 ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in freetensor/core/autograd.py def grad_ ( func : ffi . Func , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad_` is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad_ , func , requires , provides , tapes , verbose = verbose ) grad_body ( stmt , requires , provides , tapes =< GradTapeMode . NoReuseOnly : 2 > ) grad or grad_ on a function body (for internal tests only) Source code in freetensor/core/autograd.py def grad_body ( stmt : ffi . Stmt , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly ): ''' `grad` or `grad_` on a function body (for internal tests only) ''' req = set ( requires ) prov = set ( provides ) if type ( tapes ) is not GradTapeMode : tapes = set ( tapes ) return ffi . grad_body ( stmt , req , prov , tapes ) codegen codegen ( ast = None , target = None , verbose = None ) Generate native code Parameters: ast ( AST ) \u2013 The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator target ( Optional[freetensor_ffi.Target] ) \u2013 The target architecture. If omitted, use the default one in config Source code in freetensor/core/codegen.py def codegen ( ast = None , target : Optional [ ffi . Target ] = None , verbose : Optional [ bool ] = None ) -> NativeCode : ''' Generate native code Parameters ---------- ast : AST The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator target : Target (Optional) The target architecture. If omitted, use the default one in config ''' if ast is not None : if target is None : target = config . default_target () if target . type () == ffi . TargetType . CPU : raw_code = ffi . code_gen_cpu ( ast ) elif target . type () == ffi . TargetType . GPU : raw_code = ffi . code_gen_cuda ( ast ) else : assert False , \"Unrecognized target %s \" % target if verbose : print ( debug . with_line_no ( raw_code ), file = sys . stderr ) return NativeCode ( ast , raw_code , target ) else : f = codegen if target is not None : f = functools . partial ( f , target = target ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f config Global configurations backend_compiler_cxx ( * args , ** kvs ) backend_compiler_cxx() -> str Backend compiler used to compile generated C++ code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) backend_compiler_nvcc ( * args , ** kvs ) backend_compiler_nvcc() -> str Backend compiler used to compile generated CUDA code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) debug_binary ( * args , ** kvs ) debug_binary() -> bool Check if compiling binary in debug mode Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) default_device ( * args , ** kvs ) default_device() -> freetensor_ffi.Device Check current default device Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) default_target ( * args , ** kvs ) default_target() -> freetensor_ffi.Target Check current default target Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) pretty_print ( * args , ** kvs ) pretty_print() -> bool Check if colored printing enabled Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) print_all_id ( * args , ** kvs ) pretty_print() -> bool Check if colored printing enabled Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_backend_compiler_cxx ( * args , ** kvs ) set_backend_compiler_cxx(path: str) -> None Set backend compiler used to compile generated C++ code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_backend_compiler_nvcc ( * args , ** kvs ) set_backend_compiler_nvcc(path: str) -> None Set backend compiler used to compile generated CUDA code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_debug_binary ( * args , ** kvs ) set_debug_binary(flag: bool = True) -> None Compile with -g at backend. Do not delete the binary file after loaded Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_default_device ( * args , ** kvs ) set_default_device(device: freetensor_ffi.Device) -> None Set default device (internal implementation of with Device ) Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_default_target ( * args , ** kvs ) set_default_target(target: freetensor_ffi.Target) -> None Set default target (internal implementation of with Target ) Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_pretty_print ( * args , ** kvs ) set_pretty_print(flag: bool = True) -> None Set colored printing Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_print_all_id ( * args , ** kvs ) set_pretty_print(flag: bool = True) -> None Set colored printing Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) set_werror ( * args , ** kvs ) set_werror(flag: bool = True) -> None Error on warning Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) werror ( * args , ** kvs ) werror() -> bool Check if error-on-warning enabled Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) with_cuda ( * args , ** kvs ) with_cuda() -> bool Check if FreeTensor is built with CUDA Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) with_mkl ( * args , ** kvs ) with_mkl() -> str Check if FreeTensor is built with MKL Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) with_pytorch ( * args , ** kvs ) with_pytorch() -> bool Check if FreeTensor is built with PyTorch interface Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs ) context Facility to pick statements to build an AST Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module. pop_ast ( verbose = False ) Get AST and reset context Internally used by transformer and tests Source code in freetensor/core/context.py def pop_ast ( verbose : bool = False ): \"\"\" Get AST and reset context Internally used by `transformer` and tests \"\"\" ret = ctx_stack . pop () . make_stmt () ctx_stack . reset () if verbose : print ( \"The popped AST is:\" , file = sys . stderr ) print ( ret , file = sys . stderr ) print ( file = sys . stderr ) return ret driver Device ( Device ) A computing device of a Target E.g. suppose GPU() is a Target (architecture), then Device(GPU(), 0) means the 0-th GPU (device) A Device can be used as a \"with\" scope, then all the Array s and Driver s will use it by default. In this style, it also sets the default Target. E.g: with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default Source code in freetensor/core/driver.py class Device ( ffi . Device ): ''' A computing device of a Target E.g. suppose GPU() is a Target (architecture), then Device(GPU(), 0) means the 0-th GPU (device) A Device can be used as a \"with\" scope, then all the `Array`s and `Driver`s will use it by default. In this style, it also sets the default Target. E.g: ``` with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default ``` ''' def __init__ ( self , target : Target , num : int = 0 ): super ( Device , self ) . __init__ ( target , num ) def __enter__ ( self ): self . old_target = config . default_target () self . old_device = config . default_device () config . set_default_target ( self . target ()) config . set_default_device ( self ) return self def __exit__ ( self , exc_type , exc_value , traceback ): config . set_default_target ( self . old_target ) config . set_default_device ( self . old_device ) Driver ( Driver ) Source code in freetensor/core/driver.py class Driver ( ffi . Driver ): def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , src , device , host_device , verbose ) self . func = func def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ]) for key in kws : kws [ key ] = array ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws ) def collect_returns ( self ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 : return None elif len ( values ) == 1 : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values ) def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns () __call__ ( self , * args , ** kws ) special Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call self.set_args first, then self.time , and finally self.collect_returns Source code in freetensor/core/driver.py def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns () __init__ ( self , func , src , device = None , host_device = None , verbose = None ) special Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using build_binary Parameters: func ( Func ) \u2013 AST of the function, where the function signature is needed to determine the parameters and return values src ( str ) \u2013 Native code generated from codegen device ( Optional[freetensor.core.driver.Device] ) \u2013 The device to run the program. If omitted, use the default device in config verbose ( Optional[bool] ) \u2013 True to print extra infomation Source code in freetensor/core/driver.py def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , src , device , host_device , verbose ) self . func = func collect_returns ( self ) Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack Source code in freetensor/core/driver.py def collect_returns ( self ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 : return None elif len ( values ) == 1 : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values ) set_args ( self , * args , ** kws ) Set argument for an invocation Source code in freetensor/core/driver.py def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ]) for key in kws : kws [ key ] = array ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws ) ReturnValuesPack Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: x, y, z = pack , or in a named manner: pack['x'] Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values Source code in freetensor/core/driver.py class ReturnValuesPack : ''' Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: `x, y, z = pack`, or in a named manner: `pack['x']` Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values ''' def __init__ ( self , keys : Sequence [ str ], values : Sequence [ Array ]): keys = list ( keys ) values = list ( values ) assert len ( keys ) == len ( values ) self . keys = keys self . values = values def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key ) __getitem__ ( self , key ) special Get a return value with a name. Tuple is supported for multiple values Source code in freetensor/core/driver.py def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key ) __iter__ ( self ) special Get all return values in the order declared in Func Source code in freetensor/core/driver.py def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values Target ( Target ) A target architecture A Target can be used as a \"with\" scope, then all the lower s and codegen s will use it by default. In this style, it also sets the default Device as the 0-th device of the given Target. E.g: with Target(...): ast = lower(ast) # Use the Target above by default a = Array(...) # Use the 0-th device of the Target above by default Source code in freetensor/core/driver.py class Target ( ffi . Target ): ''' A target architecture A Target can be used as a \"with\" scope, then all the `lower`s and `codegen`s will use it by default. In this style, it also sets the default Device as the 0-th device of the given Target. E.g: ``` with Target(...): ast = lower(ast) # Use the Target above by default a = Array(...) # Use the 0-th device of the Target above by default ``` ''' def __init__ ( self , use_native_arch : bool = True ): super ( Target , self ) . __init__ ( use_native_arch ) def __enter__ ( self ): self . old_target = config . default_target () self . old_device = config . default_device () config . set_default_target ( self ) config . set_default_device ( Device ( self , 0 )) return self def __exit__ ( self , exc_type , exc_value , traceback ): config . set_default_target ( self . old_target ) config . set_default_device ( self . old_device ) array ( data ) Factory function for Array It converts more data format to Array Source code in freetensor/core/driver.py def array ( data ): ''' Factory function for Array It converts more data format to Array ''' if type ( data ) is Array : return data # For NumPy, Although Pybind11's `array_t` type provides a flag `forcecast` to # cast from a strided array to a contiguous one. But it always casts to a specific # type, e.g. float64. I have no idea how to support multiple types. Therfore, # we have to call NumPy's `.copy(order='C')` to make a new NumPy array. This # function can only be called from Python side (not from PyBind11's `py::array` # type). if type ( data ) is np . ndarray : if not data . flags [ 'C_CONTIGUOUS' ]: data = data . copy ( order = 'C' ) return Array ( data ) if data . __class__ . __module__ == 'torch' : import torch if type ( data ) is torch . Tensor : if not config . with_pytorch (): raise ffi . DriverError ( \"FreeTensor should be built with WITH_PYTORCH to accept a PyTorch tensor\" ) if not data . is_contiguous (): data = data . contiguous () return Array ( data ) raise ffi . DriverError ( f \"Unsupported data type { type ( data ) } for Array\" ) build_binary ( code = None , device = None , host_device = None , verbose = None ) Compile a program using a backend compiler and load it into memory Parameters: code ( Optional[freetensor.core.codegen.NativeCode] ) \u2013 Native code generated by codegen . If not specified, a partial function is returned, which can be used as a decorator device ( Optional[freetensor.core.driver.Device] ) \u2013 The device to run the program. If omitted, use the default device in config Source code in freetensor/core/driver.py def build_binary ( code : Optional [ NativeCode ] = None , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory Parameters ---------- code : NativeCode Native code generated by `codegen`. If not specified, a partial function is returned, which can be used as a decorator device : Device (Optional) The device to run the program. If omitted, use the default device in config ''' if code is not None : if device is None : device = config . default_device () if device . target () != code . target : raise ffi . DriverError ( f \"Codegen target ( { code . target } ) is inconsistent with device target ( { device . target () } )\" ) return Driver ( code . func , code . code , device , host_device , verbose ) else : f = build_binary if device is not None : f = functools . partial ( f , device = device ) if host_device is not None : f = functools . partial ( f , host_device = host_device ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f expr Facility to build AST expressions Classes and functions in this module are not only used internally for constructing AST nodes, and also exposed to users via multi-stage programming VarRef ( FrontendVar ) Variable of FreeTensor All variables in FreeTensor DSL (declared via Var , created by empty or var , returned by libop , etc.), and their slices, are VarRef objects. Operations on VarRef objects generates AST nodes Source code in freetensor/core/expr.py class VarRef ( ffi . FrontendVar ): ''' Variable of FreeTensor All variables in FreeTensor DSL (declared via `Var`, created by `empty` or `var`, returned by `libop`, etc.), and their slices, are `VarRef` objects. Operations on `VarRef` objects generates AST nodes ''' def __init__ ( self , name : str , vardef , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = []): super ( VarRef , self ) . __init__ ( name , full_shape , dtype , mtype , indices ) self . vardef = vardef from .stmt import find_borrowed_vardefs self . borrowed_vardefs = find_borrowed_vardefs ( indices ) for item in self . borrowed_vardefs : item . lend_out () def __del__ ( self ): for item in self . borrowed_vardefs : item . reclaim () def __getitem__ ( self , key ): return VarRef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) def __setitem__ ( self , key , value ): var = VarRef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) if var . ndim > 0 : if value is not None : # In standard Python data model, functions like __iadd__ # returns the modified self, and __setitem__ does a self- # assignment. We do the augmenting assignment directly # in __iadd__ and return None, so we do not have to do # it again here from .. import libop libop . assign ( var , value ) return if var . vardef . atype == ffi . AccessType ( \"input\" ): raise ffi . InvalidProgram ( \"Cannot modify an \\\" input \\\" tensor `\" + self . name + \"`\" ) if var . vardef . borrower_cnt > 0 : raise ffi . InvalidProgram ( \"Cannot modify tensor `\" + self . name + \"` becuase it has been borrowed in another tensor's shape, \" \"a tensor slice, or a range of a loop\" ) top = ctx_stack . top () top . append_stmt ( var . as_store ( top . get_next_nid (), value )) def select ( self , idx , dim ): assert isinstance ( dim , int ) assert dim >= 0 and dim < self . ndim indices = [ slice ( None , None ) if d != dim else idx for d in range ( self . ndim ) ] return self [ indices ] def _parse_key ( self , key ): if key is None or key is ... : key = () if not isinstance ( key , collections . abc . Sequence ): key = ( key ,) ffiIdx = [] for idx , length in zip ( key , self . shape ()): if isinstance ( idx , slice ): start = idx . start if idx . start is not None else 0 stop = idx . stop if idx . stop is not None else length assert idx . step is None or idx . step == 1 ffiIdx . append ( ffi . FrontendVarIdx ( start , stop )) elif isinstance ( idx , VarRef ): if len ( idx . full_shape ) == len ( idx . indices ): ffiIdx . append ( ffi . FrontendVarIdx ( idx . as_load ())) else : assert len ( key ) == 1 , f \"Shape of an index of { self . name } should be 1-D, instead of { idx . name } \" assert type ( idx . full_shape [ 0 ] ) is ffi . IntConst , \"Dynamic number of dimensions is not supported\" ndim = idx . full_shape [ 0 ] . val ffiIdx += [ ffi . FrontendVarIdx ( idx [ i ] . as_load ()) for i in range ( ndim ) ] else : ffiIdx . append ( ffi . FrontendVarIdx ( idx )) return ffiIdx def __add__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( self , other ) return self . as_load () + other def __radd__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( other , self ) return other + self . as_load () def __iadd__ ( self , other ): if self . ndim > 0 : from .. import libop libop . add_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __sub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( self , other ) return self . as_load () - other def __rsub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( other , self ) return other - self . as_load () def __isub__ ( self , other ): if self . ndim > 0 : from .. import libop libop . sub_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __mul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( self , other ) return self . as_load () * other def __rmul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( other , self ) return other * self . as_load () def __imul__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mul_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __truediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( self , other ) return self . as_load () / other def __rtruediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( other , self ) return other / self . as_load () def __itruediv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . truediv_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __floordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( self , other ) return self . as_load () // other def __rfloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( other , self ) return other // self . as_load () def __ifloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . floordiv_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __mod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( self , other ) return self . as_load () % other def __rmod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( other , self ) return other % self . as_load () def __imod__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mod_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __lt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . lt ( self , other ) return self . as_load () < other def __le__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . le ( self , other ) return self . as_load () <= other def __gt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . gt ( self , other ) return self . as_load () > other def __ge__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ge ( self , other ) return self . as_load () >= other def __eq__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . eq ( self , other ) return self . as_load () == other def __ne__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ne ( self , other ) return self . as_load () != other def __neg__ ( self ): if self . ndim > 0 : from .. import libop return libop . neg ( self ) return 0 - self . as_load () def __matmul__ ( self , other ): from .. import libop return libop . matmul ( self , other ) def __rmatmul__ ( self , other ): from .. import libop return libop . matmul ( other , self ) abs ( expr ) Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The absolute value Source code in freetensor/core/expr.py def abs ( expr ): ''' Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The absolute value ''' if _istensor ( expr ): from .. import libop return libop . abs ( expr ) if type ( expr ) in ( int , float ): return builtins . abs ( expr ) return ffi . makeAbs ( expr ) add ( lhs , rhs ) lhs + rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The sum Source code in freetensor/core/expr.py def add ( lhs , rhs ): ''' `lhs + rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The sum ''' return lhs + rhs any () Create an AnyExpr node (only for testing) Any nodes matches any expression nodes in ast.match Source code in freetensor/core/expr.py def any (): ''' Create an AnyExpr node (only for testing) Any nodes matches any expression nodes in `ast.match` ''' return ffi . makeAnyExpr () cast ( expr , dtype ) Cast to another type Parameters: expr ( VarRef or Number ) \u2013 The operand dtype ( DataTypr or str ) \u2013 The target data type Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def cast ( expr , dtype ): ''' Cast to another type Parameters ---------- expr : VarRef or Number The operand dtype : DataTypr or str The target data type Returns ------- VarRef or Number The result ''' return ffi . makeCast ( expr , ffi . DataType ( dtype )) ceil ( expr ) Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def ceil ( expr ): ''' Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . ceil ( expr ) return ffi . makeCeil ( expr ) ceildiv ( lhs , rhs ) Ceiling integer division of lhs dividing by rhs The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def ceildiv ( lhs , rhs ): ''' Ceiling integer division of `lhs` dividing by `rhs` The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . ceildiv ( lhs , rhs ) if type ( lhs ) is int and type ( rhs ) is int : return lhs // rhs + ( lhs % rhs > 0 ) return ffi . makeCeilDiv ( lhs , rhs ) dtype ( var ) Get element data type of a variable Source code in freetensor/core/expr.py def dtype ( var ): ''' Get element data type of a variable ''' if isinstance ( var , VarRef ): return var . dtype elif isinstance ( var , ffi . Expr ): return var . dtype else : # TODO: Config default type if isinstance ( var , float ): return ffi . DataType ( \"float32\" ) elif isinstance ( var , int ): return ffi . DataType ( \"int32\" ) else : raise Exception ( 'Unknown scalar type: ' + str ( type ( var ))) eq ( lhs , rhs ) lhs == rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def eq ( lhs , rhs ): ''' `lhs == rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs == rhs exp ( expr ) Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The exponent Source code in freetensor/core/expr.py def exp ( expr ): ''' Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The exponent ''' if _istensor ( expr ): from .. import libop return libop . exp ( expr ) if type ( expr ) in ( int , float ): return math . exp ( expr ) return ffi . makeExp ( expr ) floor ( expr ) Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def floor ( expr ): ''' Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . floor ( expr ) return ffi . makeFloor ( expr ) floordiv ( lhs , rhs ) Floored integer division of lhs dividing by rhs The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over round_towards_0_div , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def floordiv ( lhs , rhs ): ''' Floored integer division of `lhs` dividing by `rhs` The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over `round_towards_0_div`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs // rhs ge ( lhs , rhs ) lhs >= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def ge ( lhs , rhs ): ''' `lhs >= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs >= rhs gt ( lhs , rhs ) lhs > rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def gt ( lhs , rhs ): ''' `lhs > rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs > rhs if_then_else ( cond , then_case , else_case ) Similar to then_case if cond else else_case NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use if_then_else to guard an out-of-bound array indexing Parameters: cond ( VarRef of Number ) \u2013 Condition lhs ( VarRef or Number ) \u2013 Then-case experssion rhs ( VarRef or Number ) \u2013 Else-case expression Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def if_then_else ( cond , then_case , else_case ): ''' Similar to `then_case if cond else else_case` NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use `if_then_else` to guard an out-of-bound array indexing Parameters ---------- cond : VarRef of Number Condition lhs : VarRef or Number Then-case experssion rhs : VarRef or Number Else-case expression Returns ------- VarRef or Number The result ''' if type ( cond ) is bool : return then_case if cond else else_case return ffi . makeIfExpr ( cond , then_case , else_case ) intrinsic ( fmt , * params , ** kws ) Invoke whatever target code Parameters: fmt ( str ) \u2013 What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) The following variadic arguments ( Expr ) \u2013 Parameters to fmt ret_type ( DataType or str ) \u2013 (Keyword argument only) The return type. Void for no return type. Defaults to Void has_side_effect ( bool ) \u2013 (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false Source code in freetensor/core/expr.py def intrinsic ( fmt , * params , ** kws ): \"\"\" Invoke whatever target code Parameters ---------- fmt : str What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) The following variadic arguments : Expr Parameters to `fmt` ret_type : DataType or str (Keyword argument only) The return type. Void for no return type. Defaults to Void has_side_effect: bool (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false \"\"\" ret_type = ffi . DataType ( \"void\" ) has_side_effect = False if \"ret_type\" in kws : ret_type = ffi . DataType ( kws [ \"ret_type\" ]) del kws [ \"ret_type\" ] if \"has_side_effect\" in kws : has_side_effect = kws [ \"has_side_effect\" ] del kws [ \"has_side_effect\" ] assert len ( kws ) == 0 , \"Unrecognized keyword arguments: %s \" % kws return ffi . makeIntrinsic ( fmt , params , ret_type , has_side_effect ) l_and ( lhs , rhs ) Logical and of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The logical and Source code in freetensor/core/expr.py def l_and ( lhs , rhs ): ''' Logical and of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical and ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_and ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs and rhs else : return ffi . makeLAnd ( lhs , rhs ) l_not ( expr ) Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The logical not Source code in freetensor/core/expr.py def l_not ( expr ): ''' Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The logical not ''' if _istensor ( expr ): from .. import libop return libop . l_not ( expr ) if type ( expr ) is bool : return not expr else : return ffi . makeLNot ( expr ) l_or ( lhs , rhs ) Logical or of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The logical or Source code in freetensor/core/expr.py def l_or ( lhs , rhs ): ''' Logical or of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical or ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_or ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs or rhs else : return ffi . makeLOr ( lhs , rhs ) le ( lhs , rhs ) lhs <= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def le ( lhs , rhs ): ''' `lhs <= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs <= rhs lt ( lhs , rhs ) lhs < rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def lt ( lhs , rhs ): ''' `lhs < rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs < rhs max ( lhs , rhs ) Maximum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The maximum Source code in freetensor/core/expr.py def max ( lhs , rhs ): ''' Maximum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The maximum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . max ( lhs , rhs ) if type ( lhs ) in ( int , float ) and type ( rhs ) in ( int , float ): return builtins . max ( lhs , rhs ) return ffi . makeMax ( lhs , rhs ) min ( lhs , rhs ) Minimum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The minimum Source code in freetensor/core/expr.py def min ( lhs , rhs ): ''' Minimum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The minimum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . min ( lhs , rhs ) if type ( lhs ) in ( int , float ) and type ( rhs ) in ( int , float ): return builtins . min ( lhs , rhs ) return ffi . makeMin ( lhs , rhs ) mod ( lhs , rhs ) lhs modulus rhs The result is always non-negative (following Python convention, instead of C). This function is recommended over remainder , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The modulo Source code in freetensor/core/expr.py def mod ( lhs , rhs ): ''' `lhs` modulus `rhs` The result is always non-negative (following Python convention, instead of C). This function is recommended over `remainder`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The modulo ''' return lhs % rhs mtype ( var ) Get memory type of a variable Source code in freetensor/core/expr.py def mtype ( var ): ''' Get memory type of a variable ''' if isinstance ( var , VarRef ): return var . mtype else : return 'byvalue' mul ( lhs , rhs ) lhs * rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The product Source code in freetensor/core/expr.py def mul ( lhs , rhs ): ''' `lhs * rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The product ''' return lhs * rhs ndim ( var ) Get the number of dimensions of a variable Source code in freetensor/core/expr.py def ndim ( var ): ''' Get the number of dimensions of a variable ''' if isinstance ( var , VarRef ): return var . ndim else : return 0 ne ( lhs , rhs ) lhs != rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def ne ( lhs , rhs ): ''' `lhs != rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs != rhs remainder ( lhs , rhs ) Remainder of lhs dividing rhs The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use lhs % rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The remainder Source code in freetensor/core/expr.py def remainder ( lhs , rhs ): ''' Remainder of `lhs` dividing `rhs` The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use `lhs % rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The remainder ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . remainder ( lhs , rhs ) return ffi . makeRemainder ( lhs , rhs ) round_towards_0_div ( lhs , rhs ) C-style integer division of lhs dividing by rhs The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use lhs // rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def round_towards_0_div ( lhs , rhs ): ''' C-style integer division of `lhs` dividing by `rhs` The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use `lhs // rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . round_towards_0_div ( lhs , rhs ) return ffi . makeRoundTowards0Div ( lhs , rhs ) shape ( var , i = None ) shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable Source code in freetensor/core/expr.py def shape ( var , i = None ): ''' shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable ''' if isinstance ( var , VarRef ): return var . shape ( i ) else : if i is None : return () else : raise Exception ( f 'Getting size of dimension { i } of scalar { var } ' ) sigmoid ( expr ) Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def sigmoid ( expr ): ''' Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . sigmoid ( expr ) return ffi . makeSigmoid ( expr ) sqrt ( expr ) Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The square root Source code in freetensor/core/expr.py def sqrt ( expr ): ''' Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square root ''' if _istensor ( expr ): from .. import libop return libop . sqrt ( expr ) if type ( expr ) in ( int , float ): return math . sqrt ( expr ) return ffi . makeSqrt ( expr ) square ( expr ) Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The square Source code in freetensor/core/expr.py def square ( expr ): ''' Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square ''' if _istensor ( expr ): from .. import libop return libop . square ( expr ) if type ( expr ) in ( int , float ): return expr * expr return ffi . makeSquare ( expr ) sub ( lhs , rhs ) lhs - rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The difference Source code in freetensor/core/expr.py def sub ( lhs , rhs ): ''' `lhs - rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The difference ''' return lhs - rhs tanh ( expr ) Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def tanh ( expr ): ''' Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . tanh ( expr ) if type ( expr ) in ( int , float ): return math . tanh ( expr ) return ffi . makeTanh ( expr ) truediv ( lhs , rhs ) Floating point division of lhs dividing by rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def truediv ( lhs , rhs ): ''' Floating point division of `lhs` dividing by `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs / rhs optimize optimize ( func = None , schedule_callback = None , target = None , device = None , default_dynamic_range = True , verbose = None ) An one-click optimization from Python function to binary executable Usage: @optimize def f(...): ... It is equivalent to: @build_binary @codegen @lower @transform def f(...): ... Parameters: func ( Python function or AST ) \u2013 The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator schedule_callback ( Optional[Callable[[freetensor.core.schedule.Schedule], NoneType]] ) \u2013 Schedule(s) to apply target ( Optional[freetensor.core.driver.Target] ) \u2013 The target architecture. You don't have to set target if you set device device ( Optional[freetensor.core.driver.Device] ) \u2013 Where to run the program default_dynamic_range ( bool ) \u2013 If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose ( Optional[int] ) \u2013 Verbosity level. Can be 0, 1 or 2 Source code in freetensor/core/optimize.py def optimize ( func = None , schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , target : Optional [ Target ] = None , device : Optional [ Device ] = None , default_dynamic_range : bool = True , verbose : Optional [ int ] = None ): ''' An one-click optimization from Python function to binary executable Usage: ``` @optimize def f(...): ... ``` It is equivalent to: ``` @build_binary @codegen @lower @transform def f(...): ... ``` Parameters ---------- func : Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator schedule_callback : Callable (Optional) Schedule(s) to apply target : Target (Optional) The target architecture. You don't have to set target if you set device device : Device (Optional) Where to run the program default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int (Optional) Verbosity level. Can be 0, 1 or 2 ''' if func is not None : if target is None and device is not None : target = device . target () if not issubclass ( type ( func ), ffi . AST ): ast = transform ( func , default_dynamic_range = default_dynamic_range , verbose = verbose ) else : ast = func ast = schedule ( ast , schedule_callback , verbose = verbose ) ast = lower ( ast , target , verbose = verbose ) code = codegen ( ast , target , verbose = verbose ) exe = build_binary ( code , device , verbose = verbose ) return exe else : f = optimize if schedule_callback is not None : f = functools . partial ( f , schedule_callback = schedule_callback ) if target is not None : f = functools . partial ( f , target = target ) if device is not None : f = functools . partial ( f , device = device ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f passes lower ( ast = None , target = None , skip_passes = None , verbose = None ) Lower an AST using a series of passes Parameters: ast ( AST ) \u2013 The AST to be lowered. Can be a Func or a Stmt . If not specified, a partial function of lower will be returned, which can be used as a decorator target ( Optional[freetensor_ffi.Target] ) \u2013 Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config skip_passes ( Optional[Sequence[str]] ) \u2013 Skip some pass for testing or debugging. Names in skipPasses are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes verbose ( Optional[int] ) \u2013 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes Source code in freetensor/core/passes.py def lower ( ast = None , target : Optional [ ffi . Target ] = None , skip_passes : Optional [ Sequence [ str ]] = None , verbose : Optional [ int ] = None ): ''' Lower an AST using a series of passes Parameters ---------- ast : AST The AST to be lowered. Can be a `Func` or a `Stmt`. If not specified, a partial function of `lower` will be returned, which can be used as a decorator target : Target (Optional) Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config skip_passes : Sequence[str] (Optional) Skip some pass for testing or debugging. Names in `skipPasses` are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes verbose : int (Optional) 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes ''' if ast is not None : return ffi . lower ( ast , target , set () if skip_passes is None else set ( skip_passes ), 0 if verbose is None else verbose ) else : _lower = lower if target is not None : _lower = functools . partial ( _lower , target = target ) if skip_passes is not None : _lower = functools . partial ( _lower , skip_passes = skip_passes ) if verbose is not None : _lower = functools . partial ( _lower , verbose = verbose ) return _lower schedule Schedule ( Schedule ) Source code in freetensor/core/schedule.py class Schedule ( ffi . Schedule ): def __init__ ( self , ast , verbose : int = 0 ): super ( Schedule , self ) . __init__ ( ast , verbose ) def split ( self , node , factor =- 1 , nparts =- 1 , shift = 0 ): \"\"\" Split a loop into two nested loops To fission a loop into two consecutive loops, use `fission` instead Two modes are provided: 1. Specify `factor` and leave `nparts` to -1. It will result in an outer loop with length `ceil(n / factor)`, and an inner loop with length `factor`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * factor + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively 2. Specify `nparts` and leave `factor` to -1. It will result in an outer loop with length `nparts`, and an inner loop with length `ceil(n / nparts)`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * ceil(n / nparts) + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively Please note that the second mode will introduce an `i0 * ceil(n / nparts)` factor into the program, which cannot be recognized by polyhedral analysis, which may hinder some following schedules. If possible, plese use the first mode, and then reorder the inner and outer loops Parameters ---------- node : str, ID or Stmt The loop to be split factor : int Length of the inner loop. Set to -1 if using `nparts` nparts : int Length of the outer loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the loop is not found Returns ------- (str, str) (outer loop ID, inner loop ID) \"\"\" return super ( Schedule , self ) . split ( ID ( node ), factor , nparts , shift ) def reorder ( self , order ): \"\"\" Reorder directly nested loops To swap consecutive loops, use `swap` instead Parameters ---------- order : array like of str, ID or Stmt Vector of loops. The requested order of the loops Raises ------ InvalidSchedule if the input is invalid or there are breaking dependencies \"\"\" super ( Schedule , self ) . reorder ( list ( map ( ID , order ))) def merge ( self , loop1 , loop2 ): \"\"\" Merge two directly nested loops into one To fuse consecutive loops, use `fuse` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the merged loop Parameters ---------- loop1, loop2 : str, ID or Stmt loops to be merged, can be in any order Raises ------ InvalidSchedule if the loops are not directly nested Returns ------- str ID of the merged loop \"\"\" return super ( Schedule , self ) . merge ( ID ( loop1 ), ID ( loop2 )) def fission ( self , loop , side , splitter , suffix0 = \".a\" , suffix1 = \".b\" ): \"\"\" Fission a loop into two loops each containing part of the statements, one followed by another To split loop into two nested loops, use `split` instead Parameters ---------- loop : str, ID or Stmt The loop to be fissioned side : FissionSide If `After`, `splitter` is the last statement of the first loop. If `Before`, `splitter` is the first statement of the second loop splitter : str, ID or Stmt Where to fission the loop suffix0 : str ID suffix of the statements in the first loop, default to \".a\", can be \"\" for convenience, but cannot be the same with suffix1 suffix1 : str ID suffix of the statements in the second loop, default to \".b\", can be \"\" for convenience, but cannot be the same with suffix0 Raises ------ InvalidSchedule if any dependency cannot be resolved Returns ------- (map, map) ({old ID -> new ID in 1st loop}, {old ID -> new ID in 2nd loop}) \"\"\" return super ( Schedule , self ) . fission ( ID ( loop ), side , ID ( splitter ), suffix0 , suffix1 ) def fuse ( self , loop0 , loop1 = None , strict = False ): \"\"\" Fuse two directly following loops with the same length into one To merge nested loops into one, use `merge` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the fused loop Parameters ---------- loop0 : str, ID or Stmt The leading loop loop1 : str, ID or Stmt, Optional The following loop. If omitted, it will try to find a following loop of `loop0` strict : bool False by default. If set to True, throw an error if unable to determine whether the two loops are of the same length Raises ------ InvalidSchedule if the two loops are not directly following, the two loops are not of the same length, or there is any dependency cannot be resolved Returns ------- str ID of the result loop \"\"\" if loop1 is None : return super ( Schedule , self ) . fuse ( ID ( loop0 ), strict ) else : return super ( Schedule , self ) . fuse ( ID ( loop0 ), ID ( loop1 ), strict ) def swap ( self , order ): \"\"\" Swap statements in the same block To reorder nested loops, use `reorder` instead Parameters ---------- order : array like of str, ID or Stmt The statements Raises ------ InvalidSchedule if the statements are not found or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . swap ( list ( map ( ID , order ))) def blend ( self , loop ): \"\"\" Unroll a loop and interleave statements from each iteration E.g. ``` for i = 0 to 2 { f(i); g(i); } ``` will be transformed to be ``` f(0); f(1); g(0); g(1); ``` Virtual threads in TVM can be implemented via blend Parameters ---------- loop : str, ID or Stmt The loop being transformed Raises ------ InvalidSchedule if the loop is not found, the loop length is not a constant, or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . blend ( ID ( loop )) def cache ( self , stmt , var , mtype ): \"\"\" Cache a variable into a new local variable All needed data will be filled into the cache first, then all reads and writes will be directed to the cache, and finally all needed data will be flushed from the cache Note for reduction: This transformation preserves the computation order. It will transform ``` a += x a += y ``` to ``` a.cache = a + x + y a = a.cache ``` If you need a \"real\" cache for reduction, which reorders the computation, use `cache_reduction` instead Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found Returns ------- (str, str, str, str) (ID of the statement that fills the cache, ID of the statement that flushes from the cache, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache ( ID ( stmt ), var , MemType ( mtype )) def cache_reduction ( self , stmt , var , mtype ): \"\"\" Perform local reductions (e.g. sum) in a local variable first, and then reduce the local result to the global variable E.g. ``` a += x a += y ``` will be transformed to be ``` a.cache = x + y a += a.cache ``` Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached. Only reductions are allowed on `var` in `stmt`. Plain reads or writes are not allowed mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found, or there are unsupported reads or writes Returns ------- (str, str, str, str) (ID of the statement that initialize the cache, ID of the statement that reduces the local result to the global result, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache_reduction ( ID ( stmt ), var , MemType ( mtype )) def set_mem_type ( self , vardef , mtype ): \"\"\" Change where a variable is stored Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable mtype : MemType Where the variable should be stored Raises ------ InvalidSchedule if the variable is not found \"\"\" super ( Schedule , self ) . set_mem_type ( ID ( vardef ), MemType ( mtype )) def var_split ( self , vardef , dim , mode , factor =- 1 , nparts =- 1 ): \"\"\" Split a dimension of a variable into two Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int which dimension to be split mode : VarSplitMode When the dimension to split is not divisible by `factor` or `nparts`, the resulting shape may become larger. In `FixedSize` mode, the actual buffer size will not be changed, and gurads will be added to prevent out-of-bound accesses. In `RelaxedSize` mode, the buffer size may increase. The `RelaxedSize` mode cannot be applied to I/O variables factor : int Length of the inner (higher no.) dimension. Set to -1 if using `nparts` nparts : int Length of the outer (lower no.) loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the variable or the dimension is not found \"\"\" return super ( Schedule , self ) . var_split ( ID ( vardef ), dim , mode , factor , nparts ) def var_merge ( self , vardef , dim ): \"\"\" Merge two dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int Merge the `dim`-th and the `(dim + 1)`-th dimension \"\"\" return super ( Schedule , self ) . var_merge ( ID ( vardef ), dim ) def var_reorder ( self , vardef , order ): \"\"\" Reorder the dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable order : array like of str, ID or Stmt Vector of integers. The new order of the dimensions Raises ------ InvalidSchedule if the variable or the order is illegal \"\"\" return super ( Schedule , self ) . var_reorder ( ID ( vardef ), order ) def move_to ( self , stmt , side , dst ): \"\"\" Move a statement to a new position This is a composite schedule command, which is implemented with other commands Parameters ---------- stmt : str, ID or Stmt The statement to be moved side : MoveToSide Whether `stmt` will be BEFORE or AFTER `dst dst : str, ID or Stmt Insert `stmt` to be directly after this statement Raises ------ InvalidSchedule if there is no feasible path to move Returns ------- str The new ID of stmt \"\"\" return super ( Schedule , self ) . move_to ( ID ( stmt ), side , ID ( dst )) def inline ( self , vardef ): \"\"\" Remove a variable. When the variable is used, recompute its value Parameters ---------- vardef : str, ID or Stmt The VarDef statement of the specific variable. It can not be an I/O varible Raises ------ InvalidSchedule if the variable cannot be completely removed \"\"\" return super ( Schedule , self ) . inline ( ID ( vardef )) def parallelize ( self , loop , parallel ): \"\"\" Mark a loop with a parallel implementation Parameters ---------- loop : str, ID or Stmt The loop parallel : ParallelScope Parallel scope \"\"\" super ( Schedule , self ) . parallelize ( ID ( loop ), ParallelScope ( parallel )) def unroll ( self , loop , immediate = False ): \"\"\" Unroll a loop Parameters ---------- loop : str, ID or Stmt ID of the loop immediate : bool If false (by default), postpone the unroll procedure to the backend compiler, which saves scheduling time. If true, unroll the loop immediately, which may help further simplifications based on the unrolled result. If your purpose is just to fill the instruction cache, set it to false. If you are unrolling a loop that computes array indices, set it to true Raises ------ InvalidSchedule if the loop is not found or length of the loop is not a constant \"\"\" super ( Schedule , self ) . unroll ( ID ( loop ), immediate ) def vectorize ( self , loop ): \"\"\" Vectorize a loop Please note that, as vectorization is different from architecture to achitecture, the scheduler may or may not postpone it to the backend compiler. The vectorization is a best-effort schedule Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the ID or name is not found, or the dependency requirement is not met \"\"\" super ( Schedule , self ) . vectorize ( ID ( loop )) def separate_tail ( self , noDuplicateVarDefs = False ): \"\"\" Seperate main iterations and tail iterations of a loop E.g. ``` for i = 0 -> 3 { for j = 0 -> 4 { if (i * 4 + j < 10) { ... } } } ``` Each loop will be separated into 2 parts: the body and the tail. After simplification, the program will finally be transformed to ``` for i = 0 -> 2 { for j = 0 -> 4 { ... } } for j = 0 -> 2 { ... } ``` Ideally, all programs can benefit from this schedule. However, this schedule may greatly increase the program size and make the compiling time way too long. Therefore, this transformation is implemented as a schedule, which can be applied optionally. (TODO: Optionally apply this schedule to part of the program) Parameters ---------- noDuplicateVarDefs : bool If there is two VarDef nodes in two branches, it may result in doubled memory use, since different thread may go to different branch. Set this parameter to true to stop duplicating VarDef nodes. \"\"\" super ( Schedule , self ) . separate_tail ( noDuplicateVarDefs ) def as_matmul ( self , loop ): \"\"\" Transform nested loops to be a external call to a matrix multiplication Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the loop cannot be transformed to be a matrix multiplication \"\"\" super ( Schedule , self ) . as_matmul ( ID ( loop )) def auto_schedule ( self , target ): \"\"\" (Experimental) Automatic scheduling using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_schedule ( target ) def auto_use_lib ( self , target ): \"\"\" (Experimental) Automatically use external libs using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_use_lib ( target ) def auto_fuse ( self , target ): \"\"\" (Experimental) Automatically fuse consecutive loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_fuse ( target ) def auto_parallelize ( self , target ): \"\"\" (Experimental) Automatically parallelize some loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_parallelize ( target ) def auto_set_mem_type ( self , target ): \"\"\" (Experimental) Automatically set memory types using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_set_mem_type ( target ) def auto_unroll ( self , target ): \"\"\" (Experimental) Automatically unroll loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_unroll ( target ) as_matmul ( self , loop ) Transform nested loops to be a external call to a matrix multiplication Parameters: loop ( str, ID or Stmt ) \u2013 ID of the loop Exceptions: InvalidSchedule \u2013 if the loop cannot be transformed to be a matrix multiplication Source code in freetensor/core/schedule.py def as_matmul ( self , loop ): \"\"\" Transform nested loops to be a external call to a matrix multiplication Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the loop cannot be transformed to be a matrix multiplication \"\"\" super ( Schedule , self ) . as_matmul ( ID ( loop )) auto_fuse ( self , target ) (Experimental) Automatically fuse consecutive loops using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_fuse ( self , target ): \"\"\" (Experimental) Automatically fuse consecutive loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_fuse ( target ) auto_parallelize ( self , target ) (Experimental) Automatically parallelize some loops using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_parallelize ( self , target ): \"\"\" (Experimental) Automatically parallelize some loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_parallelize ( target ) auto_schedule ( self , target ) (Experimental) Automatic scheduling using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_schedule ( self , target ): \"\"\" (Experimental) Automatic scheduling using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_schedule ( target ) auto_set_mem_type ( self , target ) (Experimental) Automatically set memory types using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_set_mem_type ( self , target ): \"\"\" (Experimental) Automatically set memory types using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_set_mem_type ( target ) auto_unroll ( self , target ) (Experimental) Automatically unroll loops using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_unroll ( self , target ): \"\"\" (Experimental) Automatically unroll loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_unroll ( target ) auto_use_lib ( self , target ) (Experimental) Automatically use external libs using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_use_lib ( self , target ): \"\"\" (Experimental) Automatically use external libs using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_use_lib ( target ) blend ( self , loop ) Unroll a loop and interleave statements from each iteration E.g. for i = 0 to 2 { f(i); g(i); } will be transformed to be f(0); f(1); g(0); g(1); Virtual threads in TVM can be implemented via blend Parameters: loop ( str, ID or Stmt ) \u2013 The loop being transformed Exceptions: InvalidSchedule \u2013 if the loop is not found, the loop length is not a constant, or the dependencies cannot be solved Source code in freetensor/core/schedule.py def blend ( self , loop ): \"\"\" Unroll a loop and interleave statements from each iteration E.g. ``` for i = 0 to 2 { f(i); g(i); } ``` will be transformed to be ``` f(0); f(1); g(0); g(1); ``` Virtual threads in TVM can be implemented via blend Parameters ---------- loop : str, ID or Stmt The loop being transformed Raises ------ InvalidSchedule if the loop is not found, the loop length is not a constant, or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . blend ( ID ( loop )) cache ( self , stmt , var , mtype ) Cache a variable into a new local variable All needed data will be filled into the cache first, then all reads and writes will be directed to the cache, and finally all needed data will be flushed from the cache Note for reduction: This transformation preserves the computation order. It will transform a += x a += y to a.cache = a + x + y a = a.cache If you need a \"real\" cache for reduction, which reorders the computation, use cache_reduction instead Parameters: stmt ( str, ID or Stmt ) \u2013 The statement or block (e.g. an If or a For) to be modified var ( str ) \u2013 Name of the variable to be cached mtype ( MemType ) \u2013 Where to cache Exceptions: InvalidSchedule \u2013 if the ID or name is not found Returns: (str, str, str, str) \u2013 (ID of the statement that fills the cache, ID of the statement that flushes from the cache, name of the cache variable, ID of the VarDef node of the cache variable) Source code in freetensor/core/schedule.py def cache ( self , stmt , var , mtype ): \"\"\" Cache a variable into a new local variable All needed data will be filled into the cache first, then all reads and writes will be directed to the cache, and finally all needed data will be flushed from the cache Note for reduction: This transformation preserves the computation order. It will transform ``` a += x a += y ``` to ``` a.cache = a + x + y a = a.cache ``` If you need a \"real\" cache for reduction, which reorders the computation, use `cache_reduction` instead Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found Returns ------- (str, str, str, str) (ID of the statement that fills the cache, ID of the statement that flushes from the cache, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache ( ID ( stmt ), var , MemType ( mtype )) cache_reduction ( self , stmt , var , mtype ) Perform local reductions (e.g. sum) in a local variable first, and then reduce the local result to the global variable E.g. a += x a += y will be transformed to be a.cache = x + y a += a.cache Parameters: stmt ( str, ID or Stmt ) \u2013 The statement or block (e.g. an If or a For) to be modified var ( str ) \u2013 Name of the variable to be cached. Only reductions are allowed on var in stmt . Plain reads or writes are not allowed mtype ( MemType ) \u2013 Where to cache Exceptions: InvalidSchedule \u2013 if the ID or name is not found, or there are unsupported reads or writes Returns: (str, str, str, str) \u2013 (ID of the statement that initialize the cache, ID of the statement that reduces the local result to the global result, name of the cache variable, ID of the VarDef node of the cache variable) Source code in freetensor/core/schedule.py def cache_reduction ( self , stmt , var , mtype ): \"\"\" Perform local reductions (e.g. sum) in a local variable first, and then reduce the local result to the global variable E.g. ``` a += x a += y ``` will be transformed to be ``` a.cache = x + y a += a.cache ``` Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached. Only reductions are allowed on `var` in `stmt`. Plain reads or writes are not allowed mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found, or there are unsupported reads or writes Returns ------- (str, str, str, str) (ID of the statement that initialize the cache, ID of the statement that reduces the local result to the global result, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache_reduction ( ID ( stmt ), var , MemType ( mtype )) fission ( self , loop , side , splitter , suffix0 = '.a' , suffix1 = '.b' ) Fission a loop into two loops each containing part of the statements, one followed by another To split loop into two nested loops, use split instead Parameters: loop ( str, ID or Stmt ) \u2013 The loop to be fissioned side ( FissionSide ) \u2013 If After , splitter is the last statement of the first loop. If Before , splitter is the first statement of the second loop splitter ( str, ID or Stmt ) \u2013 Where to fission the loop suffix0 ( str ) \u2013 ID suffix of the statements in the first loop, default to \".a\", can be \"\" for convenience, but cannot be the same with suffix1 suffix1 ( str ) \u2013 ID suffix of the statements in the second loop, default to \".b\", can be \"\" for convenience, but cannot be the same with suffix0 Exceptions: InvalidSchedule \u2013 if any dependency cannot be resolved Returns: (map, map) \u2013 ({old ID -> new ID in 1st loop}, {old ID -> new ID in 2nd loop}) Source code in freetensor/core/schedule.py def fission ( self , loop , side , splitter , suffix0 = \".a\" , suffix1 = \".b\" ): \"\"\" Fission a loop into two loops each containing part of the statements, one followed by another To split loop into two nested loops, use `split` instead Parameters ---------- loop : str, ID or Stmt The loop to be fissioned side : FissionSide If `After`, `splitter` is the last statement of the first loop. If `Before`, `splitter` is the first statement of the second loop splitter : str, ID or Stmt Where to fission the loop suffix0 : str ID suffix of the statements in the first loop, default to \".a\", can be \"\" for convenience, but cannot be the same with suffix1 suffix1 : str ID suffix of the statements in the second loop, default to \".b\", can be \"\" for convenience, but cannot be the same with suffix0 Raises ------ InvalidSchedule if any dependency cannot be resolved Returns ------- (map, map) ({old ID -> new ID in 1st loop}, {old ID -> new ID in 2nd loop}) \"\"\" return super ( Schedule , self ) . fission ( ID ( loop ), side , ID ( splitter ), suffix0 , suffix1 ) fuse ( self , loop0 , loop1 = None , strict = False ) Fuse two directly following loops with the same length into one To merge nested loops into one, use merge instead parallelize , unroll and vectorize properties will be reset on the fused loop Parameters: loop0 ( str, ID or Stmt ) \u2013 The leading loop loop1 ( str, ID or Stmt, Optional ) \u2013 The following loop. If omitted, it will try to find a following loop of loop0 strict ( bool ) \u2013 False by default. If set to True, throw an error if unable to determine whether the two loops are of the same length Exceptions: InvalidSchedule \u2013 if the two loops are not directly following, the two loops are not of the same length, or there is any dependency cannot be resolved Returns: str \u2013 ID of the result loop Source code in freetensor/core/schedule.py def fuse ( self , loop0 , loop1 = None , strict = False ): \"\"\" Fuse two directly following loops with the same length into one To merge nested loops into one, use `merge` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the fused loop Parameters ---------- loop0 : str, ID or Stmt The leading loop loop1 : str, ID or Stmt, Optional The following loop. If omitted, it will try to find a following loop of `loop0` strict : bool False by default. If set to True, throw an error if unable to determine whether the two loops are of the same length Raises ------ InvalidSchedule if the two loops are not directly following, the two loops are not of the same length, or there is any dependency cannot be resolved Returns ------- str ID of the result loop \"\"\" if loop1 is None : return super ( Schedule , self ) . fuse ( ID ( loop0 ), strict ) else : return super ( Schedule , self ) . fuse ( ID ( loop0 ), ID ( loop1 ), strict ) inline ( self , vardef ) Remove a variable. When the variable is used, recompute its value Parameters: vardef ( str, ID or Stmt ) \u2013 The VarDef statement of the specific variable. It can not be an I/O varible Exceptions: InvalidSchedule \u2013 if the variable cannot be completely removed Source code in freetensor/core/schedule.py def inline ( self , vardef ): \"\"\" Remove a variable. When the variable is used, recompute its value Parameters ---------- vardef : str, ID or Stmt The VarDef statement of the specific variable. It can not be an I/O varible Raises ------ InvalidSchedule if the variable cannot be completely removed \"\"\" return super ( Schedule , self ) . inline ( ID ( vardef )) merge ( self , loop1 , loop2 ) Merge two directly nested loops into one To fuse consecutive loops, use fuse instead parallelize , unroll and vectorize properties will be reset on the merged loop Parameters: loop1, loop2 ( str, ID or Stmt ) \u2013 loops to be merged, can be in any order Exceptions: InvalidSchedule \u2013 if the loops are not directly nested Returns: str \u2013 ID of the merged loop Source code in freetensor/core/schedule.py def merge ( self , loop1 , loop2 ): \"\"\" Merge two directly nested loops into one To fuse consecutive loops, use `fuse` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the merged loop Parameters ---------- loop1, loop2 : str, ID or Stmt loops to be merged, can be in any order Raises ------ InvalidSchedule if the loops are not directly nested Returns ------- str ID of the merged loop \"\"\" return super ( Schedule , self ) . merge ( ID ( loop1 ), ID ( loop2 )) move_to ( self , stmt , side , dst ) Move a statement to a new position This is a composite schedule command, which is implemented with other commands Parameters: stmt ( str, ID or Stmt ) \u2013 The statement to be moved side ( MoveToSide ) \u2013 Whether stmt will be BEFORE or AFTER `dst dst ( str, ID or Stmt ) \u2013 Insert stmt to be directly after this statement Exceptions: InvalidSchedule \u2013 if there is no feasible path to move Returns: str \u2013 The new ID of stmt Source code in freetensor/core/schedule.py def move_to ( self , stmt , side , dst ): \"\"\" Move a statement to a new position This is a composite schedule command, which is implemented with other commands Parameters ---------- stmt : str, ID or Stmt The statement to be moved side : MoveToSide Whether `stmt` will be BEFORE or AFTER `dst dst : str, ID or Stmt Insert `stmt` to be directly after this statement Raises ------ InvalidSchedule if there is no feasible path to move Returns ------- str The new ID of stmt \"\"\" return super ( Schedule , self ) . move_to ( ID ( stmt ), side , ID ( dst )) parallelize ( self , loop , parallel ) Mark a loop with a parallel implementation Parameters: loop ( str, ID or Stmt ) \u2013 The loop parallel ( ParallelScope ) \u2013 Parallel scope Source code in freetensor/core/schedule.py def parallelize ( self , loop , parallel ): \"\"\" Mark a loop with a parallel implementation Parameters ---------- loop : str, ID or Stmt The loop parallel : ParallelScope Parallel scope \"\"\" super ( Schedule , self ) . parallelize ( ID ( loop ), ParallelScope ( parallel )) reorder ( self , order ) Reorder directly nested loops To swap consecutive loops, use swap instead Parameters: order ( array like of str, ID or Stmt ) \u2013 Vector of loops. The requested order of the loops Exceptions: InvalidSchedule \u2013 if the input is invalid or there are breaking dependencies Source code in freetensor/core/schedule.py def reorder ( self , order ): \"\"\" Reorder directly nested loops To swap consecutive loops, use `swap` instead Parameters ---------- order : array like of str, ID or Stmt Vector of loops. The requested order of the loops Raises ------ InvalidSchedule if the input is invalid or there are breaking dependencies \"\"\" super ( Schedule , self ) . reorder ( list ( map ( ID , order ))) separate_tail ( self , noDuplicateVarDefs = False ) Seperate main iterations and tail iterations of a loop E.g. for i = 0 -> 3 { for j = 0 -> 4 { if (i * 4 + j < 10) { ... } } } Each loop will be separated into 2 parts: the body and the tail. After simplification, the program will finally be transformed to for i = 0 -> 2 { for j = 0 -> 4 { ... } } for j = 0 -> 2 { ... } Ideally, all programs can benefit from this schedule. However, this schedule may greatly increase the program size and make the compiling time way too long. Therefore, this transformation is implemented as a schedule, which can be applied optionally. (TODO: Optionally apply this schedule to part of the program) Parameters: noDuplicateVarDefs ( bool ) \u2013 If there is two VarDef nodes in two branches, it may result in doubled memory use, since different thread may go to different branch. Set this parameter to true to stop duplicating VarDef nodes. Source code in freetensor/core/schedule.py def separate_tail ( self , noDuplicateVarDefs = False ): \"\"\" Seperate main iterations and tail iterations of a loop E.g. ``` for i = 0 -> 3 { for j = 0 -> 4 { if (i * 4 + j < 10) { ... } } } ``` Each loop will be separated into 2 parts: the body and the tail. After simplification, the program will finally be transformed to ``` for i = 0 -> 2 { for j = 0 -> 4 { ... } } for j = 0 -> 2 { ... } ``` Ideally, all programs can benefit from this schedule. However, this schedule may greatly increase the program size and make the compiling time way too long. Therefore, this transformation is implemented as a schedule, which can be applied optionally. (TODO: Optionally apply this schedule to part of the program) Parameters ---------- noDuplicateVarDefs : bool If there is two VarDef nodes in two branches, it may result in doubled memory use, since different thread may go to different branch. Set this parameter to true to stop duplicating VarDef nodes. \"\"\" super ( Schedule , self ) . separate_tail ( noDuplicateVarDefs ) set_mem_type ( self , vardef , mtype ) Change where a variable is stored Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable mtype ( MemType ) \u2013 Where the variable should be stored Exceptions: InvalidSchedule \u2013 if the variable is not found Source code in freetensor/core/schedule.py def set_mem_type ( self , vardef , mtype ): \"\"\" Change where a variable is stored Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable mtype : MemType Where the variable should be stored Raises ------ InvalidSchedule if the variable is not found \"\"\" super ( Schedule , self ) . set_mem_type ( ID ( vardef ), MemType ( mtype )) split ( self , node , factor =- 1 , nparts =- 1 , shift = 0 ) Split a loop into two nested loops To fission a loop into two consecutive loops, use fission instead Two modes are provided: Specify factor and leave nparts to -1. It will result in an outer loop with length ceil(n / factor) , and an inner loop with length factor , where n is the original loop length added by shift . The original iterator i will be transformed to i0 * factor + i1 , where i0 and i1 are the iterators of the new outer and inner loops, respectively Specify nparts and leave factor to -1. It will result in an outer loop with length nparts , and an inner loop with length ceil(n / nparts) , where n is the original loop length added by shift . The original iterator i will be transformed to i0 * ceil(n / nparts) + i1 , where i0 and i1 are the iterators of the new outer and inner loops, respectively Please note that the second mode will introduce an i0 * ceil(n / nparts) factor into the program, which cannot be recognized by polyhedral analysis, which may hinder some following schedules. If possible, plese use the first mode, and then reorder the inner and outer loops Parameters: node ( str, ID or Stmt ) \u2013 The loop to be split factor ( int ) \u2013 Length of the inner loop. Set to -1 if using nparts nparts ( int ) \u2013 Length of the outer loop. Set to -1 if using factor Exceptions: InvalidSchedule \u2013 if the loop is not found Returns: (str, str) \u2013 (outer loop ID, inner loop ID) Source code in freetensor/core/schedule.py def split ( self , node , factor =- 1 , nparts =- 1 , shift = 0 ): \"\"\" Split a loop into two nested loops To fission a loop into two consecutive loops, use `fission` instead Two modes are provided: 1. Specify `factor` and leave `nparts` to -1. It will result in an outer loop with length `ceil(n / factor)`, and an inner loop with length `factor`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * factor + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively 2. Specify `nparts` and leave `factor` to -1. It will result in an outer loop with length `nparts`, and an inner loop with length `ceil(n / nparts)`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * ceil(n / nparts) + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively Please note that the second mode will introduce an `i0 * ceil(n / nparts)` factor into the program, which cannot be recognized by polyhedral analysis, which may hinder some following schedules. If possible, plese use the first mode, and then reorder the inner and outer loops Parameters ---------- node : str, ID or Stmt The loop to be split factor : int Length of the inner loop. Set to -1 if using `nparts` nparts : int Length of the outer loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the loop is not found Returns ------- (str, str) (outer loop ID, inner loop ID) \"\"\" return super ( Schedule , self ) . split ( ID ( node ), factor , nparts , shift ) swap ( self , order ) Swap statements in the same block To reorder nested loops, use reorder instead Parameters: order ( array like of str, ID or Stmt ) \u2013 The statements Exceptions: InvalidSchedule \u2013 if the statements are not found or the dependencies cannot be solved Source code in freetensor/core/schedule.py def swap ( self , order ): \"\"\" Swap statements in the same block To reorder nested loops, use `reorder` instead Parameters ---------- order : array like of str, ID or Stmt The statements Raises ------ InvalidSchedule if the statements are not found or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . swap ( list ( map ( ID , order ))) unroll ( self , loop , immediate = False ) Unroll a loop Parameters: loop ( str, ID or Stmt ) \u2013 ID of the loop immediate ( bool ) \u2013 If false (by default), postpone the unroll procedure to the backend compiler, which saves scheduling time. If true, unroll the loop immediately, which may help further simplifications based on the unrolled result. If your purpose is just to fill the instruction cache, set it to false. If you are unrolling a loop that computes array indices, set it to true Exceptions: InvalidSchedule \u2013 if the loop is not found or length of the loop is not a constant Source code in freetensor/core/schedule.py def unroll ( self , loop , immediate = False ): \"\"\" Unroll a loop Parameters ---------- loop : str, ID or Stmt ID of the loop immediate : bool If false (by default), postpone the unroll procedure to the backend compiler, which saves scheduling time. If true, unroll the loop immediately, which may help further simplifications based on the unrolled result. If your purpose is just to fill the instruction cache, set it to false. If you are unrolling a loop that computes array indices, set it to true Raises ------ InvalidSchedule if the loop is not found or length of the loop is not a constant \"\"\" super ( Schedule , self ) . unroll ( ID ( loop ), immediate ) var_merge ( self , vardef , dim ) Merge two dimensions of a variable Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable dim ( int ) \u2013 Merge the dim -th and the (dim + 1) -th dimension Source code in freetensor/core/schedule.py def var_merge ( self , vardef , dim ): \"\"\" Merge two dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int Merge the `dim`-th and the `(dim + 1)`-th dimension \"\"\" return super ( Schedule , self ) . var_merge ( ID ( vardef ), dim ) var_reorder ( self , vardef , order ) Reorder the dimensions of a variable Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable order ( array like of str, ID or Stmt ) \u2013 Vector of integers. The new order of the dimensions Exceptions: InvalidSchedule \u2013 if the variable or the order is illegal Source code in freetensor/core/schedule.py def var_reorder ( self , vardef , order ): \"\"\" Reorder the dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable order : array like of str, ID or Stmt Vector of integers. The new order of the dimensions Raises ------ InvalidSchedule if the variable or the order is illegal \"\"\" return super ( Schedule , self ) . var_reorder ( ID ( vardef ), order ) var_split ( self , vardef , dim , mode , factor =- 1 , nparts =- 1 ) Split a dimension of a variable into two Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable dim ( int ) \u2013 which dimension to be split mode ( VarSplitMode ) \u2013 When the dimension to split is not divisible by factor or nparts , the resulting shape may become larger. In FixedSize mode, the actual buffer size will not be changed, and gurads will be added to prevent out-of-bound accesses. In RelaxedSize mode, the buffer size may increase. The RelaxedSize mode cannot be applied to I/O variables factor ( int ) \u2013 Length of the inner (higher no.) dimension. Set to -1 if using nparts nparts ( int ) \u2013 Length of the outer (lower no.) loop. Set to -1 if using factor Exceptions: InvalidSchedule \u2013 if the variable or the dimension is not found Source code in freetensor/core/schedule.py def var_split ( self , vardef , dim , mode , factor =- 1 , nparts =- 1 ): \"\"\" Split a dimension of a variable into two Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int which dimension to be split mode : VarSplitMode When the dimension to split is not divisible by `factor` or `nparts`, the resulting shape may become larger. In `FixedSize` mode, the actual buffer size will not be changed, and gurads will be added to prevent out-of-bound accesses. In `RelaxedSize` mode, the buffer size may increase. The `RelaxedSize` mode cannot be applied to I/O variables factor : int Length of the inner (higher no.) dimension. Set to -1 if using `nparts` nparts : int Length of the outer (lower no.) loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the variable or the dimension is not found \"\"\" return super ( Schedule , self ) . var_split ( ID ( vardef ), dim , mode , factor , nparts ) vectorize ( self , loop ) Vectorize a loop Please note that, as vectorization is different from architecture to achitecture, the scheduler may or may not postpone it to the backend compiler. The vectorization is a best-effort schedule Parameters: loop ( str, ID or Stmt ) \u2013 ID of the loop Exceptions: InvalidSchedule \u2013 if the ID or name is not found, or the dependency requirement is not met Source code in freetensor/core/schedule.py def vectorize ( self , loop ): \"\"\" Vectorize a loop Please note that, as vectorization is different from architecture to achitecture, the scheduler may or may not postpone it to the backend compiler. The vectorization is a best-effort schedule Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the ID or name is not found, or the dependency requirement is not met \"\"\" super ( Schedule , self ) . vectorize ( ID ( loop )) schedule ( ast = None , callback = None , verbose = None ) Apply any schedule on an AST through a user callback Parameters: ast ( Func or Stmt ) \u2013 The AST to schedule. If not specified, a partial function will be returned that cna be used as a decorator callback ( Callable[[freetensor.core.schedule.Schedule], NoneType] ) \u2013 Specify what schedule(s) to do in this callback verbose ( Optional[int] ) \u2013 0 = print nothing. 1 = print the final AST. 2 = print an AST after each schedule Source code in freetensor/core/schedule.py def schedule ( ast = None , callback : Callable [[ Schedule ], None ] = None , verbose : Optional [ int ] = None ): ''' Apply any schedule on an AST through a user callback Parameters ---------- ast : Func or Stmt The AST to schedule. If not specified, a partial function will be returned that cna be used as a decorator callback : Callable Specify what schedule(s) to do in this callback verbose : int (Optional) 0 = print nothing. 1 = print the final AST. 2 = print an AST after each schedule ''' if ast is not None : if callback is None : return ast if verbose is None : verbose = 0 s = Schedule ( ast , verbose = verbose ) callback ( s ) if ast . type () == ffi . ASTNodeType . Func : return s . func () else : return s . ast () else : f = schedule if callback is not None : f = functools . partial ( f , callback = callback ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f stmt Facility to build AST statements Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module. Classes and functions in this module are all in BigCamel naming style, to distinguish from expressions in expr.py Assert Scope used to create an Assert node This scope is internally used by transformer and tests E.g.: with Assert(i > 0): ... # Assertion body Source code in freetensor/core/stmt.py class Assert : ''' Scope used to create an Assert node This scope is internally used by `transformer` and tests E.g.: ``` with Assert(i > 0): ... # Assertion body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () nid = top . get_next_nid () top . append_stmt ( ffi . makeAssert ( nid , self . cond , body )) Else Scope used to create an else branch of an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # True branch with Else(): ... # Else branch Source code in freetensor/core/stmt.py class Else : ''' Scope used to create an else branch of an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # True branch with Else(): ... # Else branch ``` ''' def __init__ ( self ): pass def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_else_stmt ( body ) For Scope used to create a For node This scope is internally used by transformer and tests E.g.: with For('i', 0, n) as i: ... # Loop body Source code in freetensor/core/stmt.py class For : ''' Scope used to create a For node This scope is internally used by `transformer` and tests E.g.: ``` with For('i', 0, n) as i: ... # Loop body ``` ''' def __init__ ( self , iter_var : str , begin , end , step = 1 , nid : str = \"\" , no_deps : Optional [ Sequence [ str ]] = None , prefer_libs : Optional [ bool ] = None ): self . iter_var = iter_var self . begin = begin self . end = end self . step = step self . nid = nid self . no_deps = no_deps self . prefer_libs = prefer_libs self . borrowed_vardefs = set () for x in [ begin , end , step ]: for name in ffi . all_reads ( ffi . Expr ( x )): self . borrowed_vardefs . add ( open_vardefs [ name ]) def __enter__ ( self ): for item in self . borrowed_vardefs : item . lend_out () ctx_stack . push () return ffi . makeVar ( self . iter_var ) def __exit__ ( self , exc_type , exc_value , traceback ): for item in self . borrowed_vardefs : item . reclaim () if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () top . append_for_stmt ( self . iter_var , self . begin , self . end , self . step , body , nid = self . nid , no_deps = self . no_deps , prefer_libs = self . prefer_libs ) If Scope used to create an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # Branch body Source code in freetensor/core/stmt.py class If : ''' Scope used to create an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # Branch body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_then_stmt ( self . cond , body ) NamedScope Scope used to create an StmtSeq node with an explicit ID E.g.: with NamedScope(): ... # body This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes Source code in freetensor/core/stmt.py class NamedScope : ''' Scope used to create an StmtSeq node with an explicit ID E.g.: ``` with NamedScope(): ... # body ``` This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes ''' def __init__ ( self , nid : str ): self . nid = nid def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt ( self . nid ) ctx_stack . top () . append_stmt ( body ) Any () Create an Any node (only for testing) Any nodes matches any statement nodes in ast.match Source code in freetensor/core/stmt.py def Any (): ''' Create an Any node (only for testing) Any nodes matches any statement nodes in `ast.match` ''' ctx_stack . top () . append_stmt ( ffi . makeAny ()) Eval ( expr ) Create an Eval node This scope is internally used by transformer and tests Source code in freetensor/core/stmt.py def Eval ( expr ): ''' Create an Eval node This scope is internally used by `transformer` and tests ''' top = ctx_stack . top () top . append_stmt ( ffi . makeEval ( top . get_next_nid (), expr )) Invoke ( func , * args , ** kvs ) Inlined invocation of another AST This scope is internally used by transformer and tests Invoke can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use inline in transformer instead, which supports generic types Source code in freetensor/core/stmt.py def Invoke ( func , * args , ** kvs ): ''' Inlined invocation of another AST This scope is internally used by `transformer` and tests `Invoke` can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use `inline` in `transformer` instead, which supports generic types ''' top = ctx_stack . top () top . append_stmt ( ffi . inlined_invoke ( top . get_next_nid (), func , args , kvs )) MarkNid ( nid ) Mark the ID of the following statement This scope is internally used by transformer and tests Source code in freetensor/core/stmt.py def MarkNid ( nid : str ): \"\"\" Mark the ID of the following statement This scope is internally used by `transformer` and tests \"\"\" ctx_stack . top () . set_next_nid ( nid ) VarDef ( * args ) A factory function that creates a VarDef or a series of nested VarDef s This scope is internally used by transformer and tests Source code in freetensor/core/stmt.py def VarDef ( * args ): ''' A factory function that creates a VarDef or a series of nested `VarDef`s This scope is internally used by `transformer` and tests ''' if len ( args ) == 1 : return _VarsDef ( args [ 0 ]) else : return _VarDef ( * args ) transformer Transform user Python functions to ASTs via generating staging functions. FunctionScope dataclass FunctionScope(filename: str, funcname: str) Source code in freetensor/core/transformer.py @dataclass class FunctionScope : filename : str funcname : str def __enter__ ( self ): StagingContext . call_stack . append ( traceback . FrameSummary ( self . filename , 1 , self . funcname )) StagingContext . allow_return_stack . append ( True ) def __exit__ ( self , exc_class , exc_value , traceback ): if exc_class is None : StagingContext . call_stack . pop () StagingContext . allow_return_stack . pop () NamingScope ( FunctionScope ) dataclass Source code in freetensor/core/transformer.py class NamingScope ( FunctionScope ): def __init__ ( self , filename : str , funcname : str , namespace : Optional [ str ]) -> None : super () . __init__ ( filename , funcname ) if len ( StagingContext . id_stack ) > 0 and namespace is None : raise StagingError ( 'Namespace must not be None for inner levels.' ) self . namespace = namespace self . ids = {} def __enter__ ( self ): super () . __enter__ () StagingContext . id_stack . append ( self ) def __exit__ ( self , _1 , _2 , _3 ): super () . __exit__ ( _1 , _2 , _3 ) popped = StagingContext . id_stack . pop () if popped != self : raise StagingError ( 'NamingScope enter/exit not match, must be FILO' ) def fullid ( self , nid : str ): if self . namespace is not None : prefix = self . namespace + '->' else : prefix = '' if nid in self . ids : suffix = '$' + str ( self . ids [ nid ]) self . ids [ nid ] += 1 else : suffix = '' self . ids [ nid ] = 1 return prefix + nid + suffix __init__ ( self , filename , funcname , namespace ) special Initialize self. See help(type(self)) for accurate signature. Source code in freetensor/core/transformer.py def __init__ ( self , filename : str , funcname : str , namespace : Optional [ str ]) -> None : super () . __init__ ( filename , funcname ) if len ( StagingContext . id_stack ) > 0 and namespace is None : raise StagingError ( 'Namespace must not be None for inner levels.' ) self . namespace = namespace self . ids = {} PredefinedVarCreator ( VarCreator ) dataclass Source code in freetensor/core/transformer.py class PredefinedVarCreator ( VarCreator ): def __init__ ( self , initializer : List [ Any ], dtype : str , mtype : str ): def get_shape ( lst ): if not isinstance ( lst , list ): assert ndim ( lst ) == 0 return () if len ( lst ) == 0 : return ( 0 ,) shape_ = get_shape ( lst [ 0 ]) for x in lst [ 1 :]: assert shape_ == get_shape ( x ) return ( len ( lst ),) + shape_ super () . __init__ ( get_shape ( initializer ), dtype , mtype ) self . initializer = initializer def assign ( self , name : str ) -> VarRef : var = super () . assign ( name ) def impl ( var_slice , init_slice ): if not isinstance ( init_slice , list ): var_slice [()] = init_slice else : for i , x in enumerate ( init_slice ): impl ( var_slice [ i ], x ) impl ( var , self . initializer ) return var __class__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) __init__ ( self , initializer , dtype , mtype ) special Initialize self. See help(type(self)) for accurate signature. Source code in freetensor/core/transformer.py def __init__ ( self , initializer : List [ Any ], dtype : str , mtype : str ): def get_shape ( lst ): if not isinstance ( lst , list ): assert ndim ( lst ) == 0 return () if len ( lst ) == 0 : return ( 0 ,) shape_ = get_shape ( lst [ 0 ]) for x in lst [ 1 :]: assert shape_ == get_shape ( x ) return ( len ( lst ),) + shape_ super () . __init__ ( get_shape ( initializer ), dtype , mtype ) self . initializer = initializer assign ( self , name ) Customized assign behavior. Creates a VarDef with its full name. Source code in freetensor/core/transformer.py def assign ( self , name : str ) -> VarRef : var = super () . assign ( name ) def impl ( var_slice , init_slice ): if not isinstance ( init_slice , list ): var_slice [()] = init_slice else : for i , x in enumerate ( init_slice ): impl ( var_slice [ i ], x ) impl ( var , self . initializer ) return var StagedAssignable ( ABC ) Source code in freetensor/core/transformer.py class StagedAssignable ( abc . ABC ): @abc . abstractmethod def assign ( self , name : str ) -> VarRef : raise NotImplementedError () __class__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) StagedPredicate ( ABC ) Source code in freetensor/core/transformer.py class StagedPredicate ( abc . ABC ): @abc . abstractmethod def if_then_else_stmt ( self , then_body : Callable [[], None ], else_body : Optional [ Callable [[], None ]]): raise NotImplementedError () @abc . abstractmethod def if_then_else_expr ( self , then_expr : Callable [[], Any ], else_expr : Callable [[], Any ]): raise NotImplementedError () @abc . abstractmethod def while_stmt ( self , body : Callable [[], None ]): raise NotImplementedError () __class__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) StagedTypeAnnotation Source code in freetensor/core/transformer.py class StagedTypeAnnotation ( metaclass = StagedTypeAnnotationMeta ): @abc . abstractmethod def annotate ( self , name : str ) -> VarRef : raise NotImplementedError () __class__ ( ABCMeta ) inherited Source code in freetensor/core/transformer.py class StagedTypeAnnotationMeta ( abc . ABCMeta ): def __getitem__ ( self , args ): return self ( * args ) __base__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) register ( cls , subclass ) inherited Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) StagedTypeAnnotationMeta ( ABCMeta ) Source code in freetensor/core/transformer.py class StagedTypeAnnotationMeta ( abc . ABCMeta ): def __getitem__ ( self , args ): return self ( * args ) __base__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) register ( cls , subclass ) inherited Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) StagingContext Helper class managing context in IR staging. Source code in freetensor/core/transformer.py class StagingContext : '''Helper class managing context in IR staging.''' id_stack : List [ NamingScope ] = [] lifetime_stack : List [ LifetimeScope ] = [] allow_return_stack : List [ bool ] = [] closure : Dict [ str , Any ] = {} call_stack : List [ traceback . FrameSummary ] = [] name_dict : Dict [ str , int ] = {} @staticmethod def register_implicit_scope ( scope ): return StagingContext . lifetime_stack [ - 1 ] . register_implicit_scope ( scope ) @staticmethod def fullid ( nid : str ) -> str : '''Get namespace-prepended full nid of given short nid.''' return StagingContext . id_stack [ - 1 ] . fullid ( nid ) @staticmethod def fullname ( name : str ) -> str : '''Get distinct name.''' if name in StagingContext . name_dict : StagingContext . name_dict [ name ] += 1 return f ' { name } _ { StagingContext . name_dict [ name ] } ' else : StagingContext . name_dict [ name ] = 0 return name @staticmethod def allow_return (): return StagingContext . allow_return_stack [ - 1 ] @staticmethod def in_staging (): return len ( StagingContext . lifetime_stack ) > 0 @staticmethod def reset (): StagingContext . id_stack . clear () StagingContext . lifetime_stack . clear () StagingContext . closure = {} StagingContext . call_stack = [] StagingContext . name_dict = {} fullid ( nid ) staticmethod Get namespace-prepended full nid of given short nid. Source code in freetensor/core/transformer.py @staticmethod def fullid ( nid : str ) -> str : '''Get namespace-prepended full nid of given short nid.''' return StagingContext . id_stack [ - 1 ] . fullid ( nid ) fullname ( name ) staticmethod Get distinct name. Source code in freetensor/core/transformer.py @staticmethod def fullname ( name : str ) -> str : '''Get distinct name.''' if name in StagingContext . name_dict : StagingContext . name_dict [ name ] += 1 return f ' { name } _ { StagingContext . name_dict [ name ] } ' else : StagingContext . name_dict [ name ] = 0 return name StagingError ( Exception ) Error occurred during staging function execution (i.e. IR tree generation). Source code in freetensor/core/transformer.py class StagingError ( Exception ): '''Error occurred during staging function execution (i.e. IR tree generation).''' def __init__ ( self , message : str ) -> None : # TODO: add output of StagingContext.call_stack super () . __init__ ( f ' { message } : \\n { \"\" . join ( traceback . format_list ( StagingContext . call_stack [ 1 :])) } ' . lstrip ()) TransformError ( Exception ) Error occurred during AST transforming from python function to staging function that generates IR tree. Source code in freetensor/core/transformer.py class TransformError ( Exception ): '''Error occurred during AST transforming from python function to staging function that generates IR tree.''' def __init__ ( self , message : str , filename : str , base_lineno : int , error_node : ast . AST ) -> None : super () . __init__ ( f 'At { filename } : { base_lineno + error_node . lineno } : \\n { message } .' ) Transformer ( NodeTransformer ) dataclass Transformer(filename: str, base_lineno: int, curr_func: str = None, nonlocals: List[List[str]] = None) Source code in freetensor/core/transformer.py @dataclass class Transformer ( ast . NodeTransformer ): filename : str base_lineno : int curr_func : str = None nonlocals : List [ List [ str ]] = None def visit ( self , node : ast . AST ): new_node = super () . visit ( node ) if isinstance ( node , ast . stmt ) and not isinstance ( node , ast . FunctionDef ): if not isinstance ( new_node , list ): new_node = [ new_node ] return location_helper ([ ast . Expr ( call_helper ( mark_position , ast . Constant ( self . base_lineno ), ast . Constant ( node . lineno ))) ] + new_node , node ) return new_node def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = assign('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = assign('lhs', rhs)` ''' node : ast . Assign = self . generic_visit ( old_node ) # FIXME: multi-assign not implemented if len ( node . targets ) == 1 and ( isinstance ( node . targets [ 0 ], ast . Name ) or isinstance ( node . targets [ 0 ], ast . Attribute )): name = None if isinstance ( node . targets [ 0 ], ast . Name ): name = node . targets [ 0 ] . id elif isinstance ( node . targets [ 0 ], ast . Attribute ): name = node . targets [ 0 ] . attr if name is not None : node = ast . Assign ( node . targets , call_helper ( assign_stmt , ast . Constant ( name ), node . value )) return location_helper ( node , old_node ) def handleType_AnnAssign ( self , node : ast . AnnAssign ) -> Any : x = node . target assert isinstance ( x , ast . Name ) assert node . value is None x_str = ast . Constant ( x . id ) Ty = node . annotation intermediate = f 'freetensor__annotate__ { x . id } ' intermediate_store = ast . Name ( intermediate , ast . Store ()) intermediate_load = ast . Name ( intermediate , ast . Load ()) node = [ ast . Assign ([ intermediate_store ], call_helper ( annotate_stmt , x_str , Ty )), ast . If ( intermediate_load , [ ast . Assign ([ x ], intermediate_load )], []) ] return node def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if isinstance ( old_node . target , ast . Name ) and len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # while opening a fake function, For loops initiates an iter name as well. # need to remove it from the outer nonlocals list to implement shadowing. # only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) if old_node . target . id in nonlocals : nonlocals . remove ( old_node . target . id ) nonlocals = list ( nonlocals ) node = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ node . target . id ], node . body , nonlocals ), ast . Expr ( call_helper ( foreach , ast . Constant ( node . target . id ), node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return location_helper ( node , old_node ) def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( while_stmt , ast . Lambda ( _empty_args , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return location_helper ( node , old_node ) def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( if_then_else_stmt , test , then_body , else_body ))) return location_helper ( new_node , old_node ) def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( if_then_else_expr , node . test , ast . Lambda ( _empty_args , node . body ), ast . Lambda ( _empty_args , node . orelse )) return location_helper ( node , old_node ) def visit_FunctionDef ( self , old_node : ast . FunctionDef ) -> Any : prev_func = self . curr_func self . curr_func = old_node . name # nested functions follow original Python (shitty) scoping, # thus backup the nonlocals stack and prepare a clean one. prev_nonlocals = self . nonlocals self . nonlocals = None with NonlocalTransformingScope ( self ): # mark arguments as nonlocal for name in old_node . args . args + old_node . args . kwonlyargs : self . nonlocals [ - 1 ] . append ( name . arg ) if old_node . args . vararg : self . nonlocals [ - 1 ] . append ( old_node . args . vararg . arg ) if old_node . args . kwarg : self . nonlocals [ - 1 ] . append ( old_node . args . kwarg . arg ) node : ast . FunctionDef = self . generic_visit ( old_node ) node . decorator_list = [] node . body = [ ast . With ( items = [ ast . withitem ( context_expr = call_helper ( functiondef_wrapper , ast . Constant ( self . filename ), ast . Constant ( node . name )), optional_vars = None ) ], body = [ stmt for arg in node . args . posonlyargs + node . args . args if arg . annotation for stmt in self . handleType_AnnAssign ( location_helper ( ast . AnnAssign ( ast . Name ( arg . arg , ast . Store ( )), arg . annotation , None , 1 ), old_node )) ] + node . body ) ] for arg in [ node . args . vararg , node . args . kwarg ] + node . args . posonlyargs + node . args . args + node . args . kwonlyargs : if arg is not None : arg . annotation = None self . curr_func = prev_func self . nonlocals = prev_nonlocals return location_helper ( node , old_node ) def visit_Assert ( self , old_node : ast . Assert ) -> Any : node : ast . Assert = self . generic_visit ( old_node ) node = ast . Expr ( call_helper ( assert_stmt , node . test )) return location_helper ( node , old_node ) def visit_BoolOp ( self , old_node : ast . BoolOp ) -> Any : node : ast . BoolOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . And ): libfunc = and_expr elif isinstance ( node . op , ast . Or ): libfunc = or_expr else : return location_helper ( node , old_node ) node = call_helper ( libfunc , * [ ast . Lambda ( _empty_args , v ) for v in node . values ]) return location_helper ( node , old_node ) def visit_UnaryOp ( self , old_node : ast . UnaryOp ) -> Any : node : ast . UnaryOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . Not ): node = call_helper ( not_expr , node . operand ) return location_helper ( node , old_node ) def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( location_helper ( node , old_node )) def visit_Attribute ( self , old_node : ast . Attribute ) -> Any : node : ast . Attribute = self . generic_visit ( old_node ) if isinstance ( node . ctx , ast . Load ): node = call_helper ( load_attr , node . value , ast . Constant ( node . attr )) return location_helper ( node , old_node ) def visit_Return ( self , old_node : ast . Return ) -> Any : node : ast . Return = self . generic_visit ( old_node ) assert self . curr_func is not None node = ast . Return ( call_helper ( return_stmt , node . value , ast . Constant ( self . curr_func ))) return location_helper ( node , old_node ) def visit_Lambda ( self , old_node : ast . Lambda ) -> Any : with NonlocalTransformingScope ( self ): node : ast . Lambda = self . generic_visit ( old_node ) return location_helper ( node , old_node ) def visit_comprehension ( self , old_node : ast . comprehension ) -> Any : with NonlocalTransformingScope ( self ): node : ast . comprehension = self . generic_visit ( old_node ) return location_helper ( node , old_node ) def visit_Name ( self , node : ast . Name ) -> Any : if isinstance ( node . ctx , ast . Store ): self . nonlocals [ - 1 ] . append ( node . id ) return self . generic_visit ( node ) def visit_AsyncFunctionDef ( self , node : ast . AsyncFunctionDef ) -> Any : raise TransformError ( 'Async functions not supported.' , self . filename , self . base_lineno , node ) def visit_ClassDef ( self , node : ast . ClassDef ) -> Any : raise TransformError ( 'Class definitions not supported.' , self . filename , self . base_lineno , node ) generic_visit ( self , node ) inherited Called if no explicit visitor function exists for a node. Source code in freetensor/core/transformer.py def generic_visit ( self , node ): for field , old_value in iter_fields ( node ): if isinstance ( old_value , list ): new_values = [] for value in old_value : if isinstance ( value , AST ): value = self . visit ( value ) if value is None : continue elif not isinstance ( value , AST ): new_values . extend ( value ) continue new_values . append ( value ) old_value [:] = new_values elif isinstance ( old_value , AST ): new_node = self . visit ( old_value ) if new_node is None : delattr ( node , field ) else : setattr ( node , field , new_node ) return node visit ( self , node ) Visit a node. Source code in freetensor/core/transformer.py def visit ( self , node : ast . AST ): new_node = super () . visit ( node ) if isinstance ( node , ast . stmt ) and not isinstance ( node , ast . FunctionDef ): if not isinstance ( new_node , list ): new_node = [ new_node ] return location_helper ([ ast . Expr ( call_helper ( mark_position , ast . Constant ( self . base_lineno ), ast . Constant ( node . lineno ))) ] + new_node , node ) return new_node visit_AnnAssign ( self , old_node ) Rule: x: Ty -> freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x : pure annotation Source code in freetensor/core/transformer.py def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node visit_Assign ( self , old_node ) Rule: lhs = rhs -> lhs = assign('lhs', rhs) x.lhs = rhs -> x.lhs = assign('lhs', rhs) Source code in freetensor/core/transformer.py def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = assign('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = assign('lhs', rhs)` ''' node : ast . Assign = self . generic_visit ( old_node ) # FIXME: multi-assign not implemented if len ( node . targets ) == 1 and ( isinstance ( node . targets [ 0 ], ast . Name ) or isinstance ( node . targets [ 0 ], ast . Attribute )): name = None if isinstance ( node . targets [ 0 ], ast . Name ): name = node . targets [ 0 ] . id elif isinstance ( node . targets [ 0 ], ast . Attribute ): name = node . targets [ 0 ] . attr if name is not None : node = ast . Assign ( node . targets , call_helper ( assign_stmt , ast . Constant ( name ), node . value )) return location_helper ( node , old_node ) visit_Compare ( self , old_node ) Expand multiple comparison into and expression. Source code in freetensor/core/transformer.py def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( location_helper ( node , old_node )) visit_For ( self , old_node ) Rule: for x in iter: body -> def for_body(x): body foreach('x', iter, for_body) Source code in freetensor/core/transformer.py def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if isinstance ( old_node . target , ast . Name ) and len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # while opening a fake function, For loops initiates an iter name as well. # need to remove it from the outer nonlocals list to implement shadowing. # only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) if old_node . target . id in nonlocals : nonlocals . remove ( old_node . target . id ) nonlocals = list ( nonlocals ) node = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ node . target . id ], node . body , nonlocals ), ast . Expr ( call_helper ( foreach , ast . Constant ( node . target . id ), node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return location_helper ( node , old_node ) visit_If ( self , old_node ) Rule: if pred: body else: orelse -> def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) Source code in freetensor/core/transformer.py def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( if_then_else_stmt , test , then_body , else_body ))) return location_helper ( new_node , old_node ) visit_IfExp ( self , old_node ) Rule: body if test else orelse -> if_then_else_expr(test, body, orelse) Source code in freetensor/core/transformer.py def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( if_then_else_expr , node . test , ast . Lambda ( _empty_args , node . body ), ast . Lambda ( _empty_args , node . orelse )) return location_helper ( node , old_node ) visit_While ( self , old_node ) Rule: while pred: body -> def while_body(): body while_stmt(lambda: pred, while_body) Source code in freetensor/core/transformer.py def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( while_stmt , ast . Lambda ( _empty_args , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return location_helper ( node , old_node ) Var ( StagedTypeAnnotation ) Source code in freetensor/core/transformer.py class Var ( StagedTypeAnnotation ): def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype def annotate ( self , name : str ) -> VarRef : return StagingContext . register_implicit_scope ( _VarDef ( prepare_vardef ( name ), self . shape , self . dtype , self . atype , self . mtype )) __class__ ( ABCMeta ) inherited Source code in freetensor/core/transformer.py class StagedTypeAnnotationMeta ( abc . ABCMeta ): def __getitem__ ( self , args ): return self ( * args ) __base__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) register ( cls , subclass ) inherited Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) __init__ ( self , shape , dtype , atype = 'input' , mtype = None ) special Declare a variable Parameters: name ( str ) \u2013 Name of the variable shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable atype ( str or AccessType ) \u2013 Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Source code in freetensor/core/transformer.py def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype VarCreator ( StagedAssignable ) dataclass VarCreator(shape: Union[Sequence, freetensor.core.expr.VarRef], dtype: str, mtype: str) Source code in freetensor/core/transformer.py @dataclass class VarCreator ( StagedAssignable ): shape : Union [ Sequence , VarRef ] dtype : str mtype : str def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' return StagingContext . register_implicit_scope ( _VarDef ( prepare_vardef ( name ), self . shape , self . dtype , 'cache' , self . mtype )) __class__ ( type ) inherited Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) assign ( self , name ) Customized assign behavior. Creates a VarDef with its full name. Source code in freetensor/core/transformer.py def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' return StagingContext . register_implicit_scope ( _VarDef ( prepare_vardef ( name ), self . shape , self . dtype , 'cache' , self . mtype )) dynamic_range ( StagedIterable ) Dynamic range that generates For loop in IR tree. Source code in freetensor/core/transformer.py class dynamic_range ( StagedIterable ): '''Dynamic range that generates For loop in IR tree.''' def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step def foreach ( self , name : str , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' with For ( StagingContext . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var ) __init__ ( self , start , stop = None , step = 1 ) special Initialize a dynamic range. Arguments semantic identical to builtin range . Source code in freetensor/core/transformer.py def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step foreach ( self , name , body ) Customized foreach behavior. Creates a For loop. Source code in freetensor/core/transformer.py def foreach ( self , name : str , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' with For ( StagingContext . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var ) assert_stmt ( test ) Assert staging tool. Source code in freetensor/core/transformer.py def assert_stmt ( test ): '''Assert staging tool.''' if isinstance ( test , ffi . Expr ): StagingContext . register_implicit_scope ( Assert ( test )) else : assert test assign_stmt ( name , value ) Customized assign wrapper. If value is instance of StagedAssignable , it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. Source code in freetensor/core/transformer.py def assign_stmt ( name : str , value ): '''Customized assign wrapper. If `value` is instance of `StagedAssignable`, it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. ''' if isinstance ( value , StagedAssignable ): return value . assign ( name ) else : return value call_helper ( callee , * args , ** kwargs ) Call helper that generates a python AST Call node with given callee and arguments AST node. Source code in freetensor/core/transformer.py def call_helper ( callee , * args : ast . expr , ** kwargs : ast . expr ): '''Call helper that generates a python AST Call node with given callee and arguments AST node.''' return ast . Call ( module_helper ( callee ), list ( args ), [ ast . keyword ( k , w ) for k , w in kwargs . items ()]) capture_var ( * args , ** kwargs ) Capture external array as tensor variable. Source code in freetensor/core/transformer.py def impl ( * args , ** kwargs ): if StagingContext . in_staging (): return staging ( * args , ** kwargs ) else : return original ( * args , ** kwargs ) empty ( * args , ** kwargs ) Create an empty variable Parameters: shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Source code in freetensor/core/transformer.py def impl ( * args , ** kwargs ): if StagingContext . in_staging (): return staging ( * args , ** kwargs ) else : return original ( * args , ** kwargs ) foreach ( name , iter , body ) Customized foreach wrapper. If value is instance of StagedIterable , its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. Source code in freetensor/core/transformer.py def foreach ( name : str , iter , body : Callable [[ Any ], None ]) -> None : '''Customized foreach wrapper. If `value` is instance of `StagedIterable`, its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. ''' if isinstance ( iter , StagedIterable ): iter . foreach ( name , body ) else : for iter_var in iter : body ( iter_var ) function_helper ( name , args , body , nonlocals ) Function helper that generates a python AST FunctionDef node with given name, arguments name, and body. Source code in freetensor/core/transformer.py def function_helper ( name : str , args : Sequence [ str ], body : List [ ast . stmt ], nonlocals : List [ str ]): '''Function helper that generates a python AST FunctionDef node with given name, arguments name, and body.''' nonlocal_body = ([ ast . Nonlocal ( nonlocals )] if len ( nonlocals ) > 0 else []) + body return ast . FunctionDef ( name = name , args = ast . arguments ( args = [], vararg = None , kwarg = None , posonlyargs = [ ast . arg ( a , None ) for a in args ], defaults = [], kwonlyargs = [], kw_defaults = []), body = nonlocal_body , returns = None , decorator_list = []) if_then_else_expr ( predicate , then_expr , else_expr ) If-then-else expression staging tool. Source code in freetensor/core/transformer.py def if_then_else_expr ( predicate , then_expr , else_expr ): '''If-then-else expression staging tool.''' if isinstance ( predicate , StagedPredicate ): return predicate . if_then_else_expr ( then_expr , else_expr ) else : if predicate : return then_expr () else : return else_expr () if_then_else_stmt ( predicate , then_body , else_body = None ) If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. Source code in freetensor/core/transformer.py def if_then_else_stmt ( predicate , then_body , else_body = None ): '''If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. ''' if isinstance ( predicate , StagedPredicate ): predicate . if_then_else_stmt ( then_body , else_body ) else : if predicate : then_body () elif else_body : else_body () inline ( func = None , src = None , fallback = None , default_dynamic_range = True , verbose = False ) Enable a user function to be called by a transformed function at run time Parameters: func ( Python function ) \u2013 The user function src ( str (Optional) ) \u2013 The source code of func . This parameter is only required if the source code cannot be get automatically, e.g., if func is generated from a exec default_dynamic_range ( bool ) \u2013 If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose ( bool ) \u2013 True to print the generated Python code that is used for transforming Source code in freetensor/core/transformer.py def inline ( func = None , src = None , fallback = None , default_dynamic_range = True , verbose = False ): ''' Enable a user function to be called by a transformed function at run time Parameters ---------- func : Python function The user function src : str (Optional) The source code of `func`. This parameter is only required if the source code cannot be get automatically, e.g., if `func` is generated from a `exec` default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : bool True to print the generated Python code that is used for transforming ''' extra_locals = _prepare_extra_locals ( default_dynamic_range ) def decorator ( func ): return functools . wraps ( func )( staged_callable ( into_staging ( func , extra_locals , src , verbose = verbose )[ 0 ], fallback or func )) if callable ( func ): return decorator ( func ) else : return decorator load_attr ( obj , attr ) Load attribute staging tool. Allows customization of reading attributes. Source code in freetensor/core/transformer.py def load_attr ( obj , attr : str ): '''Load attribute staging tool. Allows customization of reading attributes.''' try : return getattr ( obj , attr ) except AttributeError : if attr == \"ndim\" : return ndim ( obj ) if attr == \"shape\" : return lambda i = None : shape ( obj , i ) if attr == \"dtype\" : return dtype ( obj ) if attr == \"mtype\" : return mtype ( obj ) raise module_helper ( callee ) Helper to get an AST node with full path to given symbol, which should be in current module. Source code in freetensor/core/transformer.py def module_helper ( callee ): '''Helper to get an AST node with full path to given symbol, which should be in current module.''' return ast . Attribute ( ast . Attribute ( ast . Name ( '__ft__' , ast . Load ()), 'transformer' , ast . Load ()), callee . __name__ , ast . Load ()) return_stmt ( value , funcname ) Return staging tool. Only allow return in static control flow. Source code in freetensor/core/transformer.py def return_stmt ( value , funcname ): '''Return staging tool. Only allow return in static control flow.''' if not StagingContext . allow_return (): raise StagingError ( 'Return is only allowed in statically deterministic control flow.' ) if isinstance ( value , StagedAssignable ): value = value . assign ( funcname ) return value transform ( func = None , default_dynamic_range = True , verbose = 0 ) Transform a user function to an AST Parameters: func ( Python function ) \u2013 The user function to transform. If not specified, a partial function will be returend, which can be used as a decorator default_dynamic_range ( bool ) \u2013 If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose ( int ) \u2013 0 = print nothing. 1 = print the resulting AST. 2 = 1 + print the generated Python code that is used for transforming Source code in freetensor/core/transformer.py def transform ( func = None , default_dynamic_range = True , verbose : int = 0 ): ''' Transform a user function to an AST Parameters ---------- func : Python function The user function to transform. If not specified, a partial function will be returend, which can be used as a decorator default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int 0 = print nothing. 1 = print the resulting AST. 2 = 1 + print the generated Python code that is used for transforming ''' if verbose is None : verbose = 0 extra_locals = _prepare_extra_locals ( default_dynamic_range ) def decorator ( func ): params = list ( inspect . signature ( func ) . parameters ) staging_func , filename , funcname = into_staging ( func , extra_locals , verbose = verbose >= 2 ) try : with LifetimeScope (): with NamingScope ( filename , funcname , None ): # for p in params: # StagingContext.id_stack[-1].ids[p] = 1 # StagingContext.name_dict[p] = 0 returns = staging_func ( * params ) if isinstance ( returns , VarRef ): returns = [ returns ] elif isinstance ( returns , tuple ): for ret in returns : if not isinstance ( ret , VarRef ): raise StagingError ( 'Illegal return at top level, need to be a `VarRef` or a tuple of `VarRef`s' ) returns = list ( returns ) elif returns is None : returns = [] else : raise StagingError ( 'Illegal return at top level, need to be a `VarRef` or a tuple of `VarRef`s' ) for ret in returns : if ret . vardef . atype == 'input' or ret . vardef . atype == 'inout' : ret . vardef . set_atype ( 'inout' ) else : ret . vardef . set_atype ( 'output' ) returns = [ ( ret . vardef . name , ret . vardef . dtype ) for ret in returns ] closure = StagingContext . closure except Exception as e : raise StagingError ( 'Exception occurred in staging' ) from e finally : StagingContext . reset () staged_ast = pop_ast () staged = Func ( func . __name__ , params + list ( closure . keys ()), returns , staged_ast , closure ) if verbose >= 1 : print ( \"The transformed AST is:\" , file = sys . stderr ) print ( staged , file = sys . stderr ) print ( file = sys . stderr ) return staged if callable ( func ): return decorator ( func ) else : return decorator var ( * args , ** kwargs ) Create an with variable a given initializer Parameters: initializer ( Sequence[Sequence[...Sequence[Expr]...]] ) \u2013 (Multi-level of) sequence of expressions. Will be data of the variable shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Source code in freetensor/core/transformer.py def impl ( * args , ** kwargs ): if StagingContext . in_staging (): return staging ( * args , ** kwargs ) else : return original ( * args , ** kwargs ) while_stmt ( fpred , body ) While statement staging tool. Source code in freetensor/core/transformer.py def while_stmt ( fpred , body ): '''While statement staging tool.''' first_pred = fpred () if isinstance ( first_pred , StagedPredicate ): first_pred . while_stmt ( body ) else : if first_pred : body () while fpred (): body () libop special assign add_to ( * _args , ** _kvs ) (Broadcasted) add to a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) assign ( * _args , ** _kvs ) (Broadcasted) assign to a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) floordiv_to ( * _args , ** _kvs ) (Broadcasted) rounding-towards-negative-infinity integer division (following Python convention, but not C) from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) mod_to ( * _args , ** _kvs ) (Broadcasted) modulo (results are non-negative, following Python convention, but not C) from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) mul_to ( * _args , ** _kvs ) (Broadcasted) multiply to a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sub_to ( * _args , ** _kvs ) (Broadcasted) subtract from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) truediv_to ( * _args , ** _kvs ) (Broadcasted) floating-point division from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) constant zeros ( shape , dtype , mtype = None ) Create a zero tensor Parameters: shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Returns: The zero tensor Source code in freetensor/libop/constant.py @core . inline def zeros ( shape , dtype , mtype = None ): ''' Create a zero tensor Parameters ---------- shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Returns ------- VarRef : The zero tensor ''' y = core . empty ( shape , dtype , mtype ) #! nid: recur zeros_ ( y ) return y zeros_ ( y ) Fill zeros to a tensor Parameters: y ( VarRef ) \u2013 The tensor to fill Source code in freetensor/libop/constant.py @core . inline def zeros_ ( y ): ''' Fill zeros to a tensor Parameters ---------- y : VarRef The tensor to fill ''' if core . ndim ( y ) == 0 : y [()] = 0 else : #! nid: L_elem for i in range ( core . shape ( y , 0 )): #! nid: recur zeros_ ( y [ i ]) conv conv ( X , W , B = None , auto_pad = 'NOTSET' , dilations = None , group = 1 , kernel_shape = None , pads = None , strides = None ) Convolution. The result is returned Parameters follow ONNX convention. Currently only 2-D convolution is supported Source code in freetensor/libop/conv.py @core . inline def conv ( X , W , B = None , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , group : int = 1 , kernel_shape : Optional [ Sequence [ int ]] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Convolution. The result is returned Parameters follow ONNX convention. Currently only 2-D convolution is supported ''' n_spatial_dim = 2 # Currently only 2-D convolution is supported (TODO) if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" dtype = core . up_cast ( X . dtype , W . dtype ) mtype = core . same_mtype ( X . mtype , W . mtype ) if B is not None : dtype = core . up_cast ( dtype , B . dtype ) mtype = core . same_mtype ( mtype , B . mtype ) #! nid: V_Y Y = core . empty ([ X . shape ( 0 ), W . shape ( 0 ), calc_out_size ( X . shape ( 2 ), dilations [ 0 ], W . shape ( 2 ), pads [ 0 ], pads [ 2 ], strides [ 0 ]), calc_out_size ( X . shape ( 3 ), dilations [ 1 ], W . shape ( 3 ), pads [ 1 ], pads [ 3 ], strides [ 1 ]) ], dtype , mtype ) #! nid: recur conv_ ( X , W , B , Y , auto_pad , dilations , group , kernel_shape , pads , strides ) return Y conv_ ( X , W , B , Y , auto_pad = 'NOTSET' , dilations = None , group = 1 , kernel_shape = None , pads = None , strides = None ) Convolution. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D convolution is supported Source code in freetensor/libop/conv.py @core . inline def conv_ ( X , W , B , Y , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , group : int = 1 , kernel_shape : Optional [ Sequence [ int ]] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Convolution. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D convolution is supported ''' n_spatial_dim = 2 # Currently only 2-D convolution is supported (TODO) if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" if B is None : # yapf: disable #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_g for g in range ( group ): #! nid: L_c_out for c_out in range ( W . shape ( 0 ) // group ): #! nid: L_h for h in range ( Y . shape ( 2 )): #! nid: L_w for w in range ( Y . shape ( 3 )): #! nid: init Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] = 0 #! nid: L_c_in for c_in in range ( W . shape ( 1 )): #! nid: L_kh for kh in range ( W . shape ( 2 )): #! nid: L_kw for kw in range ( W . shape ( 3 )): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! nid: compute Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] += X [ n , g * W . shape ( 1 ) + c_in , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] ] * W [ g * ( W . shape ( 0 ) // group ) + c_out , c_in , kh , kw ] # yapf: enable else : # yapf: disable #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_g for g in range ( group ): #! nid: L_c_out for c_out in range ( W . shape ( 0 ) // group ): #! nid: L_h for h in range ( Y . shape ( 2 )): #! nid: L_w for w in range ( Y . shape ( 3 )): #! nid: init Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] = B [ g * ( W . shape ( 0 ) // group ) + c_out ] #! nid: L_c_in for c_in in range ( W . shape ( 1 )): #! nid: L_kh for kh in range ( W . shape ( 2 )): #! nid: L_kw for kw in range ( W . shape ( 3 )): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! nid: compute Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] += X [ n , g * W . shape ( 1 ) + c_in , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] ] * W [ g * ( W . shape ( 0 ) // group ) + c_out , c_in , kh , kw ] # yapf: enable element_wise abs ( * _args , ** _kvs ) Element-wise absolute value of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) abs_ ( * _args , ** _kvs ) Element-wise absolute value of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) add ( * _args , ** _kvs ) (Broadcasted) element-wise addition of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) add_ ( * _args , ** _kvs ) (Broadcasted) element-wise addition of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ceil ( * _args , ** _kvs ) Element-wise ceil of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ceil_ ( * _args , ** _kvs ) Element-wise ceil of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ceildiv ( * _args , ** _kvs ) (Broadcasted) element-wise rounding-towards-positive-infinity integer division of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ceildiv_ ( * _args , ** _kvs ) (Broadcasted) element-wise rounding-towards-positive-infinity integer division of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) eq ( * _args , ** _kvs ) (Broadcasted) element-wise equal of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) eq_ ( * _args , ** _kvs ) (Broadcasted) element-wise equal of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) exp ( * _args , ** _kvs ) Element-wise natrual exponent of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) exp_ ( * _args , ** _kvs ) Element-wise natrual exponent of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) floor ( * _args , ** _kvs ) Element-wise floor of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) floor_ ( * _args , ** _kvs ) Element-wise floor of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) floordiv ( * _args , ** _kvs ) (Broadcasted) element-wise rounding-towards-negative-infinity integer division (following Python convention, but not C, recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) floordiv_ ( * _args , ** _kvs ) (Broadcasted) element-wise rounding-towards-negative-infinity integer division (following Python convention, but not C, recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ge ( * _args , ** _kvs ) (Broadcasted) element-wise greater-than-or-equal-to of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ge_ ( * _args , ** _kvs ) (Broadcasted) element-wise greater-than-or-equal-to of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) gt ( * _args , ** _kvs ) (Broadcasted) element-wise greater-than of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) gt_ ( * _args , ** _kvs ) (Broadcasted) element-wise greater-than of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) l_and ( * _args , ** _kvs ) (Broadcasted) element-wise logical and of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) l_and_ ( * _args , ** _kvs ) (Broadcasted) element-wise logical and of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) l_not ( * _args , ** _kvs ) Element-wise logical not of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) l_not_ ( * _args , ** _kvs ) Element-wise logical not of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) l_or ( * _args , ** _kvs ) (Broadcasted) element-wise logical or of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) l_or_ ( * _args , ** _kvs ) (Broadcasted) element-wise logical or of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) le ( * _args , ** _kvs ) (Broadcasted) element-wise less-than-or-equal-to of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) le_ ( * _args , ** _kvs ) (Broadcasted) element-wise less-than-or-equal-to of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) lt ( * _args , ** _kvs ) (Broadcasted) element-wise less-than of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) lt_ ( * _args , ** _kvs ) (Broadcasted) element-wise less-than of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) max ( * _args , ** _kvs ) (Broadcasted) element-wise maximum of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) max_ ( * _args , ** _kvs ) (Broadcasted) element-wise maximum of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) min ( * _args , ** _kvs ) (Broadcasted) element-wise minimum of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) min_ ( * _args , ** _kvs ) (Broadcasted) element-wise minimum of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) mod ( * _args , ** _kvs ) (Broadcasted) element-wise modulo (results are non-negative, following Python convention, but not C, recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) mod_ ( * _args , ** _kvs ) (Broadcasted) element-wise modulo (results are non-negative, following Python convention, but not C, recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) mul ( * _args , ** _kvs ) (Broadcasted) element-wise multiplication of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) mul_ ( * _args , ** _kvs ) (Broadcasted) element-wise multiplication of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ne ( * _args , ** _kvs ) (Broadcasted) element-wise non-equal of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) ne_ ( * _args , ** _kvs ) (Broadcasted) element-wise non-equal of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) neg ( * _args , ** _kvs ) Element-wise negation of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) neg_ ( * _args , ** _kvs ) Element-wise negation of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) relu ( * _args , ** _kvs ) Element-wise ReLU of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) relu_ ( * _args , ** _kvs ) Element-wise ReLU of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) remainder ( * _args , ** _kvs ) (Broadcasted) element-wise remainder (results can be positive or negative, following C convention, but not Python, NOT recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) remainder_ ( * _args , ** _kvs ) (Broadcasted) element-wise remainder (results can be positive or negative, following C convention, but not Python, NOT recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) round_towards_0_div ( * _args , ** _kvs ) (Broadcasted) element-wise rounding-towards-0 integer division (following C convention, but not Python, NOT recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) round_towards_0_div_ ( * _args , ** _kvs ) (Broadcasted) element-wise rounding-towards-0 integer division (following C convention, but not Python, NOT recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sigmoid ( * _args , ** _kvs ) Element-wise sigmoid of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sigmoid_ ( * _args , ** _kvs ) Element-wise sigmoid of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sqrt ( * _args , ** _kvs ) Element-wise square root of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sqrt_ ( * _args , ** _kvs ) Element-wise square root of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) square ( * _args , ** _kvs ) Element-wise square of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) square_ ( * _args , ** _kvs ) Element-wise square of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sub ( * _args , ** _kvs ) (Broadcasted) element-wise subtraction of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) sub_ ( * _args , ** _kvs ) (Broadcasted) element-wise subtraction of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) tanh ( * _args , ** _kvs ) Element-wise tanh of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) tanh_ ( * _args , ** _kvs ) Element-wise tanh of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) truediv ( * _args , ** _kvs ) (Broadcasted) element-wise floating-point division of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) truediv_ ( * _args , ** _kvs ) (Broadcasted) element-wise floating-point division of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) matmul einsum ( fmt , * args ) Einstein summation. The result is returned Parameters: fmt ( str ) \u2013 The format string. E.g. \"ik,kj->ij\" represents a matrix multiplcation args ( Sequence[VarRef] ) \u2013 All inputs arguments. E.g. if fmt is \"ik,kj->ij\" , it iterates axis i and k of args[0] , axis k and j of args[1] , axis i and j of the returned value Returns: The result tensor Source code in freetensor/libop/matmul.py @core . inline def einsum ( fmt : str , * args ): ''' Einstein summation. The result is returned Parameters ---------- fmt : str The format string. E.g. `\"ik,kj->ij\"` represents a matrix multiplcation args : Sequence[VarRef] All inputs arguments. E.g. if `fmt` is `\"ik,kj->ij\"`, it iterates axis `i` and `k` of `args[0]`, axis `k` and `j` of `args[1]`, axis `i` and `j` of the returned value Returns ------- VarRef : The result tensor ''' lefts , right = fmt . split ( '->' ) lefts = lefts . split ( ',' ) shapes = [] for v in right : offsets = [ left . find ( v ) for left in lefts ] iter_args , iter_offsets = zip ( * filter ( lambda x : x [ 1 ] != - 1 , zip ( args , offsets ))) assert len ( iter_args ) > 0 shapes . append ( iter_args [ 0 ] . shape ( iter_offsets [ 0 ])) # FIXME: compute dtype and mtype from every inputs Y = core . empty ( shapes , args [ 0 ] . dtype , args [ 0 ] . mtype ) einsum_ ( fmt , * args , Y ) return Y einsum_ ( fmt , * args ) Einstein summation. The result is written to the last argument Parameters: fmt ( str ) \u2013 The format string. E.g. \"ik,kj->ij\" represents a matrix multiplcation args ( Sequence[VarRef] ) \u2013 All arguments including inputs and the output. E.g. if fmt is \"ik,kj->ij\" , it iterates axis i and k of args[0] , axis k and j of args[1] , axis i and j of args[2] Source code in freetensor/libop/matmul.py @core . inline def einsum_ ( fmt : str , * args ): ''' Einstein summation. The result is written to the last argument Parameters ---------- fmt : str The format string. E.g. `\"ik,kj->ij\"` represents a matrix multiplcation args : Sequence[VarRef] All arguments including inputs and the output. E.g. if `fmt` is `\"ik,kj->ij\"`, it iterates axis `i` and `k` of `args[0]`, axis `k` and `j` of `args[1]`, axis `i` and `j` of `args[2]` ''' lefts , right = fmt . split ( '->' ) lefts = lefts . split ( ',' ) order = right for left in lefts : for idx in left : if idx not in order : order += idx _einsum_ ( lefts , right , order , True , * args ) gemm ( A , B , C = None , has_bias = False , trans_A = False , trans_B = False , alpha = 1.0 , beta = 1.0 ) General matrix multiplcation following BLAS convention and return the result It performs Y = alpha tr?(A) @ tr?(B) + C , where @ represents matrix multiplication, tr? represents an optional transposition Parameters: A ( VarRef ) \u2013 The left-hand-side operand of matrix multiplication B ( VarRef ) \u2013 The right-hand-side operand of matrix multiplication C ( VarRef (Optional) ) \u2013 The bias tensor trans_A ( bool ) \u2013 If true, transpose A . Defaults to False trans_B ( bool ) \u2013 If true, transpose B . Defaults to False alpha ( float ) \u2013 Coefficient of tr?(A) @ tr?(B) . Defaults to 1.0 beta ( float ) \u2013 Coefficient of C . Defaults to 1.0 Returns: The resulting tensor Source code in freetensor/libop/matmul.py @core . inline def gemm ( A , B , C = None , has_bias : bool = False , trans_A : bool = False , trans_B : bool = False , alpha : float = 1.0 , beta : float = 1.0 ): ''' General matrix multiplcation following BLAS convention and return the result It performs `Y = alpha tr?(A) @ tr?(B) + C`, where `@` represents matrix multiplication, `tr?` represents an optional transposition Parameters ---------- A : VarRef The left-hand-side operand of matrix multiplication B : VarRef The right-hand-side operand of matrix multiplication C : VarRef (Optional) The bias tensor trans_A : bool (Optional) If true, transpose `A`. Defaults to False trans_B : bool (Optional) If true, transpose `B`. Defaults to False alpha : Number (Optional) Coefficient of `tr?(A) @ tr?(B)`. Defaults to 1.0 beta : Number (Optional) Coefficient of `C`. Defaults to 1.0 Returns ------- VarRef : The resulting tensor ''' dtype = core . up_cast ( A . dtype , B . dtype ) mtype = core . same_mtype ( A . mtype , B . mtype ) if C is not None : dtype = core . up_cast ( dtype , C . dtype ) mtype = core . same_mtype ( mtype , C . mtype ) Y = core . empty ( _comp_shape ( A , B , trans_A , trans_B ), dtype , mtype ) #! nid: recur gemm_ ( A , B , C , Y , trans_A , trans_B , alpha , beta ) return Y gemm_ ( A , B , C , Y , trans_A = False , trans_B = False , alpha = 1.0 , beta = 1.0 ) General matrix multiplcation following BLAS convention. The result is written to an existing tensor It performs Y = alpha tr?(A) @ tr?(B) + C , where @ represents matrix multiplication, tr? represents an optional transposition Parameters: A ( VarRef ) \u2013 The left-hand-side operand of matrix multiplication B ( VarRef ) \u2013 The right-hand-side operand of matrix multiplication C ( VarRef (Optional) ) \u2013 The bias tensor Y ( VarRef ) \u2013 The resulting tensor trans_A ( bool ) \u2013 If true, transpose A . Defaults to False trans_B ( bool ) \u2013 If true, transpose B . Defaults to False alpha ( float ) \u2013 Coefficient of tr?(A) @ tr?(B) . Defaults to 1.0 beta ( float ) \u2013 Coefficient of C . Defaults to 1.0 Source code in freetensor/libop/matmul.py @core . inline def gemm_ ( A , B , C , Y , trans_A : bool = False , trans_B : bool = False , alpha : float = 1.0 , beta : float = 1.0 ): ''' General matrix multiplcation following BLAS convention. The result is written to an existing tensor It performs `Y = alpha tr?(A) @ tr?(B) + C`, where `@` represents matrix multiplication, `tr?` represents an optional transposition Parameters ---------- A : VarRef The left-hand-side operand of matrix multiplication B : VarRef The right-hand-side operand of matrix multiplication C : VarRef (Optional) The bias tensor Y : VarRef The resulting tensor trans_A : bool (Optional) If true, transpose `A`. Defaults to False trans_B : bool (Optional) If true, transpose `B`. Defaults to False alpha : Number (Optional) Coefficient of `tr?(A) @ tr?(B)`. Defaults to 1.0 beta : Number (Optional) Coefficient of `C`. Defaults to 1.0 ''' a_fmt = 'ki' if trans_A else 'ik' b_fmt = 'jk' if trans_B else 'kj' fmt = f \" { a_fmt } , { b_fmt } ->ij\" if C is None : #! nid: einsum einsum_ ( fmt , A , B , Y ) #! nid: mul_to mul_to ( Y , alpha ) else : #! nid: einsum einsum_ ( fmt , A , B , Y ) #! nid: mul_to mul_to ( Y , alpha ) #! nid: add_to add_to ( Y , mul ( beta , C )) matmul ( A , B ) Matrix multiplcation. The result is returned Parameters: A ( VarRef ) \u2013 The left-hand-side operand B ( VarRef ) \u2013 The right-hand-side operand Returns: The resulting tensor Source code in freetensor/libop/matmul.py @core . inline def matmul ( A , B ): ''' Matrix multiplcation. The result is returned Parameters ---------- A : VarRef The left-hand-side operand B : VarRef The right-hand-side operand Returns ------- VarRef : The resulting tensor ''' #! nid: einsum Y = einsum ( _make_matmul_fmt ( A . ndim , B . ndim ), A , B ) return Y matmul_ ( A , B , Y ) Matrix multiplcation. The result is written to an existing tensor Parameters: A ( VarRef ) \u2013 The left-hand-side operand B ( VarRef ) \u2013 The right-hand-side operand C ( VarRef ) \u2013 The resulting tensor Source code in freetensor/libop/matmul.py @core . inline def matmul_ ( A , B , Y ): ''' Matrix multiplcation. The result is written to an existing tensor Parameters ---------- A : VarRef The left-hand-side operand B : VarRef The right-hand-side operand C : VarRef The resulting tensor ''' #! nid: einsum einsum_ ( _make_matmul_fmt ( A . ndim , B . ndim ), A , B , Y ) pooling global_avg_pool ( X ) Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def global_avg_pool ( X ): ''' Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 )], X . dtype , X . mtype ) #! nid: recur global_avg_pool_ ( X , Y ) return Y global_avg_pool_ ( X , Y ) Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def global_avg_pool_ ( X , Y ): ''' Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_c for c in range ( X . shape ( 1 )): #! nid: init Y [ n , c ] = 0 #! nid: L_h for h in range ( X . shape ( 2 )): #! nid: L_w for w in range ( X . shape ( 3 )): #! nid: compute Y [ n , c ] += X [ n , c , h , w ] #! nid: flush Y [ n , c ] /= X . shape ( 2 ) * X . shape ( 3 ) max_pool ( X , auto_pad = 'NOTSET' , dilations = None , kernel_shape = None , pads = None , strides = None ) Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def max_pool ( X , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 ), calc_out_size ( X . shape ( 2 ), dilations [ 0 ], kernel_shape [ 0 ], pads [ 0 ], pads [ 2 ], strides [ 0 ]), calc_out_size ( X . shape ( 3 ), dilations [ 1 ], kernel_shape [ 1 ], pads [ 1 ], pads [ 3 ], strides [ 1 ]) ], X . dtype , X . mtype ) #! nid: recur max_pool_ ( X , Y , auto_pad , dilations , kernel_shape , pads , strides ) return Y max_pool_ ( X , Y , auto_pad = 'NOTSET' , dilations = None , kernel_shape = None , pads = None , strides = None ) Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def max_pool_ ( X , Y , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" # yapf: disable #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_c for c in range ( X . shape ( 1 )): #! nid: L_h for h in range ( Y . shape ( 2 )): #! nid: L_w for w in range ( Y . shape ( 3 )): #! nid: init Y [ n , c , h , w ] = core . min_value ( X . dtype ) #! nid: L_kh for kh in range ( kernel_shape [ 0 ]): #! nid: L_kw for kw in range ( kernel_shape [ 1 ]): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! nid: compute Y [ n , c , h , w ] = core . max ( Y [ n , c , h , w ], X [ n , c , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ]]) # yapf: enable reduction all ( * _args , ** _kvs ) Reduction of logical and of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) all_ ( * _args , ** _kvs ) Reduction of logical and of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) any ( * _args , ** _kvs ) Reduction of logical or of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) any_ ( * _args , ** _kvs ) Reduction of logical or of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) reduce_max ( x , axes , keepdims = True ) Maximum of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py @core . inline def reduce_max ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! nid: impl y = _general_reduce ( core . max , core . min_value ( core . dtype ( x )), x , axes , keepdims ) return y reduce_max_ ( x , y , axes , keepdims = True ) Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py @core . inline def reduce_max_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! nid: impl _general_reduce_ ( core . max , core . min_value ( core . dtype ( x )), x , y , axes , keepdims ) reduce_min ( x , axes , keepdims = True ) Minimum of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py @core . inline def reduce_min ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! nid: impl y = _general_reduce ( core . min , core . max_value ( core . dtype ( x )), x , axes , keepdims ) return y reduce_min_ ( x , y , axes , keepdims = True ) Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py @core . inline def reduce_min_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! nid: impl _general_reduce_ ( core . min , core . max_value ( core . dtype ( x )), x , y , axes , keepdims ) reduce_prod ( * _args , ** _kvs ) Product of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) reduce_prod_ ( * _args , ** _kvs ) Product of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) reduce_sum ( * _args , ** _kvs ) Sum of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) reduce_sum_ ( * _args , ** _kvs ) Sum of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs ) reshape expand ( a , expand_shape ) Broadcast a tensor to a given shape, following the broadcasting rules Parameters: a ( VarRef ) \u2013 The input tensor b ( Sequence of expressions ) \u2013 The broadcasted shape Returns: The broadcasted tensor Source code in freetensor/libop/reshape.py @core . inline def expand ( a , expand_shape ): ''' Broadcast a tensor to a given shape, following the broadcasting rules Parameters ---------- a : VarRef The input tensor b : Sequence of expressions The broadcasted shape Returns ------- VarRef : The broadcasted tensor ''' # FIXME: out_shape = broadcast(a.shape, expand_shape) out = core . empty ( expand_shape , core . dtype ( a ), core . mtype ( a )) #! nid: recur expand_ ( a , out ) return out expand_ ( a , out ) Broadcast a tensor to an existing tensor, following the broadcasting rules Parameters: a ( VarRef ) \u2013 The input tensor b ( VarRef ) \u2013 The broadcasted tensor Source code in freetensor/libop/reshape.py @core . inline def expand_ ( a , out ): ''' Broadcast a tensor to an existing tensor, following the broadcasting rules Parameters ---------- a : VarRef The input tensor b : VarRef The broadcasted tensor ''' if out . ndim == 0 : out [()] = a else : #! nid: L_elem for i in range ( out . shape ( 0 )): if core . ndim ( a ) < out . ndim : #! nid: recur expand_ ( a , out [ i ]) else : #! nid: recur expand_ ( a [ i % a . shape ( 0 )], out [ i ]) flatten ( x , axis = 1 ) Flatten a tensor to have fewer dimensions, and return the result Parameters: x ( VarRef ) \u2013 The input tensor axis ( int (Optional) ) \u2013 The result tensor will have up to axis dimensions. All dimensions after axis will be flatten to 1-D. Negative axis means counting form the last dimension Returns: The result tensor Source code in freetensor/libop/reshape.py @core . inline def flatten ( x , axis = 1 ): ''' Flatten a tensor to have fewer dimensions, and return the result Parameters ---------- x : VarRef The input tensor axis : int (Optional) The result tensor will have up to `axis` dimensions. All dimensions after `axis` will be flatten to 1-D. Negative axis means counting form the last dimension Returns ------- VarRef : The result tensor ''' y = core . empty ( _flatten_comp_shape ( x , axis ), core . dtype ( x ), core . mtype ( x )) #! nid: recur flatten_ ( x , y , axis ) return y flatten_ ( x , y , axis = 1 ) Flatten a tensor to have fewer dimensions, and write to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axis ( int ) \u2013 The result tensor will have up to axis dimensions. All dimensions after axis will be flatten to 1-D. Negative axis means counting form the last dimension Source code in freetensor/libop/reshape.py @core . inline def flatten_ ( x , y , axis : int = 1 ): ''' Flatten a tensor to have fewer dimensions, and write to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axis : int (Optional) The result tensor will have up to `axis` dimensions. All dimensions after `axis` will be flatten to 1-D. Negative axis means counting form the last dimension ''' if axis == 0 : #! nid: recur _flatten_inner_ ( x , y [ 0 ]) else : #! nid: L_outer for i in range ( x . shape ( 0 )): #! nid: recur flatten_ ( x [ i ], y [ i * ( y . shape ( 0 ) // x . shape ( 0 )):( i + 1 ) * ( y . shape ( 0 ) // x . shape ( 0 ))], axis - 1 ) unsqueeze ( x , axes ) Insert singleton dimensions to a tensor, and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] ) \u2013 Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension Returns: VarRef \u2013 The resulting tensor Source code in freetensor/libop/reshape.py @core . inline def unsqueeze ( x , axes : Sequence [ int ]): ''' Insert singleton dimensions to a tensor, and return the result Parameters ---------- x : VarRef The input tensor axes : Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension Returns ------- VarRef The resulting tensor ''' y = core . empty ( _unsqueeze_comp_shape ( _circular_axes ( axes , core . ndim ( x )), x ), core . dtype ( x ), core . mtype ( x )) #! nid: recur unsqueeze_ ( x , y , axes ) return y unsqueeze_ ( x , y , axes ) Insert singleton dimensions to a tensor, and write the result to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The resulting tensor axes ( Sequence[int] ) \u2013 Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension Source code in freetensor/libop/reshape.py @core . inline def unsqueeze_ ( x , y , axes : Sequence [ int ]): ''' Insert singleton dimensions to a tensor, and write the result to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The resulting tensor axes : Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension ''' axes = _circular_axes ( axes , core . ndim ( x )) if y . ndim == 0 : y [()] = x elif begin_with_0 ( axes ): #! nid: recur unsqueeze_ ( x , y [ 0 ], all_minus_one ( axes [ 1 :])) else : #! nid: L for i in range ( x . shape ( 0 )): #! nid: recur unsqueeze_ ( x [ i ], y [ i ], all_minus_one ( axes )) softmax softmax ( x , axis =- 1 ) Softmax of tensor x along an axis and return the result Parameters: x ( VarRef ) \u2013 The input tensor axis ( int (Optional) ) \u2013 Axis that the softmax is performed along. Negative axis means count from the last dimension Returns: The result tensor Source code in freetensor/libop/softmax.py @core . inline def softmax ( x , axis =- 1 ): ''' Softmax of tensor `x` along an axis and return the result Parameters ---------- x : VarRef The input tensor axis : int (Optional) Axis that the softmax is performed along. Negative axis means count from the last dimension Returns ------- VarRef : The result tensor ''' #! nid: max maxval = reduce_max ( x , axes = [ axis ], keepdims = True ) #! nid: sub corrected = sub ( x , maxval ) #! nid: exp exponent = exp ( corrected ) #! nid: sum summation = reduce_sum ( exponent , axes = [ axis ], keepdims = True ) #! nid: div out = truediv ( exponent , summation ) return out softmax_ ( x , y , axis =- 1 ) Softmax of tensor x along an axis, and write to tensor y Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axis ( int ) \u2013 Axis that the softmax is performed along. Negative axis means count from the last dimension Source code in freetensor/libop/softmax.py @core . inline def softmax_ ( x , y , axis : int = - 1 ): ''' Softmax of tensor `x` along an axis, and write to tensor `y` Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axis : int (Optional) Axis that the softmax is performed along. Negative axis means count from the last dimension ''' #! nid: max maxval = reduce_max ( x , axes = [ axis ], keepdims = True ) #! nid: sub corrected = sub ( x , maxval ) #! nid: exp exponent = exp ( corrected ) #! nid: sum summation = reduce_sum ( exponent , axes = [ axis ], keepdims = True ) #! nid: div truediv_ ( exponent , summation , y )","title":"Python API"},{"location":"api/#python-api","text":"","title":"Python API"},{"location":"api/#freetensor.core","text":"","title":"core"},{"location":"api/#freetensor.core.auto_schedule","text":"","title":"auto_schedule"},{"location":"api/#freetensor.core.auto_schedule.AutoSchedule","text":"Source code in freetensor/core/auto_schedule.py class AutoSchedule ( ffi . AutoSchedule ): def __init__ ( self , schedule , target , device , * , population = 64 , explore_ratio = 0.1 , tag = \"\" , min_block_size = 0 , rule_set = None , verbose = 0 ): ''' Automatic scheduler Parameters ---------- schedule : Schedule A Schedule object to apply schedules onto target : Target The type of devices to compile to population : int How many programs to test in each iteration explore_ratio : float Portion of random programs in the population. Higher ratio focuses on exploration, while lower ratio focuses on exploitation rule_set : Optional[set] Explicitly control over what rules to use. None for defualt rules verbose : int Verbosity level. 0 = print nothing, 1 = print tuning progress, 2 = print extra info mation of each rule ''' self . population = population self . n_explore = int ( population * explore_ratio ) self . n_exploit = population - self . n_explore self . model = None self . xgb_params = {} self . save_file_name = tag + \"_xgb.model\" if os . path . isfile ( self . save_file_name ): self . model = xgb . Booster () self . model . load_model ( self . save_file_name ) self . verbose = verbose def predict_func ( features ): return self . predict ( features ) def update_func ( features , times ): return self . update ( features , times ) super ( AutoSchedule , self ) . __init__ ( schedule , target , device , predict_func , update_func , tag , min_block_size , rule_set , verbose ) def set_params ( self , * args , ** kws ): super ( AutoSchedule , self ) . set_params ( args , kws ) def run ( self , iteration ): for i in range ( iteration ): if self . verbose >= 1 : print ( \"Iteration\" , i ) self . search_one_round ( self . population , self . n_exploit , self . n_explore ) return self . get_best_schedule () def predict ( self , features ): if not self . model : return [ 1 ] * len ( features ) return self . model . predict ( xgb . DMatrix ( np . array ( features ), missing =- 1 )) def update ( self , features , times ): dtrain = xgb . DMatrix ( np . array ( features ), np . array ( times ), missing =- 1 ) self . model = xgb . train ( self . xgb_params , dtrain , xgb_model = self . model ) self . model . save_model ( self . save_file_name )","title":"AutoSchedule"},{"location":"api/#freetensor.core.auto_schedule.AutoSchedule.__init__","text":"Automatic scheduler Parameters: schedule ( Schedule ) \u2013 A Schedule object to apply schedules onto target ( Target ) \u2013 The type of devices to compile to population ( int ) \u2013 How many programs to test in each iteration explore_ratio ( float ) \u2013 Portion of random programs in the population. Higher ratio focuses on exploration, while lower ratio focuses on exploitation rule_set ( Optional[set] ) \u2013 Explicitly control over what rules to use. None for defualt rules verbose ( int ) \u2013 Verbosity level. 0 = print nothing, 1 = print tuning progress, 2 = print extra info mation of each rule Source code in freetensor/core/auto_schedule.py def __init__ ( self , schedule , target , device , * , population = 64 , explore_ratio = 0.1 , tag = \"\" , min_block_size = 0 , rule_set = None , verbose = 0 ): ''' Automatic scheduler Parameters ---------- schedule : Schedule A Schedule object to apply schedules onto target : Target The type of devices to compile to population : int How many programs to test in each iteration explore_ratio : float Portion of random programs in the population. Higher ratio focuses on exploration, while lower ratio focuses on exploitation rule_set : Optional[set] Explicitly control over what rules to use. None for defualt rules verbose : int Verbosity level. 0 = print nothing, 1 = print tuning progress, 2 = print extra info mation of each rule ''' self . population = population self . n_explore = int ( population * explore_ratio ) self . n_exploit = population - self . n_explore self . model = None self . xgb_params = {} self . save_file_name = tag + \"_xgb.model\" if os . path . isfile ( self . save_file_name ): self . model = xgb . Booster () self . model . load_model ( self . save_file_name ) self . verbose = verbose def predict_func ( features ): return self . predict ( features ) def update_func ( features , times ): return self . update ( features , times ) super ( AutoSchedule , self ) . __init__ ( schedule , target , device , predict_func , update_func , tag , min_block_size , rule_set , verbose )","title":"__init__()"},{"location":"api/#freetensor.core.auto_schedule.AutoSchedule.set_params","text":"set_params(self: freetensor_ffi.AutoSchedule, args: List[freetensor_ffi.Array], kws: Dict[str, freetensor_ffi.Array] = {}) -> None Source code in freetensor/core/auto_schedule.py def set_params ( self , * args , ** kws ): super ( AutoSchedule , self ) . set_params ( args , kws )","title":"set_params()"},{"location":"api/#freetensor.core.autograd","text":"","title":"autograd"},{"location":"api/#freetensor.core.autograd.ArgRetDict","text":"Look an object using either a function argument or return value's name or its position Source code in freetensor/core/autograd.py class ArgRetDict : ''' Look an object using either a function argument or return value's name or its position ''' def __init__ ( self , func , d ): self . func = func self . d = d def __getitem__ ( self , key ): if type ( key ) is Return : key = key . get_name ( self . func ) return self . d [ key ]","title":"ArgRetDict"},{"location":"api/#freetensor.core.autograd.Return","text":"Alias of a return value of a function Return(n) represents the n-th return value (counted from 0) Return() can be used if there is only one return value Source code in freetensor/core/autograd.py class Return : ''' Alias of a return value of a function `Return(n)` represents the n-th return value (counted from 0) `Return()` can be used if there is only one return value ''' def __init__ ( self , n : Optional [ int ] = None ): self . n = n def get_name ( self , func ): assert len ( func . returns ) > 0 , f \" { func . name } has no return value\" if self . n is not None : return func . returns [ self . n ] . name else : assert len ( func . returns ) == 1 , f \" { func . name } has more than one return value, and you need to specify the number of a return value\" return func . returns [ 0 ] . name","title":"Return"},{"location":"api/#freetensor.core.autograd.grad","text":"Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad is an out-of-place version. The resulting gradient are returned from the backward function. Parameters: func ( Func ) \u2013 The original function requires ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of input variables that need gradients provides ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of output variables whose gradients are known. A return value of a function can be specified with a Return object tapes ( Union[Sequence, freetensor_ffi.GradTapeMode] ) \u2013 Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns: tuple \u2013 ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in freetensor/core/autograd.py def grad ( func : ffi . Func , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad` is an out-of-place version. The resulting gradient are returned from the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad , func , requires , provides , tapes , verbose = verbose )","title":"grad()"},{"location":"api/#freetensor.core.autograd.grad_","text":"Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad_ is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters: func ( Func ) \u2013 The original function requires ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of input variables that need gradients provides ( Sequence[Union[str, freetensor.core.autograd.Return]] ) \u2013 Name of output variables whose gradients are known. A return value of a function can be specified with a Return object tapes ( Union[Sequence, freetensor_ffi.GradTapeMode] ) \u2013 Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns: tuple \u2013 ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in freetensor/core/autograd.py def grad_ ( func : ffi . Func , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad_` is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef IDs of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad_ , func , requires , provides , tapes , verbose = verbose )","title":"grad_()"},{"location":"api/#freetensor.core.autograd.grad_body","text":"grad or grad_ on a function body (for internal tests only) Source code in freetensor/core/autograd.py def grad_body ( stmt : ffi . Stmt , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly ): ''' `grad` or `grad_` on a function body (for internal tests only) ''' req = set ( requires ) prov = set ( provides ) if type ( tapes ) is not GradTapeMode : tapes = set ( tapes ) return ffi . grad_body ( stmt , req , prov , tapes )","title":"grad_body()"},{"location":"api/#freetensor.core.codegen","text":"","title":"codegen"},{"location":"api/#freetensor.core.codegen.codegen","text":"Generate native code Parameters: ast ( AST ) \u2013 The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator target ( Optional[freetensor_ffi.Target] ) \u2013 The target architecture. If omitted, use the default one in config Source code in freetensor/core/codegen.py def codegen ( ast = None , target : Optional [ ffi . Target ] = None , verbose : Optional [ bool ] = None ) -> NativeCode : ''' Generate native code Parameters ---------- ast : AST The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator target : Target (Optional) The target architecture. If omitted, use the default one in config ''' if ast is not None : if target is None : target = config . default_target () if target . type () == ffi . TargetType . CPU : raw_code = ffi . code_gen_cpu ( ast ) elif target . type () == ffi . TargetType . GPU : raw_code = ffi . code_gen_cuda ( ast ) else : assert False , \"Unrecognized target %s \" % target if verbose : print ( debug . with_line_no ( raw_code ), file = sys . stderr ) return NativeCode ( ast , raw_code , target ) else : f = codegen if target is not None : f = functools . partial ( f , target = target ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f","title":"codegen()"},{"location":"api/#freetensor.core.config","text":"Global configurations","title":"config"},{"location":"api/#freetensor.core.config.backend_compiler_cxx","text":"backend_compiler_cxx() -> str Backend compiler used to compile generated C++ code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"backend_compiler_cxx()"},{"location":"api/#freetensor.core.config.backend_compiler_nvcc","text":"backend_compiler_nvcc() -> str Backend compiler used to compile generated CUDA code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"backend_compiler_nvcc()"},{"location":"api/#freetensor.core.config.debug_binary","text":"debug_binary() -> bool Check if compiling binary in debug mode Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"debug_binary()"},{"location":"api/#freetensor.core.config.default_device","text":"default_device() -> freetensor_ffi.Device Check current default device Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"default_device()"},{"location":"api/#freetensor.core.config.default_target","text":"default_target() -> freetensor_ffi.Target Check current default target Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"default_target()"},{"location":"api/#freetensor.core.config.pretty_print","text":"pretty_print() -> bool Check if colored printing enabled Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"pretty_print()"},{"location":"api/#freetensor.core.config.print_all_id","text":"pretty_print() -> bool Check if colored printing enabled Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"print_all_id()"},{"location":"api/#freetensor.core.config.set_backend_compiler_cxx","text":"set_backend_compiler_cxx(path: str) -> None Set backend compiler used to compile generated C++ code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_backend_compiler_cxx()"},{"location":"api/#freetensor.core.config.set_backend_compiler_nvcc","text":"set_backend_compiler_nvcc(path: str) -> None Set backend compiler used to compile generated CUDA code Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_backend_compiler_nvcc()"},{"location":"api/#freetensor.core.config.set_debug_binary","text":"set_debug_binary(flag: bool = True) -> None Compile with -g at backend. Do not delete the binary file after loaded Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_debug_binary()"},{"location":"api/#freetensor.core.config.set_default_device","text":"set_default_device(device: freetensor_ffi.Device) -> None Set default device (internal implementation of with Device ) Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_default_device()"},{"location":"api/#freetensor.core.config.set_default_target","text":"set_default_target(target: freetensor_ffi.Target) -> None Set default target (internal implementation of with Target ) Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_default_target()"},{"location":"api/#freetensor.core.config.set_pretty_print","text":"set_pretty_print(flag: bool = True) -> None Set colored printing Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_pretty_print()"},{"location":"api/#freetensor.core.config.set_print_all_id","text":"set_pretty_print(flag: bool = True) -> None Set colored printing Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_print_all_id()"},{"location":"api/#freetensor.core.config.set_werror","text":"set_werror(flag: bool = True) -> None Error on warning Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"set_werror()"},{"location":"api/#freetensor.core.config.werror","text":"werror() -> bool Check if error-on-warning enabled Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"werror()"},{"location":"api/#freetensor.core.config.with_cuda","text":"with_cuda() -> bool Check if FreeTensor is built with CUDA Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"with_cuda()"},{"location":"api/#freetensor.core.config.with_mkl","text":"with_mkl() -> str Check if FreeTensor is built with MKL Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"with_mkl()"},{"location":"api/#freetensor.core.config.with_pytorch","text":"with_pytorch() -> bool Check if FreeTensor is built with PyTorch interface Source code in freetensor/core/config.py def g ( * args , ** kvs ): return f ( * args , ** kvs )","title":"with_pytorch()"},{"location":"api/#freetensor.core.context","text":"Facility to pick statements to build an AST Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module.","title":"context"},{"location":"api/#freetensor.core.context.pop_ast","text":"Get AST and reset context Internally used by transformer and tests Source code in freetensor/core/context.py def pop_ast ( verbose : bool = False ): \"\"\" Get AST and reset context Internally used by `transformer` and tests \"\"\" ret = ctx_stack . pop () . make_stmt () ctx_stack . reset () if verbose : print ( \"The popped AST is:\" , file = sys . stderr ) print ( ret , file = sys . stderr ) print ( file = sys . stderr ) return ret","title":"pop_ast()"},{"location":"api/#freetensor.core.driver","text":"","title":"driver"},{"location":"api/#freetensor.core.driver.Device","text":"A computing device of a Target E.g. suppose GPU() is a Target (architecture), then Device(GPU(), 0) means the 0-th GPU (device) A Device can be used as a \"with\" scope, then all the Array s and Driver s will use it by default. In this style, it also sets the default Target. E.g: with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default Source code in freetensor/core/driver.py class Device ( ffi . Device ): ''' A computing device of a Target E.g. suppose GPU() is a Target (architecture), then Device(GPU(), 0) means the 0-th GPU (device) A Device can be used as a \"with\" scope, then all the `Array`s and `Driver`s will use it by default. In this style, it also sets the default Target. E.g: ``` with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default ``` ''' def __init__ ( self , target : Target , num : int = 0 ): super ( Device , self ) . __init__ ( target , num ) def __enter__ ( self ): self . old_target = config . default_target () self . old_device = config . default_device () config . set_default_target ( self . target ()) config . set_default_device ( self ) return self def __exit__ ( self , exc_type , exc_value , traceback ): config . set_default_target ( self . old_target ) config . set_default_device ( self . old_device )","title":"Device"},{"location":"api/#freetensor.core.driver.Driver","text":"Source code in freetensor/core/driver.py class Driver ( ffi . Driver ): def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , src , device , host_device , verbose ) self . func = func def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ]) for key in kws : kws [ key ] = array ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws ) def collect_returns ( self ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 : return None elif len ( values ) == 1 : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values ) def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns ()","title":"Driver"},{"location":"api/#freetensor.core.driver.Driver.__call__","text":"Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call self.set_args first, then self.time , and finally self.collect_returns Source code in freetensor/core/driver.py def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns ()","title":"__call__()"},{"location":"api/#freetensor.core.driver.Driver.__init__","text":"Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using build_binary Parameters: func ( Func ) \u2013 AST of the function, where the function signature is needed to determine the parameters and return values src ( str ) \u2013 Native code generated from codegen device ( Optional[freetensor.core.driver.Device] ) \u2013 The device to run the program. If omitted, use the default device in config verbose ( Optional[bool] ) \u2013 True to print extra infomation Source code in freetensor/core/driver.py def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , src , device , host_device , verbose ) self . func = func","title":"__init__()"},{"location":"api/#freetensor.core.driver.Driver.collect_returns","text":"Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack Source code in freetensor/core/driver.py def collect_returns ( self ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 : return None elif len ( values ) == 1 : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values )","title":"collect_returns()"},{"location":"api/#freetensor.core.driver.Driver.set_args","text":"Set argument for an invocation Source code in freetensor/core/driver.py def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ]) for key in kws : kws [ key ] = array ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws )","title":"set_args()"},{"location":"api/#freetensor.core.driver.ReturnValuesPack","text":"Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: x, y, z = pack , or in a named manner: pack['x'] Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values Source code in freetensor/core/driver.py class ReturnValuesPack : ''' Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: `x, y, z = pack`, or in a named manner: `pack['x']` Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values ''' def __init__ ( self , keys : Sequence [ str ], values : Sequence [ Array ]): keys = list ( keys ) values = list ( values ) assert len ( keys ) == len ( values ) self . keys = keys self . values = values def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key )","title":"ReturnValuesPack"},{"location":"api/#freetensor.core.driver.ReturnValuesPack.__getitem__","text":"Get a return value with a name. Tuple is supported for multiple values Source code in freetensor/core/driver.py def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key )","title":"__getitem__()"},{"location":"api/#freetensor.core.driver.ReturnValuesPack.__iter__","text":"Get all return values in the order declared in Func Source code in freetensor/core/driver.py def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values","title":"__iter__()"},{"location":"api/#freetensor.core.driver.Target","text":"A target architecture A Target can be used as a \"with\" scope, then all the lower s and codegen s will use it by default. In this style, it also sets the default Device as the 0-th device of the given Target. E.g: with Target(...): ast = lower(ast) # Use the Target above by default a = Array(...) # Use the 0-th device of the Target above by default Source code in freetensor/core/driver.py class Target ( ffi . Target ): ''' A target architecture A Target can be used as a \"with\" scope, then all the `lower`s and `codegen`s will use it by default. In this style, it also sets the default Device as the 0-th device of the given Target. E.g: ``` with Target(...): ast = lower(ast) # Use the Target above by default a = Array(...) # Use the 0-th device of the Target above by default ``` ''' def __init__ ( self , use_native_arch : bool = True ): super ( Target , self ) . __init__ ( use_native_arch ) def __enter__ ( self ): self . old_target = config . default_target () self . old_device = config . default_device () config . set_default_target ( self ) config . set_default_device ( Device ( self , 0 )) return self def __exit__ ( self , exc_type , exc_value , traceback ): config . set_default_target ( self . old_target ) config . set_default_device ( self . old_device )","title":"Target"},{"location":"api/#freetensor.core.driver.array","text":"Factory function for Array It converts more data format to Array Source code in freetensor/core/driver.py def array ( data ): ''' Factory function for Array It converts more data format to Array ''' if type ( data ) is Array : return data # For NumPy, Although Pybind11's `array_t` type provides a flag `forcecast` to # cast from a strided array to a contiguous one. But it always casts to a specific # type, e.g. float64. I have no idea how to support multiple types. Therfore, # we have to call NumPy's `.copy(order='C')` to make a new NumPy array. This # function can only be called from Python side (not from PyBind11's `py::array` # type). if type ( data ) is np . ndarray : if not data . flags [ 'C_CONTIGUOUS' ]: data = data . copy ( order = 'C' ) return Array ( data ) if data . __class__ . __module__ == 'torch' : import torch if type ( data ) is torch . Tensor : if not config . with_pytorch (): raise ffi . DriverError ( \"FreeTensor should be built with WITH_PYTORCH to accept a PyTorch tensor\" ) if not data . is_contiguous (): data = data . contiguous () return Array ( data ) raise ffi . DriverError ( f \"Unsupported data type { type ( data ) } for Array\" )","title":"array()"},{"location":"api/#freetensor.core.driver.build_binary","text":"Compile a program using a backend compiler and load it into memory Parameters: code ( Optional[freetensor.core.codegen.NativeCode] ) \u2013 Native code generated by codegen . If not specified, a partial function is returned, which can be used as a decorator device ( Optional[freetensor.core.driver.Device] ) \u2013 The device to run the program. If omitted, use the default device in config Source code in freetensor/core/driver.py def build_binary ( code : Optional [ NativeCode ] = None , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory Parameters ---------- code : NativeCode Native code generated by `codegen`. If not specified, a partial function is returned, which can be used as a decorator device : Device (Optional) The device to run the program. If omitted, use the default device in config ''' if code is not None : if device is None : device = config . default_device () if device . target () != code . target : raise ffi . DriverError ( f \"Codegen target ( { code . target } ) is inconsistent with device target ( { device . target () } )\" ) return Driver ( code . func , code . code , device , host_device , verbose ) else : f = build_binary if device is not None : f = functools . partial ( f , device = device ) if host_device is not None : f = functools . partial ( f , host_device = host_device ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f","title":"build_binary()"},{"location":"api/#freetensor.core.expr","text":"Facility to build AST expressions Classes and functions in this module are not only used internally for constructing AST nodes, and also exposed to users via multi-stage programming","title":"expr"},{"location":"api/#freetensor.core.expr.VarRef","text":"Variable of FreeTensor All variables in FreeTensor DSL (declared via Var , created by empty or var , returned by libop , etc.), and their slices, are VarRef objects. Operations on VarRef objects generates AST nodes Source code in freetensor/core/expr.py class VarRef ( ffi . FrontendVar ): ''' Variable of FreeTensor All variables in FreeTensor DSL (declared via `Var`, created by `empty` or `var`, returned by `libop`, etc.), and their slices, are `VarRef` objects. Operations on `VarRef` objects generates AST nodes ''' def __init__ ( self , name : str , vardef , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = []): super ( VarRef , self ) . __init__ ( name , full_shape , dtype , mtype , indices ) self . vardef = vardef from .stmt import find_borrowed_vardefs self . borrowed_vardefs = find_borrowed_vardefs ( indices ) for item in self . borrowed_vardefs : item . lend_out () def __del__ ( self ): for item in self . borrowed_vardefs : item . reclaim () def __getitem__ ( self , key ): return VarRef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) def __setitem__ ( self , key , value ): var = VarRef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) if var . ndim > 0 : if value is not None : # In standard Python data model, functions like __iadd__ # returns the modified self, and __setitem__ does a self- # assignment. We do the augmenting assignment directly # in __iadd__ and return None, so we do not have to do # it again here from .. import libop libop . assign ( var , value ) return if var . vardef . atype == ffi . AccessType ( \"input\" ): raise ffi . InvalidProgram ( \"Cannot modify an \\\" input \\\" tensor `\" + self . name + \"`\" ) if var . vardef . borrower_cnt > 0 : raise ffi . InvalidProgram ( \"Cannot modify tensor `\" + self . name + \"` becuase it has been borrowed in another tensor's shape, \" \"a tensor slice, or a range of a loop\" ) top = ctx_stack . top () top . append_stmt ( var . as_store ( top . get_next_nid (), value )) def select ( self , idx , dim ): assert isinstance ( dim , int ) assert dim >= 0 and dim < self . ndim indices = [ slice ( None , None ) if d != dim else idx for d in range ( self . ndim ) ] return self [ indices ] def _parse_key ( self , key ): if key is None or key is ... : key = () if not isinstance ( key , collections . abc . Sequence ): key = ( key ,) ffiIdx = [] for idx , length in zip ( key , self . shape ()): if isinstance ( idx , slice ): start = idx . start if idx . start is not None else 0 stop = idx . stop if idx . stop is not None else length assert idx . step is None or idx . step == 1 ffiIdx . append ( ffi . FrontendVarIdx ( start , stop )) elif isinstance ( idx , VarRef ): if len ( idx . full_shape ) == len ( idx . indices ): ffiIdx . append ( ffi . FrontendVarIdx ( idx . as_load ())) else : assert len ( key ) == 1 , f \"Shape of an index of { self . name } should be 1-D, instead of { idx . name } \" assert type ( idx . full_shape [ 0 ] ) is ffi . IntConst , \"Dynamic number of dimensions is not supported\" ndim = idx . full_shape [ 0 ] . val ffiIdx += [ ffi . FrontendVarIdx ( idx [ i ] . as_load ()) for i in range ( ndim ) ] else : ffiIdx . append ( ffi . FrontendVarIdx ( idx )) return ffiIdx def __add__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( self , other ) return self . as_load () + other def __radd__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( other , self ) return other + self . as_load () def __iadd__ ( self , other ): if self . ndim > 0 : from .. import libop libop . add_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __sub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( self , other ) return self . as_load () - other def __rsub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( other , self ) return other - self . as_load () def __isub__ ( self , other ): if self . ndim > 0 : from .. import libop libop . sub_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __mul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( self , other ) return self . as_load () * other def __rmul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( other , self ) return other * self . as_load () def __imul__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mul_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __truediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( self , other ) return self . as_load () / other def __rtruediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( other , self ) return other / self . as_load () def __itruediv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . truediv_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __floordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( self , other ) return self . as_load () // other def __rfloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( other , self ) return other // self . as_load () def __ifloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . floordiv_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __mod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( self , other ) return self . as_load () % other def __rmod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( other , self ) return other % self . as_load () def __imod__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mod_to ( self , other ) return # Don't return self. See __setitem__ return NotImplemented def __lt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . lt ( self , other ) return self . as_load () < other def __le__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . le ( self , other ) return self . as_load () <= other def __gt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . gt ( self , other ) return self . as_load () > other def __ge__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ge ( self , other ) return self . as_load () >= other def __eq__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . eq ( self , other ) return self . as_load () == other def __ne__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ne ( self , other ) return self . as_load () != other def __neg__ ( self ): if self . ndim > 0 : from .. import libop return libop . neg ( self ) return 0 - self . as_load () def __matmul__ ( self , other ): from .. import libop return libop . matmul ( self , other ) def __rmatmul__ ( self , other ): from .. import libop return libop . matmul ( other , self )","title":"VarRef"},{"location":"api/#freetensor.core.expr.abs","text":"Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The absolute value Source code in freetensor/core/expr.py def abs ( expr ): ''' Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The absolute value ''' if _istensor ( expr ): from .. import libop return libop . abs ( expr ) if type ( expr ) in ( int , float ): return builtins . abs ( expr ) return ffi . makeAbs ( expr )","title":"abs()"},{"location":"api/#freetensor.core.expr.add","text":"lhs + rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The sum Source code in freetensor/core/expr.py def add ( lhs , rhs ): ''' `lhs + rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The sum ''' return lhs + rhs","title":"add()"},{"location":"api/#freetensor.core.expr.any","text":"Create an AnyExpr node (only for testing) Any nodes matches any expression nodes in ast.match Source code in freetensor/core/expr.py def any (): ''' Create an AnyExpr node (only for testing) Any nodes matches any expression nodes in `ast.match` ''' return ffi . makeAnyExpr ()","title":"any()"},{"location":"api/#freetensor.core.expr.cast","text":"Cast to another type Parameters: expr ( VarRef or Number ) \u2013 The operand dtype ( DataTypr or str ) \u2013 The target data type Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def cast ( expr , dtype ): ''' Cast to another type Parameters ---------- expr : VarRef or Number The operand dtype : DataTypr or str The target data type Returns ------- VarRef or Number The result ''' return ffi . makeCast ( expr , ffi . DataType ( dtype ))","title":"cast()"},{"location":"api/#freetensor.core.expr.ceil","text":"Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def ceil ( expr ): ''' Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . ceil ( expr ) return ffi . makeCeil ( expr )","title":"ceil()"},{"location":"api/#freetensor.core.expr.ceildiv","text":"Ceiling integer division of lhs dividing by rhs The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def ceildiv ( lhs , rhs ): ''' Ceiling integer division of `lhs` dividing by `rhs` The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . ceildiv ( lhs , rhs ) if type ( lhs ) is int and type ( rhs ) is int : return lhs // rhs + ( lhs % rhs > 0 ) return ffi . makeCeilDiv ( lhs , rhs )","title":"ceildiv()"},{"location":"api/#freetensor.core.expr.dtype","text":"Get element data type of a variable Source code in freetensor/core/expr.py def dtype ( var ): ''' Get element data type of a variable ''' if isinstance ( var , VarRef ): return var . dtype elif isinstance ( var , ffi . Expr ): return var . dtype else : # TODO: Config default type if isinstance ( var , float ): return ffi . DataType ( \"float32\" ) elif isinstance ( var , int ): return ffi . DataType ( \"int32\" ) else : raise Exception ( 'Unknown scalar type: ' + str ( type ( var )))","title":"dtype()"},{"location":"api/#freetensor.core.expr.eq","text":"lhs == rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def eq ( lhs , rhs ): ''' `lhs == rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs == rhs","title":"eq()"},{"location":"api/#freetensor.core.expr.exp","text":"Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The exponent Source code in freetensor/core/expr.py def exp ( expr ): ''' Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The exponent ''' if _istensor ( expr ): from .. import libop return libop . exp ( expr ) if type ( expr ) in ( int , float ): return math . exp ( expr ) return ffi . makeExp ( expr )","title":"exp()"},{"location":"api/#freetensor.core.expr.floor","text":"Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def floor ( expr ): ''' Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . floor ( expr ) return ffi . makeFloor ( expr )","title":"floor()"},{"location":"api/#freetensor.core.expr.floordiv","text":"Floored integer division of lhs dividing by rhs The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over round_towards_0_div , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def floordiv ( lhs , rhs ): ''' Floored integer division of `lhs` dividing by `rhs` The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over `round_towards_0_div`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs // rhs","title":"floordiv()"},{"location":"api/#freetensor.core.expr.ge","text":"lhs >= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def ge ( lhs , rhs ): ''' `lhs >= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs >= rhs","title":"ge()"},{"location":"api/#freetensor.core.expr.gt","text":"lhs > rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def gt ( lhs , rhs ): ''' `lhs > rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs > rhs","title":"gt()"},{"location":"api/#freetensor.core.expr.if_then_else","text":"Similar to then_case if cond else else_case NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use if_then_else to guard an out-of-bound array indexing Parameters: cond ( VarRef of Number ) \u2013 Condition lhs ( VarRef or Number ) \u2013 Then-case experssion rhs ( VarRef or Number ) \u2013 Else-case expression Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def if_then_else ( cond , then_case , else_case ): ''' Similar to `then_case if cond else else_case` NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use `if_then_else` to guard an out-of-bound array indexing Parameters ---------- cond : VarRef of Number Condition lhs : VarRef or Number Then-case experssion rhs : VarRef or Number Else-case expression Returns ------- VarRef or Number The result ''' if type ( cond ) is bool : return then_case if cond else else_case return ffi . makeIfExpr ( cond , then_case , else_case )","title":"if_then_else()"},{"location":"api/#freetensor.core.expr.intrinsic","text":"Invoke whatever target code Parameters: fmt ( str ) \u2013 What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) The following variadic arguments ( Expr ) \u2013 Parameters to fmt ret_type ( DataType or str ) \u2013 (Keyword argument only) The return type. Void for no return type. Defaults to Void has_side_effect ( bool ) \u2013 (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false Source code in freetensor/core/expr.py def intrinsic ( fmt , * params , ** kws ): \"\"\" Invoke whatever target code Parameters ---------- fmt : str What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) The following variadic arguments : Expr Parameters to `fmt` ret_type : DataType or str (Keyword argument only) The return type. Void for no return type. Defaults to Void has_side_effect: bool (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false \"\"\" ret_type = ffi . DataType ( \"void\" ) has_side_effect = False if \"ret_type\" in kws : ret_type = ffi . DataType ( kws [ \"ret_type\" ]) del kws [ \"ret_type\" ] if \"has_side_effect\" in kws : has_side_effect = kws [ \"has_side_effect\" ] del kws [ \"has_side_effect\" ] assert len ( kws ) == 0 , \"Unrecognized keyword arguments: %s \" % kws return ffi . makeIntrinsic ( fmt , params , ret_type , has_side_effect )","title":"intrinsic()"},{"location":"api/#freetensor.core.expr.l_and","text":"Logical and of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The logical and Source code in freetensor/core/expr.py def l_and ( lhs , rhs ): ''' Logical and of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical and ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_and ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs and rhs else : return ffi . makeLAnd ( lhs , rhs )","title":"l_and()"},{"location":"api/#freetensor.core.expr.l_not","text":"Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The logical not Source code in freetensor/core/expr.py def l_not ( expr ): ''' Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The logical not ''' if _istensor ( expr ): from .. import libop return libop . l_not ( expr ) if type ( expr ) is bool : return not expr else : return ffi . makeLNot ( expr )","title":"l_not()"},{"location":"api/#freetensor.core.expr.l_or","text":"Logical or of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The logical or Source code in freetensor/core/expr.py def l_or ( lhs , rhs ): ''' Logical or of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical or ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_or ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs or rhs else : return ffi . makeLOr ( lhs , rhs )","title":"l_or()"},{"location":"api/#freetensor.core.expr.le","text":"lhs <= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def le ( lhs , rhs ): ''' `lhs <= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs <= rhs","title":"le()"},{"location":"api/#freetensor.core.expr.lt","text":"lhs < rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def lt ( lhs , rhs ): ''' `lhs < rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs < rhs","title":"lt()"},{"location":"api/#freetensor.core.expr.max","text":"Maximum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The maximum Source code in freetensor/core/expr.py def max ( lhs , rhs ): ''' Maximum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The maximum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . max ( lhs , rhs ) if type ( lhs ) in ( int , float ) and type ( rhs ) in ( int , float ): return builtins . max ( lhs , rhs ) return ffi . makeMax ( lhs , rhs )","title":"max()"},{"location":"api/#freetensor.core.expr.min","text":"Minimum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The minimum Source code in freetensor/core/expr.py def min ( lhs , rhs ): ''' Minimum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The minimum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . min ( lhs , rhs ) if type ( lhs ) in ( int , float ) and type ( rhs ) in ( int , float ): return builtins . min ( lhs , rhs ) return ffi . makeMin ( lhs , rhs )","title":"min()"},{"location":"api/#freetensor.core.expr.mod","text":"lhs modulus rhs The result is always non-negative (following Python convention, instead of C). This function is recommended over remainder , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The modulo Source code in freetensor/core/expr.py def mod ( lhs , rhs ): ''' `lhs` modulus `rhs` The result is always non-negative (following Python convention, instead of C). This function is recommended over `remainder`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The modulo ''' return lhs % rhs","title":"mod()"},{"location":"api/#freetensor.core.expr.mtype","text":"Get memory type of a variable Source code in freetensor/core/expr.py def mtype ( var ): ''' Get memory type of a variable ''' if isinstance ( var , VarRef ): return var . mtype else : return 'byvalue'","title":"mtype()"},{"location":"api/#freetensor.core.expr.mul","text":"lhs * rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The product Source code in freetensor/core/expr.py def mul ( lhs , rhs ): ''' `lhs * rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The product ''' return lhs * rhs","title":"mul()"},{"location":"api/#freetensor.core.expr.ndim","text":"Get the number of dimensions of a variable Source code in freetensor/core/expr.py def ndim ( var ): ''' Get the number of dimensions of a variable ''' if isinstance ( var , VarRef ): return var . ndim else : return 0","title":"ndim()"},{"location":"api/#freetensor.core.expr.ne","text":"lhs != rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The comparison Source code in freetensor/core/expr.py def ne ( lhs , rhs ): ''' `lhs != rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs != rhs","title":"ne()"},{"location":"api/#freetensor.core.expr.remainder","text":"Remainder of lhs dividing rhs The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use lhs % rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The remainder Source code in freetensor/core/expr.py def remainder ( lhs , rhs ): ''' Remainder of `lhs` dividing `rhs` The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use `lhs % rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The remainder ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . remainder ( lhs , rhs ) return ffi . makeRemainder ( lhs , rhs )","title":"remainder()"},{"location":"api/#freetensor.core.expr.round_towards_0_div","text":"C-style integer division of lhs dividing by rhs The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use lhs // rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def round_towards_0_div ( lhs , rhs ): ''' C-style integer division of `lhs` dividing by `rhs` The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use `lhs // rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . round_towards_0_div ( lhs , rhs ) return ffi . makeRoundTowards0Div ( lhs , rhs )","title":"round_towards_0_div()"},{"location":"api/#freetensor.core.expr.shape","text":"shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable Source code in freetensor/core/expr.py def shape ( var , i = None ): ''' shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable ''' if isinstance ( var , VarRef ): return var . shape ( i ) else : if i is None : return () else : raise Exception ( f 'Getting size of dimension { i } of scalar { var } ' )","title":"shape()"},{"location":"api/#freetensor.core.expr.sigmoid","text":"Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def sigmoid ( expr ): ''' Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . sigmoid ( expr ) return ffi . makeSigmoid ( expr )","title":"sigmoid()"},{"location":"api/#freetensor.core.expr.sqrt","text":"Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The square root Source code in freetensor/core/expr.py def sqrt ( expr ): ''' Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square root ''' if _istensor ( expr ): from .. import libop return libop . sqrt ( expr ) if type ( expr ) in ( int , float ): return math . sqrt ( expr ) return ffi . makeSqrt ( expr )","title":"sqrt()"},{"location":"api/#freetensor.core.expr.square","text":"Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The square Source code in freetensor/core/expr.py def square ( expr ): ''' Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square ''' if _istensor ( expr ): from .. import libop return libop . square ( expr ) if type ( expr ) in ( int , float ): return expr * expr return ffi . makeSquare ( expr )","title":"square()"},{"location":"api/#freetensor.core.expr.sub","text":"lhs - rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The difference Source code in freetensor/core/expr.py def sub ( lhs , rhs ): ''' `lhs - rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The difference ''' return lhs - rhs","title":"sub()"},{"location":"api/#freetensor.core.expr.tanh","text":"Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters: expr ( VarRef or Number ) \u2013 The operand Returns: VarRef or Number \u2013 The result Source code in freetensor/core/expr.py def tanh ( expr ): ''' Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . tanh ( expr ) if type ( expr ) in ( int , float ): return math . tanh ( expr ) return ffi . makeTanh ( expr )","title":"tanh()"},{"location":"api/#freetensor.core.expr.truediv","text":"Floating point division of lhs dividing by rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters: lhs ( VarRef or Number ) \u2013 The left-hand-side operand rhs ( VarRef or Number ) \u2013 The right-hand-side operand Returns: VarRef or Number \u2013 The quotient Source code in freetensor/core/expr.py def truediv ( lhs , rhs ): ''' Floating point division of `lhs` dividing by `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs / rhs","title":"truediv()"},{"location":"api/#freetensor.core.optimize","text":"","title":"optimize"},{"location":"api/#freetensor.core.optimize.optimize","text":"An one-click optimization from Python function to binary executable Usage: @optimize def f(...): ... It is equivalent to: @build_binary @codegen @lower @transform def f(...): ... Parameters: func ( Python function or AST ) \u2013 The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator schedule_callback ( Optional[Callable[[freetensor.core.schedule.Schedule], NoneType]] ) \u2013 Schedule(s) to apply target ( Optional[freetensor.core.driver.Target] ) \u2013 The target architecture. You don't have to set target if you set device device ( Optional[freetensor.core.driver.Device] ) \u2013 Where to run the program default_dynamic_range ( bool ) \u2013 If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose ( Optional[int] ) \u2013 Verbosity level. Can be 0, 1 or 2 Source code in freetensor/core/optimize.py def optimize ( func = None , schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , target : Optional [ Target ] = None , device : Optional [ Device ] = None , default_dynamic_range : bool = True , verbose : Optional [ int ] = None ): ''' An one-click optimization from Python function to binary executable Usage: ``` @optimize def f(...): ... ``` It is equivalent to: ``` @build_binary @codegen @lower @transform def f(...): ... ``` Parameters ---------- func : Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator schedule_callback : Callable (Optional) Schedule(s) to apply target : Target (Optional) The target architecture. You don't have to set target if you set device device : Device (Optional) Where to run the program default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int (Optional) Verbosity level. Can be 0, 1 or 2 ''' if func is not None : if target is None and device is not None : target = device . target () if not issubclass ( type ( func ), ffi . AST ): ast = transform ( func , default_dynamic_range = default_dynamic_range , verbose = verbose ) else : ast = func ast = schedule ( ast , schedule_callback , verbose = verbose ) ast = lower ( ast , target , verbose = verbose ) code = codegen ( ast , target , verbose = verbose ) exe = build_binary ( code , device , verbose = verbose ) return exe else : f = optimize if schedule_callback is not None : f = functools . partial ( f , schedule_callback = schedule_callback ) if target is not None : f = functools . partial ( f , target = target ) if device is not None : f = functools . partial ( f , device = device ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f","title":"optimize()"},{"location":"api/#freetensor.core.passes","text":"","title":"passes"},{"location":"api/#freetensor.core.passes.lower","text":"Lower an AST using a series of passes Parameters: ast ( AST ) \u2013 The AST to be lowered. Can be a Func or a Stmt . If not specified, a partial function of lower will be returned, which can be used as a decorator target ( Optional[freetensor_ffi.Target] ) \u2013 Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config skip_passes ( Optional[Sequence[str]] ) \u2013 Skip some pass for testing or debugging. Names in skipPasses are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes verbose ( Optional[int] ) \u2013 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes Source code in freetensor/core/passes.py def lower ( ast = None , target : Optional [ ffi . Target ] = None , skip_passes : Optional [ Sequence [ str ]] = None , verbose : Optional [ int ] = None ): ''' Lower an AST using a series of passes Parameters ---------- ast : AST The AST to be lowered. Can be a `Func` or a `Stmt`. If not specified, a partial function of `lower` will be returned, which can be used as a decorator target : Target (Optional) Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config skip_passes : Sequence[str] (Optional) Skip some pass for testing or debugging. Names in `skipPasses` are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes verbose : int (Optional) 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes ''' if ast is not None : return ffi . lower ( ast , target , set () if skip_passes is None else set ( skip_passes ), 0 if verbose is None else verbose ) else : _lower = lower if target is not None : _lower = functools . partial ( _lower , target = target ) if skip_passes is not None : _lower = functools . partial ( _lower , skip_passes = skip_passes ) if verbose is not None : _lower = functools . partial ( _lower , verbose = verbose ) return _lower","title":"lower()"},{"location":"api/#freetensor.core.schedule","text":"","title":"schedule"},{"location":"api/#freetensor.core.schedule.Schedule","text":"Source code in freetensor/core/schedule.py class Schedule ( ffi . Schedule ): def __init__ ( self , ast , verbose : int = 0 ): super ( Schedule , self ) . __init__ ( ast , verbose ) def split ( self , node , factor =- 1 , nparts =- 1 , shift = 0 ): \"\"\" Split a loop into two nested loops To fission a loop into two consecutive loops, use `fission` instead Two modes are provided: 1. Specify `factor` and leave `nparts` to -1. It will result in an outer loop with length `ceil(n / factor)`, and an inner loop with length `factor`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * factor + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively 2. Specify `nparts` and leave `factor` to -1. It will result in an outer loop with length `nparts`, and an inner loop with length `ceil(n / nparts)`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * ceil(n / nparts) + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively Please note that the second mode will introduce an `i0 * ceil(n / nparts)` factor into the program, which cannot be recognized by polyhedral analysis, which may hinder some following schedules. If possible, plese use the first mode, and then reorder the inner and outer loops Parameters ---------- node : str, ID or Stmt The loop to be split factor : int Length of the inner loop. Set to -1 if using `nparts` nparts : int Length of the outer loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the loop is not found Returns ------- (str, str) (outer loop ID, inner loop ID) \"\"\" return super ( Schedule , self ) . split ( ID ( node ), factor , nparts , shift ) def reorder ( self , order ): \"\"\" Reorder directly nested loops To swap consecutive loops, use `swap` instead Parameters ---------- order : array like of str, ID or Stmt Vector of loops. The requested order of the loops Raises ------ InvalidSchedule if the input is invalid or there are breaking dependencies \"\"\" super ( Schedule , self ) . reorder ( list ( map ( ID , order ))) def merge ( self , loop1 , loop2 ): \"\"\" Merge two directly nested loops into one To fuse consecutive loops, use `fuse` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the merged loop Parameters ---------- loop1, loop2 : str, ID or Stmt loops to be merged, can be in any order Raises ------ InvalidSchedule if the loops are not directly nested Returns ------- str ID of the merged loop \"\"\" return super ( Schedule , self ) . merge ( ID ( loop1 ), ID ( loop2 )) def fission ( self , loop , side , splitter , suffix0 = \".a\" , suffix1 = \".b\" ): \"\"\" Fission a loop into two loops each containing part of the statements, one followed by another To split loop into two nested loops, use `split` instead Parameters ---------- loop : str, ID or Stmt The loop to be fissioned side : FissionSide If `After`, `splitter` is the last statement of the first loop. If `Before`, `splitter` is the first statement of the second loop splitter : str, ID or Stmt Where to fission the loop suffix0 : str ID suffix of the statements in the first loop, default to \".a\", can be \"\" for convenience, but cannot be the same with suffix1 suffix1 : str ID suffix of the statements in the second loop, default to \".b\", can be \"\" for convenience, but cannot be the same with suffix0 Raises ------ InvalidSchedule if any dependency cannot be resolved Returns ------- (map, map) ({old ID -> new ID in 1st loop}, {old ID -> new ID in 2nd loop}) \"\"\" return super ( Schedule , self ) . fission ( ID ( loop ), side , ID ( splitter ), suffix0 , suffix1 ) def fuse ( self , loop0 , loop1 = None , strict = False ): \"\"\" Fuse two directly following loops with the same length into one To merge nested loops into one, use `merge` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the fused loop Parameters ---------- loop0 : str, ID or Stmt The leading loop loop1 : str, ID or Stmt, Optional The following loop. If omitted, it will try to find a following loop of `loop0` strict : bool False by default. If set to True, throw an error if unable to determine whether the two loops are of the same length Raises ------ InvalidSchedule if the two loops are not directly following, the two loops are not of the same length, or there is any dependency cannot be resolved Returns ------- str ID of the result loop \"\"\" if loop1 is None : return super ( Schedule , self ) . fuse ( ID ( loop0 ), strict ) else : return super ( Schedule , self ) . fuse ( ID ( loop0 ), ID ( loop1 ), strict ) def swap ( self , order ): \"\"\" Swap statements in the same block To reorder nested loops, use `reorder` instead Parameters ---------- order : array like of str, ID or Stmt The statements Raises ------ InvalidSchedule if the statements are not found or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . swap ( list ( map ( ID , order ))) def blend ( self , loop ): \"\"\" Unroll a loop and interleave statements from each iteration E.g. ``` for i = 0 to 2 { f(i); g(i); } ``` will be transformed to be ``` f(0); f(1); g(0); g(1); ``` Virtual threads in TVM can be implemented via blend Parameters ---------- loop : str, ID or Stmt The loop being transformed Raises ------ InvalidSchedule if the loop is not found, the loop length is not a constant, or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . blend ( ID ( loop )) def cache ( self , stmt , var , mtype ): \"\"\" Cache a variable into a new local variable All needed data will be filled into the cache first, then all reads and writes will be directed to the cache, and finally all needed data will be flushed from the cache Note for reduction: This transformation preserves the computation order. It will transform ``` a += x a += y ``` to ``` a.cache = a + x + y a = a.cache ``` If you need a \"real\" cache for reduction, which reorders the computation, use `cache_reduction` instead Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found Returns ------- (str, str, str, str) (ID of the statement that fills the cache, ID of the statement that flushes from the cache, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache ( ID ( stmt ), var , MemType ( mtype )) def cache_reduction ( self , stmt , var , mtype ): \"\"\" Perform local reductions (e.g. sum) in a local variable first, and then reduce the local result to the global variable E.g. ``` a += x a += y ``` will be transformed to be ``` a.cache = x + y a += a.cache ``` Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached. Only reductions are allowed on `var` in `stmt`. Plain reads or writes are not allowed mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found, or there are unsupported reads or writes Returns ------- (str, str, str, str) (ID of the statement that initialize the cache, ID of the statement that reduces the local result to the global result, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache_reduction ( ID ( stmt ), var , MemType ( mtype )) def set_mem_type ( self , vardef , mtype ): \"\"\" Change where a variable is stored Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable mtype : MemType Where the variable should be stored Raises ------ InvalidSchedule if the variable is not found \"\"\" super ( Schedule , self ) . set_mem_type ( ID ( vardef ), MemType ( mtype )) def var_split ( self , vardef , dim , mode , factor =- 1 , nparts =- 1 ): \"\"\" Split a dimension of a variable into two Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int which dimension to be split mode : VarSplitMode When the dimension to split is not divisible by `factor` or `nparts`, the resulting shape may become larger. In `FixedSize` mode, the actual buffer size will not be changed, and gurads will be added to prevent out-of-bound accesses. In `RelaxedSize` mode, the buffer size may increase. The `RelaxedSize` mode cannot be applied to I/O variables factor : int Length of the inner (higher no.) dimension. Set to -1 if using `nparts` nparts : int Length of the outer (lower no.) loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the variable or the dimension is not found \"\"\" return super ( Schedule , self ) . var_split ( ID ( vardef ), dim , mode , factor , nparts ) def var_merge ( self , vardef , dim ): \"\"\" Merge two dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int Merge the `dim`-th and the `(dim + 1)`-th dimension \"\"\" return super ( Schedule , self ) . var_merge ( ID ( vardef ), dim ) def var_reorder ( self , vardef , order ): \"\"\" Reorder the dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable order : array like of str, ID or Stmt Vector of integers. The new order of the dimensions Raises ------ InvalidSchedule if the variable or the order is illegal \"\"\" return super ( Schedule , self ) . var_reorder ( ID ( vardef ), order ) def move_to ( self , stmt , side , dst ): \"\"\" Move a statement to a new position This is a composite schedule command, which is implemented with other commands Parameters ---------- stmt : str, ID or Stmt The statement to be moved side : MoveToSide Whether `stmt` will be BEFORE or AFTER `dst dst : str, ID or Stmt Insert `stmt` to be directly after this statement Raises ------ InvalidSchedule if there is no feasible path to move Returns ------- str The new ID of stmt \"\"\" return super ( Schedule , self ) . move_to ( ID ( stmt ), side , ID ( dst )) def inline ( self , vardef ): \"\"\" Remove a variable. When the variable is used, recompute its value Parameters ---------- vardef : str, ID or Stmt The VarDef statement of the specific variable. It can not be an I/O varible Raises ------ InvalidSchedule if the variable cannot be completely removed \"\"\" return super ( Schedule , self ) . inline ( ID ( vardef )) def parallelize ( self , loop , parallel ): \"\"\" Mark a loop with a parallel implementation Parameters ---------- loop : str, ID or Stmt The loop parallel : ParallelScope Parallel scope \"\"\" super ( Schedule , self ) . parallelize ( ID ( loop ), ParallelScope ( parallel )) def unroll ( self , loop , immediate = False ): \"\"\" Unroll a loop Parameters ---------- loop : str, ID or Stmt ID of the loop immediate : bool If false (by default), postpone the unroll procedure to the backend compiler, which saves scheduling time. If true, unroll the loop immediately, which may help further simplifications based on the unrolled result. If your purpose is just to fill the instruction cache, set it to false. If you are unrolling a loop that computes array indices, set it to true Raises ------ InvalidSchedule if the loop is not found or length of the loop is not a constant \"\"\" super ( Schedule , self ) . unroll ( ID ( loop ), immediate ) def vectorize ( self , loop ): \"\"\" Vectorize a loop Please note that, as vectorization is different from architecture to achitecture, the scheduler may or may not postpone it to the backend compiler. The vectorization is a best-effort schedule Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the ID or name is not found, or the dependency requirement is not met \"\"\" super ( Schedule , self ) . vectorize ( ID ( loop )) def separate_tail ( self , noDuplicateVarDefs = False ): \"\"\" Seperate main iterations and tail iterations of a loop E.g. ``` for i = 0 -> 3 { for j = 0 -> 4 { if (i * 4 + j < 10) { ... } } } ``` Each loop will be separated into 2 parts: the body and the tail. After simplification, the program will finally be transformed to ``` for i = 0 -> 2 { for j = 0 -> 4 { ... } } for j = 0 -> 2 { ... } ``` Ideally, all programs can benefit from this schedule. However, this schedule may greatly increase the program size and make the compiling time way too long. Therefore, this transformation is implemented as a schedule, which can be applied optionally. (TODO: Optionally apply this schedule to part of the program) Parameters ---------- noDuplicateVarDefs : bool If there is two VarDef nodes in two branches, it may result in doubled memory use, since different thread may go to different branch. Set this parameter to true to stop duplicating VarDef nodes. \"\"\" super ( Schedule , self ) . separate_tail ( noDuplicateVarDefs ) def as_matmul ( self , loop ): \"\"\" Transform nested loops to be a external call to a matrix multiplication Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the loop cannot be transformed to be a matrix multiplication \"\"\" super ( Schedule , self ) . as_matmul ( ID ( loop )) def auto_schedule ( self , target ): \"\"\" (Experimental) Automatic scheduling using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_schedule ( target ) def auto_use_lib ( self , target ): \"\"\" (Experimental) Automatically use external libs using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_use_lib ( target ) def auto_fuse ( self , target ): \"\"\" (Experimental) Automatically fuse consecutive loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_fuse ( target ) def auto_parallelize ( self , target ): \"\"\" (Experimental) Automatically parallelize some loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_parallelize ( target ) def auto_set_mem_type ( self , target ): \"\"\" (Experimental) Automatically set memory types using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_set_mem_type ( target ) def auto_unroll ( self , target ): \"\"\" (Experimental) Automatically unroll loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_unroll ( target )","title":"Schedule"},{"location":"api/#freetensor.core.schedule.Schedule.as_matmul","text":"Transform nested loops to be a external call to a matrix multiplication Parameters: loop ( str, ID or Stmt ) \u2013 ID of the loop Exceptions: InvalidSchedule \u2013 if the loop cannot be transformed to be a matrix multiplication Source code in freetensor/core/schedule.py def as_matmul ( self , loop ): \"\"\" Transform nested loops to be a external call to a matrix multiplication Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the loop cannot be transformed to be a matrix multiplication \"\"\" super ( Schedule , self ) . as_matmul ( ID ( loop ))","title":"as_matmul()"},{"location":"api/#freetensor.core.schedule.Schedule.auto_fuse","text":"(Experimental) Automatically fuse consecutive loops using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_fuse ( self , target ): \"\"\" (Experimental) Automatically fuse consecutive loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_fuse ( target )","title":"auto_fuse()"},{"location":"api/#freetensor.core.schedule.Schedule.auto_parallelize","text":"(Experimental) Automatically parallelize some loops using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_parallelize ( self , target ): \"\"\" (Experimental) Automatically parallelize some loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_parallelize ( target )","title":"auto_parallelize()"},{"location":"api/#freetensor.core.schedule.Schedule.auto_schedule","text":"(Experimental) Automatic scheduling using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_schedule ( self , target ): \"\"\" (Experimental) Automatic scheduling using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_schedule ( target )","title":"auto_schedule()"},{"location":"api/#freetensor.core.schedule.Schedule.auto_set_mem_type","text":"(Experimental) Automatically set memory types using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_set_mem_type ( self , target ): \"\"\" (Experimental) Automatically set memory types using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_set_mem_type ( target )","title":"auto_set_mem_type()"},{"location":"api/#freetensor.core.schedule.Schedule.auto_unroll","text":"(Experimental) Automatically unroll loops using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_unroll ( self , target ): \"\"\" (Experimental) Automatically unroll loops using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_unroll ( target )","title":"auto_unroll()"},{"location":"api/#freetensor.core.schedule.Schedule.auto_use_lib","text":"(Experimental) Automatically use external libs using some heuristics Parameters: target ( Target ) \u2013 Target architecture Source code in freetensor/core/schedule.py def auto_use_lib ( self , target ): \"\"\" (Experimental) Automatically use external libs using some heuristics Parameters ---------- target : Target Target architecture \"\"\" super ( Schedule , self ) . auto_use_lib ( target )","title":"auto_use_lib()"},{"location":"api/#freetensor.core.schedule.Schedule.blend","text":"Unroll a loop and interleave statements from each iteration E.g. for i = 0 to 2 { f(i); g(i); } will be transformed to be f(0); f(1); g(0); g(1); Virtual threads in TVM can be implemented via blend Parameters: loop ( str, ID or Stmt ) \u2013 The loop being transformed Exceptions: InvalidSchedule \u2013 if the loop is not found, the loop length is not a constant, or the dependencies cannot be solved Source code in freetensor/core/schedule.py def blend ( self , loop ): \"\"\" Unroll a loop and interleave statements from each iteration E.g. ``` for i = 0 to 2 { f(i); g(i); } ``` will be transformed to be ``` f(0); f(1); g(0); g(1); ``` Virtual threads in TVM can be implemented via blend Parameters ---------- loop : str, ID or Stmt The loop being transformed Raises ------ InvalidSchedule if the loop is not found, the loop length is not a constant, or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . blend ( ID ( loop ))","title":"blend()"},{"location":"api/#freetensor.core.schedule.Schedule.cache","text":"Cache a variable into a new local variable All needed data will be filled into the cache first, then all reads and writes will be directed to the cache, and finally all needed data will be flushed from the cache Note for reduction: This transformation preserves the computation order. It will transform a += x a += y to a.cache = a + x + y a = a.cache If you need a \"real\" cache for reduction, which reorders the computation, use cache_reduction instead Parameters: stmt ( str, ID or Stmt ) \u2013 The statement or block (e.g. an If or a For) to be modified var ( str ) \u2013 Name of the variable to be cached mtype ( MemType ) \u2013 Where to cache Exceptions: InvalidSchedule \u2013 if the ID or name is not found Returns: (str, str, str, str) \u2013 (ID of the statement that fills the cache, ID of the statement that flushes from the cache, name of the cache variable, ID of the VarDef node of the cache variable) Source code in freetensor/core/schedule.py def cache ( self , stmt , var , mtype ): \"\"\" Cache a variable into a new local variable All needed data will be filled into the cache first, then all reads and writes will be directed to the cache, and finally all needed data will be flushed from the cache Note for reduction: This transformation preserves the computation order. It will transform ``` a += x a += y ``` to ``` a.cache = a + x + y a = a.cache ``` If you need a \"real\" cache for reduction, which reorders the computation, use `cache_reduction` instead Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found Returns ------- (str, str, str, str) (ID of the statement that fills the cache, ID of the statement that flushes from the cache, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache ( ID ( stmt ), var , MemType ( mtype ))","title":"cache()"},{"location":"api/#freetensor.core.schedule.Schedule.cache_reduction","text":"Perform local reductions (e.g. sum) in a local variable first, and then reduce the local result to the global variable E.g. a += x a += y will be transformed to be a.cache = x + y a += a.cache Parameters: stmt ( str, ID or Stmt ) \u2013 The statement or block (e.g. an If or a For) to be modified var ( str ) \u2013 Name of the variable to be cached. Only reductions are allowed on var in stmt . Plain reads or writes are not allowed mtype ( MemType ) \u2013 Where to cache Exceptions: InvalidSchedule \u2013 if the ID or name is not found, or there are unsupported reads or writes Returns: (str, str, str, str) \u2013 (ID of the statement that initialize the cache, ID of the statement that reduces the local result to the global result, name of the cache variable, ID of the VarDef node of the cache variable) Source code in freetensor/core/schedule.py def cache_reduction ( self , stmt , var , mtype ): \"\"\" Perform local reductions (e.g. sum) in a local variable first, and then reduce the local result to the global variable E.g. ``` a += x a += y ``` will be transformed to be ``` a.cache = x + y a += a.cache ``` Parameters ---------- stmt : str, ID or Stmt The statement or block (e.g. an If or a For) to be modified var : str Name of the variable to be cached. Only reductions are allowed on `var` in `stmt`. Plain reads or writes are not allowed mtype : MemType Where to cache Raises ------ InvalidSchedule if the ID or name is not found, or there are unsupported reads or writes Returns ------- (str, str, str, str) (ID of the statement that initialize the cache, ID of the statement that reduces the local result to the global result, name of the cache variable, ID of the VarDef node of the cache variable) \"\"\" return super ( Schedule , self ) . cache_reduction ( ID ( stmt ), var , MemType ( mtype ))","title":"cache_reduction()"},{"location":"api/#freetensor.core.schedule.Schedule.fission","text":"Fission a loop into two loops each containing part of the statements, one followed by another To split loop into two nested loops, use split instead Parameters: loop ( str, ID or Stmt ) \u2013 The loop to be fissioned side ( FissionSide ) \u2013 If After , splitter is the last statement of the first loop. If Before , splitter is the first statement of the second loop splitter ( str, ID or Stmt ) \u2013 Where to fission the loop suffix0 ( str ) \u2013 ID suffix of the statements in the first loop, default to \".a\", can be \"\" for convenience, but cannot be the same with suffix1 suffix1 ( str ) \u2013 ID suffix of the statements in the second loop, default to \".b\", can be \"\" for convenience, but cannot be the same with suffix0 Exceptions: InvalidSchedule \u2013 if any dependency cannot be resolved Returns: (map, map) \u2013 ({old ID -> new ID in 1st loop}, {old ID -> new ID in 2nd loop}) Source code in freetensor/core/schedule.py def fission ( self , loop , side , splitter , suffix0 = \".a\" , suffix1 = \".b\" ): \"\"\" Fission a loop into two loops each containing part of the statements, one followed by another To split loop into two nested loops, use `split` instead Parameters ---------- loop : str, ID or Stmt The loop to be fissioned side : FissionSide If `After`, `splitter` is the last statement of the first loop. If `Before`, `splitter` is the first statement of the second loop splitter : str, ID or Stmt Where to fission the loop suffix0 : str ID suffix of the statements in the first loop, default to \".a\", can be \"\" for convenience, but cannot be the same with suffix1 suffix1 : str ID suffix of the statements in the second loop, default to \".b\", can be \"\" for convenience, but cannot be the same with suffix0 Raises ------ InvalidSchedule if any dependency cannot be resolved Returns ------- (map, map) ({old ID -> new ID in 1st loop}, {old ID -> new ID in 2nd loop}) \"\"\" return super ( Schedule , self ) . fission ( ID ( loop ), side , ID ( splitter ), suffix0 , suffix1 )","title":"fission()"},{"location":"api/#freetensor.core.schedule.Schedule.fuse","text":"Fuse two directly following loops with the same length into one To merge nested loops into one, use merge instead parallelize , unroll and vectorize properties will be reset on the fused loop Parameters: loop0 ( str, ID or Stmt ) \u2013 The leading loop loop1 ( str, ID or Stmt, Optional ) \u2013 The following loop. If omitted, it will try to find a following loop of loop0 strict ( bool ) \u2013 False by default. If set to True, throw an error if unable to determine whether the two loops are of the same length Exceptions: InvalidSchedule \u2013 if the two loops are not directly following, the two loops are not of the same length, or there is any dependency cannot be resolved Returns: str \u2013 ID of the result loop Source code in freetensor/core/schedule.py def fuse ( self , loop0 , loop1 = None , strict = False ): \"\"\" Fuse two directly following loops with the same length into one To merge nested loops into one, use `merge` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the fused loop Parameters ---------- loop0 : str, ID or Stmt The leading loop loop1 : str, ID or Stmt, Optional The following loop. If omitted, it will try to find a following loop of `loop0` strict : bool False by default. If set to True, throw an error if unable to determine whether the two loops are of the same length Raises ------ InvalidSchedule if the two loops are not directly following, the two loops are not of the same length, or there is any dependency cannot be resolved Returns ------- str ID of the result loop \"\"\" if loop1 is None : return super ( Schedule , self ) . fuse ( ID ( loop0 ), strict ) else : return super ( Schedule , self ) . fuse ( ID ( loop0 ), ID ( loop1 ), strict )","title":"fuse()"},{"location":"api/#freetensor.core.schedule.Schedule.inline","text":"Remove a variable. When the variable is used, recompute its value Parameters: vardef ( str, ID or Stmt ) \u2013 The VarDef statement of the specific variable. It can not be an I/O varible Exceptions: InvalidSchedule \u2013 if the variable cannot be completely removed Source code in freetensor/core/schedule.py def inline ( self , vardef ): \"\"\" Remove a variable. When the variable is used, recompute its value Parameters ---------- vardef : str, ID or Stmt The VarDef statement of the specific variable. It can not be an I/O varible Raises ------ InvalidSchedule if the variable cannot be completely removed \"\"\" return super ( Schedule , self ) . inline ( ID ( vardef ))","title":"inline()"},{"location":"api/#freetensor.core.schedule.Schedule.merge","text":"Merge two directly nested loops into one To fuse consecutive loops, use fuse instead parallelize , unroll and vectorize properties will be reset on the merged loop Parameters: loop1, loop2 ( str, ID or Stmt ) \u2013 loops to be merged, can be in any order Exceptions: InvalidSchedule \u2013 if the loops are not directly nested Returns: str \u2013 ID of the merged loop Source code in freetensor/core/schedule.py def merge ( self , loop1 , loop2 ): \"\"\" Merge two directly nested loops into one To fuse consecutive loops, use `fuse` instead `parallelize`, `unroll` and `vectorize` properties will be reset on the merged loop Parameters ---------- loop1, loop2 : str, ID or Stmt loops to be merged, can be in any order Raises ------ InvalidSchedule if the loops are not directly nested Returns ------- str ID of the merged loop \"\"\" return super ( Schedule , self ) . merge ( ID ( loop1 ), ID ( loop2 ))","title":"merge()"},{"location":"api/#freetensor.core.schedule.Schedule.move_to","text":"Move a statement to a new position This is a composite schedule command, which is implemented with other commands Parameters: stmt ( str, ID or Stmt ) \u2013 The statement to be moved side ( MoveToSide ) \u2013 Whether stmt will be BEFORE or AFTER `dst dst ( str, ID or Stmt ) \u2013 Insert stmt to be directly after this statement Exceptions: InvalidSchedule \u2013 if there is no feasible path to move Returns: str \u2013 The new ID of stmt Source code in freetensor/core/schedule.py def move_to ( self , stmt , side , dst ): \"\"\" Move a statement to a new position This is a composite schedule command, which is implemented with other commands Parameters ---------- stmt : str, ID or Stmt The statement to be moved side : MoveToSide Whether `stmt` will be BEFORE or AFTER `dst dst : str, ID or Stmt Insert `stmt` to be directly after this statement Raises ------ InvalidSchedule if there is no feasible path to move Returns ------- str The new ID of stmt \"\"\" return super ( Schedule , self ) . move_to ( ID ( stmt ), side , ID ( dst ))","title":"move_to()"},{"location":"api/#freetensor.core.schedule.Schedule.parallelize","text":"Mark a loop with a parallel implementation Parameters: loop ( str, ID or Stmt ) \u2013 The loop parallel ( ParallelScope ) \u2013 Parallel scope Source code in freetensor/core/schedule.py def parallelize ( self , loop , parallel ): \"\"\" Mark a loop with a parallel implementation Parameters ---------- loop : str, ID or Stmt The loop parallel : ParallelScope Parallel scope \"\"\" super ( Schedule , self ) . parallelize ( ID ( loop ), ParallelScope ( parallel ))","title":"parallelize()"},{"location":"api/#freetensor.core.schedule.Schedule.reorder","text":"Reorder directly nested loops To swap consecutive loops, use swap instead Parameters: order ( array like of str, ID or Stmt ) \u2013 Vector of loops. The requested order of the loops Exceptions: InvalidSchedule \u2013 if the input is invalid or there are breaking dependencies Source code in freetensor/core/schedule.py def reorder ( self , order ): \"\"\" Reorder directly nested loops To swap consecutive loops, use `swap` instead Parameters ---------- order : array like of str, ID or Stmt Vector of loops. The requested order of the loops Raises ------ InvalidSchedule if the input is invalid or there are breaking dependencies \"\"\" super ( Schedule , self ) . reorder ( list ( map ( ID , order )))","title":"reorder()"},{"location":"api/#freetensor.core.schedule.Schedule.separate_tail","text":"Seperate main iterations and tail iterations of a loop E.g. for i = 0 -> 3 { for j = 0 -> 4 { if (i * 4 + j < 10) { ... } } } Each loop will be separated into 2 parts: the body and the tail. After simplification, the program will finally be transformed to for i = 0 -> 2 { for j = 0 -> 4 { ... } } for j = 0 -> 2 { ... } Ideally, all programs can benefit from this schedule. However, this schedule may greatly increase the program size and make the compiling time way too long. Therefore, this transformation is implemented as a schedule, which can be applied optionally. (TODO: Optionally apply this schedule to part of the program) Parameters: noDuplicateVarDefs ( bool ) \u2013 If there is two VarDef nodes in two branches, it may result in doubled memory use, since different thread may go to different branch. Set this parameter to true to stop duplicating VarDef nodes. Source code in freetensor/core/schedule.py def separate_tail ( self , noDuplicateVarDefs = False ): \"\"\" Seperate main iterations and tail iterations of a loop E.g. ``` for i = 0 -> 3 { for j = 0 -> 4 { if (i * 4 + j < 10) { ... } } } ``` Each loop will be separated into 2 parts: the body and the tail. After simplification, the program will finally be transformed to ``` for i = 0 -> 2 { for j = 0 -> 4 { ... } } for j = 0 -> 2 { ... } ``` Ideally, all programs can benefit from this schedule. However, this schedule may greatly increase the program size and make the compiling time way too long. Therefore, this transformation is implemented as a schedule, which can be applied optionally. (TODO: Optionally apply this schedule to part of the program) Parameters ---------- noDuplicateVarDefs : bool If there is two VarDef nodes in two branches, it may result in doubled memory use, since different thread may go to different branch. Set this parameter to true to stop duplicating VarDef nodes. \"\"\" super ( Schedule , self ) . separate_tail ( noDuplicateVarDefs )","title":"separate_tail()"},{"location":"api/#freetensor.core.schedule.Schedule.set_mem_type","text":"Change where a variable is stored Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable mtype ( MemType ) \u2013 Where the variable should be stored Exceptions: InvalidSchedule \u2013 if the variable is not found Source code in freetensor/core/schedule.py def set_mem_type ( self , vardef , mtype ): \"\"\" Change where a variable is stored Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable mtype : MemType Where the variable should be stored Raises ------ InvalidSchedule if the variable is not found \"\"\" super ( Schedule , self ) . set_mem_type ( ID ( vardef ), MemType ( mtype ))","title":"set_mem_type()"},{"location":"api/#freetensor.core.schedule.Schedule.split","text":"Split a loop into two nested loops To fission a loop into two consecutive loops, use fission instead Two modes are provided: Specify factor and leave nparts to -1. It will result in an outer loop with length ceil(n / factor) , and an inner loop with length factor , where n is the original loop length added by shift . The original iterator i will be transformed to i0 * factor + i1 , where i0 and i1 are the iterators of the new outer and inner loops, respectively Specify nparts and leave factor to -1. It will result in an outer loop with length nparts , and an inner loop with length ceil(n / nparts) , where n is the original loop length added by shift . The original iterator i will be transformed to i0 * ceil(n / nparts) + i1 , where i0 and i1 are the iterators of the new outer and inner loops, respectively Please note that the second mode will introduce an i0 * ceil(n / nparts) factor into the program, which cannot be recognized by polyhedral analysis, which may hinder some following schedules. If possible, plese use the first mode, and then reorder the inner and outer loops Parameters: node ( str, ID or Stmt ) \u2013 The loop to be split factor ( int ) \u2013 Length of the inner loop. Set to -1 if using nparts nparts ( int ) \u2013 Length of the outer loop. Set to -1 if using factor Exceptions: InvalidSchedule \u2013 if the loop is not found Returns: (str, str) \u2013 (outer loop ID, inner loop ID) Source code in freetensor/core/schedule.py def split ( self , node , factor =- 1 , nparts =- 1 , shift = 0 ): \"\"\" Split a loop into two nested loops To fission a loop into two consecutive loops, use `fission` instead Two modes are provided: 1. Specify `factor` and leave `nparts` to -1. It will result in an outer loop with length `ceil(n / factor)`, and an inner loop with length `factor`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * factor + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively 2. Specify `nparts` and leave `factor` to -1. It will result in an outer loop with length `nparts`, and an inner loop with length `ceil(n / nparts)`, where `n` is the original loop length added by `shift`. The original iterator `i` will be transformed to `i0 * ceil(n / nparts) + i1`, where `i0` and `i1` are the iterators of the new outer and inner loops, respectively Please note that the second mode will introduce an `i0 * ceil(n / nparts)` factor into the program, which cannot be recognized by polyhedral analysis, which may hinder some following schedules. If possible, plese use the first mode, and then reorder the inner and outer loops Parameters ---------- node : str, ID or Stmt The loop to be split factor : int Length of the inner loop. Set to -1 if using `nparts` nparts : int Length of the outer loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the loop is not found Returns ------- (str, str) (outer loop ID, inner loop ID) \"\"\" return super ( Schedule , self ) . split ( ID ( node ), factor , nparts , shift )","title":"split()"},{"location":"api/#freetensor.core.schedule.Schedule.swap","text":"Swap statements in the same block To reorder nested loops, use reorder instead Parameters: order ( array like of str, ID or Stmt ) \u2013 The statements Exceptions: InvalidSchedule \u2013 if the statements are not found or the dependencies cannot be solved Source code in freetensor/core/schedule.py def swap ( self , order ): \"\"\" Swap statements in the same block To reorder nested loops, use `reorder` instead Parameters ---------- order : array like of str, ID or Stmt The statements Raises ------ InvalidSchedule if the statements are not found or the dependencies cannot be solved \"\"\" super ( Schedule , self ) . swap ( list ( map ( ID , order )))","title":"swap()"},{"location":"api/#freetensor.core.schedule.Schedule.unroll","text":"Unroll a loop Parameters: loop ( str, ID or Stmt ) \u2013 ID of the loop immediate ( bool ) \u2013 If false (by default), postpone the unroll procedure to the backend compiler, which saves scheduling time. If true, unroll the loop immediately, which may help further simplifications based on the unrolled result. If your purpose is just to fill the instruction cache, set it to false. If you are unrolling a loop that computes array indices, set it to true Exceptions: InvalidSchedule \u2013 if the loop is not found or length of the loop is not a constant Source code in freetensor/core/schedule.py def unroll ( self , loop , immediate = False ): \"\"\" Unroll a loop Parameters ---------- loop : str, ID or Stmt ID of the loop immediate : bool If false (by default), postpone the unroll procedure to the backend compiler, which saves scheduling time. If true, unroll the loop immediately, which may help further simplifications based on the unrolled result. If your purpose is just to fill the instruction cache, set it to false. If you are unrolling a loop that computes array indices, set it to true Raises ------ InvalidSchedule if the loop is not found or length of the loop is not a constant \"\"\" super ( Schedule , self ) . unroll ( ID ( loop ), immediate )","title":"unroll()"},{"location":"api/#freetensor.core.schedule.Schedule.var_merge","text":"Merge two dimensions of a variable Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable dim ( int ) \u2013 Merge the dim -th and the (dim + 1) -th dimension Source code in freetensor/core/schedule.py def var_merge ( self , vardef , dim ): \"\"\" Merge two dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int Merge the `dim`-th and the `(dim + 1)`-th dimension \"\"\" return super ( Schedule , self ) . var_merge ( ID ( vardef ), dim )","title":"var_merge()"},{"location":"api/#freetensor.core.schedule.Schedule.var_reorder","text":"Reorder the dimensions of a variable Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable order ( array like of str, ID or Stmt ) \u2013 Vector of integers. The new order of the dimensions Exceptions: InvalidSchedule \u2013 if the variable or the order is illegal Source code in freetensor/core/schedule.py def var_reorder ( self , vardef , order ): \"\"\" Reorder the dimensions of a variable Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable order : array like of str, ID or Stmt Vector of integers. The new order of the dimensions Raises ------ InvalidSchedule if the variable or the order is illegal \"\"\" return super ( Schedule , self ) . var_reorder ( ID ( vardef ), order )","title":"var_reorder()"},{"location":"api/#freetensor.core.schedule.Schedule.var_split","text":"Split a dimension of a variable into two Parameters: vardef ( str, ID or Stmt ) \u2013 ID of the VarDef statement of the specific variable dim ( int ) \u2013 which dimension to be split mode ( VarSplitMode ) \u2013 When the dimension to split is not divisible by factor or nparts , the resulting shape may become larger. In FixedSize mode, the actual buffer size will not be changed, and gurads will be added to prevent out-of-bound accesses. In RelaxedSize mode, the buffer size may increase. The RelaxedSize mode cannot be applied to I/O variables factor ( int ) \u2013 Length of the inner (higher no.) dimension. Set to -1 if using nparts nparts ( int ) \u2013 Length of the outer (lower no.) loop. Set to -1 if using factor Exceptions: InvalidSchedule \u2013 if the variable or the dimension is not found Source code in freetensor/core/schedule.py def var_split ( self , vardef , dim , mode , factor =- 1 , nparts =- 1 ): \"\"\" Split a dimension of a variable into two Parameters ---------- vardef : str, ID or Stmt ID of the VarDef statement of the specific variable dim : int which dimension to be split mode : VarSplitMode When the dimension to split is not divisible by `factor` or `nparts`, the resulting shape may become larger. In `FixedSize` mode, the actual buffer size will not be changed, and gurads will be added to prevent out-of-bound accesses. In `RelaxedSize` mode, the buffer size may increase. The `RelaxedSize` mode cannot be applied to I/O variables factor : int Length of the inner (higher no.) dimension. Set to -1 if using `nparts` nparts : int Length of the outer (lower no.) loop. Set to -1 if using `factor` Raises ------ InvalidSchedule if the variable or the dimension is not found \"\"\" return super ( Schedule , self ) . var_split ( ID ( vardef ), dim , mode , factor , nparts )","title":"var_split()"},{"location":"api/#freetensor.core.schedule.Schedule.vectorize","text":"Vectorize a loop Please note that, as vectorization is different from architecture to achitecture, the scheduler may or may not postpone it to the backend compiler. The vectorization is a best-effort schedule Parameters: loop ( str, ID or Stmt ) \u2013 ID of the loop Exceptions: InvalidSchedule \u2013 if the ID or name is not found, or the dependency requirement is not met Source code in freetensor/core/schedule.py def vectorize ( self , loop ): \"\"\" Vectorize a loop Please note that, as vectorization is different from architecture to achitecture, the scheduler may or may not postpone it to the backend compiler. The vectorization is a best-effort schedule Parameters ---------- loop : str, ID or Stmt ID of the loop Raises ------ InvalidSchedule if the ID or name is not found, or the dependency requirement is not met \"\"\" super ( Schedule , self ) . vectorize ( ID ( loop ))","title":"vectorize()"},{"location":"api/#freetensor.core.schedule.schedule","text":"Apply any schedule on an AST through a user callback Parameters: ast ( Func or Stmt ) \u2013 The AST to schedule. If not specified, a partial function will be returned that cna be used as a decorator callback ( Callable[[freetensor.core.schedule.Schedule], NoneType] ) \u2013 Specify what schedule(s) to do in this callback verbose ( Optional[int] ) \u2013 0 = print nothing. 1 = print the final AST. 2 = print an AST after each schedule Source code in freetensor/core/schedule.py def schedule ( ast = None , callback : Callable [[ Schedule ], None ] = None , verbose : Optional [ int ] = None ): ''' Apply any schedule on an AST through a user callback Parameters ---------- ast : Func or Stmt The AST to schedule. If not specified, a partial function will be returned that cna be used as a decorator callback : Callable Specify what schedule(s) to do in this callback verbose : int (Optional) 0 = print nothing. 1 = print the final AST. 2 = print an AST after each schedule ''' if ast is not None : if callback is None : return ast if verbose is None : verbose = 0 s = Schedule ( ast , verbose = verbose ) callback ( s ) if ast . type () == ffi . ASTNodeType . Func : return s . func () else : return s . ast () else : f = schedule if callback is not None : f = functools . partial ( f , callback = callback ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f","title":"schedule()"},{"location":"api/#freetensor.core.stmt","text":"Facility to build AST statements Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module. Classes and functions in this module are all in BigCamel naming style, to distinguish from expressions in expr.py","title":"stmt"},{"location":"api/#freetensor.core.stmt.Assert","text":"Scope used to create an Assert node This scope is internally used by transformer and tests E.g.: with Assert(i > 0): ... # Assertion body Source code in freetensor/core/stmt.py class Assert : ''' Scope used to create an Assert node This scope is internally used by `transformer` and tests E.g.: ``` with Assert(i > 0): ... # Assertion body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () nid = top . get_next_nid () top . append_stmt ( ffi . makeAssert ( nid , self . cond , body ))","title":"Assert"},{"location":"api/#freetensor.core.stmt.Else","text":"Scope used to create an else branch of an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # True branch with Else(): ... # Else branch Source code in freetensor/core/stmt.py class Else : ''' Scope used to create an else branch of an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # True branch with Else(): ... # Else branch ``` ''' def __init__ ( self ): pass def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_else_stmt ( body )","title":"Else"},{"location":"api/#freetensor.core.stmt.For","text":"Scope used to create a For node This scope is internally used by transformer and tests E.g.: with For('i', 0, n) as i: ... # Loop body Source code in freetensor/core/stmt.py class For : ''' Scope used to create a For node This scope is internally used by `transformer` and tests E.g.: ``` with For('i', 0, n) as i: ... # Loop body ``` ''' def __init__ ( self , iter_var : str , begin , end , step = 1 , nid : str = \"\" , no_deps : Optional [ Sequence [ str ]] = None , prefer_libs : Optional [ bool ] = None ): self . iter_var = iter_var self . begin = begin self . end = end self . step = step self . nid = nid self . no_deps = no_deps self . prefer_libs = prefer_libs self . borrowed_vardefs = set () for x in [ begin , end , step ]: for name in ffi . all_reads ( ffi . Expr ( x )): self . borrowed_vardefs . add ( open_vardefs [ name ]) def __enter__ ( self ): for item in self . borrowed_vardefs : item . lend_out () ctx_stack . push () return ffi . makeVar ( self . iter_var ) def __exit__ ( self , exc_type , exc_value , traceback ): for item in self . borrowed_vardefs : item . reclaim () if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () top . append_for_stmt ( self . iter_var , self . begin , self . end , self . step , body , nid = self . nid , no_deps = self . no_deps , prefer_libs = self . prefer_libs )","title":"For"},{"location":"api/#freetensor.core.stmt.If","text":"Scope used to create an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # Branch body Source code in freetensor/core/stmt.py class If : ''' Scope used to create an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # Branch body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_then_stmt ( self . cond , body )","title":"If"},{"location":"api/#freetensor.core.stmt.NamedScope","text":"Scope used to create an StmtSeq node with an explicit ID E.g.: with NamedScope(): ... # body This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes Source code in freetensor/core/stmt.py class NamedScope : ''' Scope used to create an StmtSeq node with an explicit ID E.g.: ``` with NamedScope(): ... # body ``` This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes ''' def __init__ ( self , nid : str ): self . nid = nid def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt ( self . nid ) ctx_stack . top () . append_stmt ( body )","title":"NamedScope"},{"location":"api/#freetensor.core.stmt.Any","text":"Create an Any node (only for testing) Any nodes matches any statement nodes in ast.match Source code in freetensor/core/stmt.py def Any (): ''' Create an Any node (only for testing) Any nodes matches any statement nodes in `ast.match` ''' ctx_stack . top () . append_stmt ( ffi . makeAny ())","title":"Any()"},{"location":"api/#freetensor.core.stmt.Eval","text":"Create an Eval node This scope is internally used by transformer and tests Source code in freetensor/core/stmt.py def Eval ( expr ): ''' Create an Eval node This scope is internally used by `transformer` and tests ''' top = ctx_stack . top () top . append_stmt ( ffi . makeEval ( top . get_next_nid (), expr ))","title":"Eval()"},{"location":"api/#freetensor.core.stmt.Invoke","text":"Inlined invocation of another AST This scope is internally used by transformer and tests Invoke can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use inline in transformer instead, which supports generic types Source code in freetensor/core/stmt.py def Invoke ( func , * args , ** kvs ): ''' Inlined invocation of another AST This scope is internally used by `transformer` and tests `Invoke` can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use `inline` in `transformer` instead, which supports generic types ''' top = ctx_stack . top () top . append_stmt ( ffi . inlined_invoke ( top . get_next_nid (), func , args , kvs ))","title":"Invoke()"},{"location":"api/#freetensor.core.stmt.MarkNid","text":"Mark the ID of the following statement This scope is internally used by transformer and tests Source code in freetensor/core/stmt.py def MarkNid ( nid : str ): \"\"\" Mark the ID of the following statement This scope is internally used by `transformer` and tests \"\"\" ctx_stack . top () . set_next_nid ( nid )","title":"MarkNid()"},{"location":"api/#freetensor.core.stmt.VarDef","text":"A factory function that creates a VarDef or a series of nested VarDef s This scope is internally used by transformer and tests Source code in freetensor/core/stmt.py def VarDef ( * args ): ''' A factory function that creates a VarDef or a series of nested `VarDef`s This scope is internally used by `transformer` and tests ''' if len ( args ) == 1 : return _VarsDef ( args [ 0 ]) else : return _VarDef ( * args )","title":"VarDef()"},{"location":"api/#freetensor.core.transformer","text":"Transform user Python functions to ASTs via generating staging functions.","title":"transformer"},{"location":"api/#freetensor.core.transformer.FunctionScope","text":"FunctionScope(filename: str, funcname: str) Source code in freetensor/core/transformer.py @dataclass class FunctionScope : filename : str funcname : str def __enter__ ( self ): StagingContext . call_stack . append ( traceback . FrameSummary ( self . filename , 1 , self . funcname )) StagingContext . allow_return_stack . append ( True ) def __exit__ ( self , exc_class , exc_value , traceback ): if exc_class is None : StagingContext . call_stack . pop () StagingContext . allow_return_stack . pop ()","title":"FunctionScope"},{"location":"api/#freetensor.core.transformer.NamingScope","text":"Source code in freetensor/core/transformer.py class NamingScope ( FunctionScope ): def __init__ ( self , filename : str , funcname : str , namespace : Optional [ str ]) -> None : super () . __init__ ( filename , funcname ) if len ( StagingContext . id_stack ) > 0 and namespace is None : raise StagingError ( 'Namespace must not be None for inner levels.' ) self . namespace = namespace self . ids = {} def __enter__ ( self ): super () . __enter__ () StagingContext . id_stack . append ( self ) def __exit__ ( self , _1 , _2 , _3 ): super () . __exit__ ( _1 , _2 , _3 ) popped = StagingContext . id_stack . pop () if popped != self : raise StagingError ( 'NamingScope enter/exit not match, must be FILO' ) def fullid ( self , nid : str ): if self . namespace is not None : prefix = self . namespace + '->' else : prefix = '' if nid in self . ids : suffix = '$' + str ( self . ids [ nid ]) self . ids [ nid ] += 1 else : suffix = '' self . ids [ nid ] = 1 return prefix + nid + suffix","title":"NamingScope"},{"location":"api/#freetensor.core.transformer.NamingScope.__init__","text":"Initialize self. See help(type(self)) for accurate signature. Source code in freetensor/core/transformer.py def __init__ ( self , filename : str , funcname : str , namespace : Optional [ str ]) -> None : super () . __init__ ( filename , funcname ) if len ( StagingContext . id_stack ) > 0 and namespace is None : raise StagingError ( 'Namespace must not be None for inner levels.' ) self . namespace = namespace self . ids = {}","title":"__init__()"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator","text":"Source code in freetensor/core/transformer.py class PredefinedVarCreator ( VarCreator ): def __init__ ( self , initializer : List [ Any ], dtype : str , mtype : str ): def get_shape ( lst ): if not isinstance ( lst , list ): assert ndim ( lst ) == 0 return () if len ( lst ) == 0 : return ( 0 ,) shape_ = get_shape ( lst [ 0 ]) for x in lst [ 1 :]: assert shape_ == get_shape ( x ) return ( len ( lst ),) + shape_ super () . __init__ ( get_shape ( initializer ), dtype , mtype ) self . initializer = initializer def assign ( self , name : str ) -> VarRef : var = super () . assign ( name ) def impl ( var_slice , init_slice ): if not isinstance ( init_slice , list ): var_slice [()] = init_slice else : for i , x in enumerate ( init_slice ): impl ( var_slice [ i ], x ) impl ( var , self . initializer ) return var","title":"PredefinedVarCreator"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.__class__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls )","title":"__class__"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.__class__.__instancecheck__","text":"Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance )","title":"__instancecheck__()"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.__class__.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls","title":"__new__()"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.__class__.__subclasscheck__","text":"Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass )","title":"__subclasscheck__()"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.__class__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.__init__","text":"Initialize self. See help(type(self)) for accurate signature. Source code in freetensor/core/transformer.py def __init__ ( self , initializer : List [ Any ], dtype : str , mtype : str ): def get_shape ( lst ): if not isinstance ( lst , list ): assert ndim ( lst ) == 0 return () if len ( lst ) == 0 : return ( 0 ,) shape_ = get_shape ( lst [ 0 ]) for x in lst [ 1 :]: assert shape_ == get_shape ( x ) return ( len ( lst ),) + shape_ super () . __init__ ( get_shape ( initializer ), dtype , mtype ) self . initializer = initializer","title":"__init__()"},{"location":"api/#freetensor.core.transformer.PredefinedVarCreator.assign","text":"Customized assign behavior. Creates a VarDef with its full name. Source code in freetensor/core/transformer.py def assign ( self , name : str ) -> VarRef : var = super () . assign ( name ) def impl ( var_slice , init_slice ): if not isinstance ( init_slice , list ): var_slice [()] = init_slice else : for i , x in enumerate ( init_slice ): impl ( var_slice [ i ], x ) impl ( var , self . initializer ) return var","title":"assign()"},{"location":"api/#freetensor.core.transformer.StagedAssignable","text":"Source code in freetensor/core/transformer.py class StagedAssignable ( abc . ABC ): @abc . abstractmethod def assign ( self , name : str ) -> VarRef : raise NotImplementedError ()","title":"StagedAssignable"},{"location":"api/#freetensor.core.transformer.StagedAssignable.__class__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls )","title":"__class__"},{"location":"api/#freetensor.core.transformer.StagedAssignable.__class__.__instancecheck__","text":"Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance )","title":"__instancecheck__()"},{"location":"api/#freetensor.core.transformer.StagedAssignable.__class__.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls","title":"__new__()"},{"location":"api/#freetensor.core.transformer.StagedAssignable.__class__.__subclasscheck__","text":"Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass )","title":"__subclasscheck__()"},{"location":"api/#freetensor.core.transformer.StagedAssignable.__class__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.StagedPredicate","text":"Source code in freetensor/core/transformer.py class StagedPredicate ( abc . ABC ): @abc . abstractmethod def if_then_else_stmt ( self , then_body : Callable [[], None ], else_body : Optional [ Callable [[], None ]]): raise NotImplementedError () @abc . abstractmethod def if_then_else_expr ( self , then_expr : Callable [[], Any ], else_expr : Callable [[], Any ]): raise NotImplementedError () @abc . abstractmethod def while_stmt ( self , body : Callable [[], None ]): raise NotImplementedError ()","title":"StagedPredicate"},{"location":"api/#freetensor.core.transformer.StagedPredicate.__class__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls )","title":"__class__"},{"location":"api/#freetensor.core.transformer.StagedPredicate.__class__.__instancecheck__","text":"Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance )","title":"__instancecheck__()"},{"location":"api/#freetensor.core.transformer.StagedPredicate.__class__.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls","title":"__new__()"},{"location":"api/#freetensor.core.transformer.StagedPredicate.__class__.__subclasscheck__","text":"Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass )","title":"__subclasscheck__()"},{"location":"api/#freetensor.core.transformer.StagedPredicate.__class__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotation","text":"Source code in freetensor/core/transformer.py class StagedTypeAnnotation ( metaclass = StagedTypeAnnotationMeta ): @abc . abstractmethod def annotate ( self , name : str ) -> VarRef : raise NotImplementedError ()","title":"StagedTypeAnnotation"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotation.__class__","text":"Source code in freetensor/core/transformer.py class StagedTypeAnnotationMeta ( abc . ABCMeta ): def __getitem__ ( self , args ): return self ( * args )","title":"__class__"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotation.__class__.__base__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"__base__"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotation.__class__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta","text":"Source code in freetensor/core/transformer.py class StagedTypeAnnotationMeta ( abc . ABCMeta ): def __getitem__ ( self , args ): return self ( * args )","title":"StagedTypeAnnotationMeta"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta.__base__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls )","title":"__base__"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta.__base__.__instancecheck__","text":"Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance )","title":"__instancecheck__()"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta.__base__.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls","title":"__new__()"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta.__base__.__subclasscheck__","text":"Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass )","title":"__subclasscheck__()"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta.__base__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.StagedTypeAnnotationMeta.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.StagingContext","text":"Helper class managing context in IR staging. Source code in freetensor/core/transformer.py class StagingContext : '''Helper class managing context in IR staging.''' id_stack : List [ NamingScope ] = [] lifetime_stack : List [ LifetimeScope ] = [] allow_return_stack : List [ bool ] = [] closure : Dict [ str , Any ] = {} call_stack : List [ traceback . FrameSummary ] = [] name_dict : Dict [ str , int ] = {} @staticmethod def register_implicit_scope ( scope ): return StagingContext . lifetime_stack [ - 1 ] . register_implicit_scope ( scope ) @staticmethod def fullid ( nid : str ) -> str : '''Get namespace-prepended full nid of given short nid.''' return StagingContext . id_stack [ - 1 ] . fullid ( nid ) @staticmethod def fullname ( name : str ) -> str : '''Get distinct name.''' if name in StagingContext . name_dict : StagingContext . name_dict [ name ] += 1 return f ' { name } _ { StagingContext . name_dict [ name ] } ' else : StagingContext . name_dict [ name ] = 0 return name @staticmethod def allow_return (): return StagingContext . allow_return_stack [ - 1 ] @staticmethod def in_staging (): return len ( StagingContext . lifetime_stack ) > 0 @staticmethod def reset (): StagingContext . id_stack . clear () StagingContext . lifetime_stack . clear () StagingContext . closure = {} StagingContext . call_stack = [] StagingContext . name_dict = {}","title":"StagingContext"},{"location":"api/#freetensor.core.transformer.StagingContext.fullid","text":"Get namespace-prepended full nid of given short nid. Source code in freetensor/core/transformer.py @staticmethod def fullid ( nid : str ) -> str : '''Get namespace-prepended full nid of given short nid.''' return StagingContext . id_stack [ - 1 ] . fullid ( nid )","title":"fullid()"},{"location":"api/#freetensor.core.transformer.StagingContext.fullname","text":"Get distinct name. Source code in freetensor/core/transformer.py @staticmethod def fullname ( name : str ) -> str : '''Get distinct name.''' if name in StagingContext . name_dict : StagingContext . name_dict [ name ] += 1 return f ' { name } _ { StagingContext . name_dict [ name ] } ' else : StagingContext . name_dict [ name ] = 0 return name","title":"fullname()"},{"location":"api/#freetensor.core.transformer.StagingError","text":"Error occurred during staging function execution (i.e. IR tree generation). Source code in freetensor/core/transformer.py class StagingError ( Exception ): '''Error occurred during staging function execution (i.e. IR tree generation).''' def __init__ ( self , message : str ) -> None : # TODO: add output of StagingContext.call_stack super () . __init__ ( f ' { message } : \\n { \"\" . join ( traceback . format_list ( StagingContext . call_stack [ 1 :])) } ' . lstrip ())","title":"StagingError"},{"location":"api/#freetensor.core.transformer.TransformError","text":"Error occurred during AST transforming from python function to staging function that generates IR tree. Source code in freetensor/core/transformer.py class TransformError ( Exception ): '''Error occurred during AST transforming from python function to staging function that generates IR tree.''' def __init__ ( self , message : str , filename : str , base_lineno : int , error_node : ast . AST ) -> None : super () . __init__ ( f 'At { filename } : { base_lineno + error_node . lineno } : \\n { message } .' )","title":"TransformError"},{"location":"api/#freetensor.core.transformer.Transformer","text":"Transformer(filename: str, base_lineno: int, curr_func: str = None, nonlocals: List[List[str]] = None) Source code in freetensor/core/transformer.py @dataclass class Transformer ( ast . NodeTransformer ): filename : str base_lineno : int curr_func : str = None nonlocals : List [ List [ str ]] = None def visit ( self , node : ast . AST ): new_node = super () . visit ( node ) if isinstance ( node , ast . stmt ) and not isinstance ( node , ast . FunctionDef ): if not isinstance ( new_node , list ): new_node = [ new_node ] return location_helper ([ ast . Expr ( call_helper ( mark_position , ast . Constant ( self . base_lineno ), ast . Constant ( node . lineno ))) ] + new_node , node ) return new_node def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = assign('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = assign('lhs', rhs)` ''' node : ast . Assign = self . generic_visit ( old_node ) # FIXME: multi-assign not implemented if len ( node . targets ) == 1 and ( isinstance ( node . targets [ 0 ], ast . Name ) or isinstance ( node . targets [ 0 ], ast . Attribute )): name = None if isinstance ( node . targets [ 0 ], ast . Name ): name = node . targets [ 0 ] . id elif isinstance ( node . targets [ 0 ], ast . Attribute ): name = node . targets [ 0 ] . attr if name is not None : node = ast . Assign ( node . targets , call_helper ( assign_stmt , ast . Constant ( name ), node . value )) return location_helper ( node , old_node ) def handleType_AnnAssign ( self , node : ast . AnnAssign ) -> Any : x = node . target assert isinstance ( x , ast . Name ) assert node . value is None x_str = ast . Constant ( x . id ) Ty = node . annotation intermediate = f 'freetensor__annotate__ { x . id } ' intermediate_store = ast . Name ( intermediate , ast . Store ()) intermediate_load = ast . Name ( intermediate , ast . Load ()) node = [ ast . Assign ([ intermediate_store ], call_helper ( annotate_stmt , x_str , Ty )), ast . If ( intermediate_load , [ ast . Assign ([ x ], intermediate_load )], []) ] return node def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if isinstance ( old_node . target , ast . Name ) and len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # while opening a fake function, For loops initiates an iter name as well. # need to remove it from the outer nonlocals list to implement shadowing. # only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) if old_node . target . id in nonlocals : nonlocals . remove ( old_node . target . id ) nonlocals = list ( nonlocals ) node = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ node . target . id ], node . body , nonlocals ), ast . Expr ( call_helper ( foreach , ast . Constant ( node . target . id ), node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return location_helper ( node , old_node ) def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( while_stmt , ast . Lambda ( _empty_args , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return location_helper ( node , old_node ) def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( if_then_else_stmt , test , then_body , else_body ))) return location_helper ( new_node , old_node ) def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( if_then_else_expr , node . test , ast . Lambda ( _empty_args , node . body ), ast . Lambda ( _empty_args , node . orelse )) return location_helper ( node , old_node ) def visit_FunctionDef ( self , old_node : ast . FunctionDef ) -> Any : prev_func = self . curr_func self . curr_func = old_node . name # nested functions follow original Python (shitty) scoping, # thus backup the nonlocals stack and prepare a clean one. prev_nonlocals = self . nonlocals self . nonlocals = None with NonlocalTransformingScope ( self ): # mark arguments as nonlocal for name in old_node . args . args + old_node . args . kwonlyargs : self . nonlocals [ - 1 ] . append ( name . arg ) if old_node . args . vararg : self . nonlocals [ - 1 ] . append ( old_node . args . vararg . arg ) if old_node . args . kwarg : self . nonlocals [ - 1 ] . append ( old_node . args . kwarg . arg ) node : ast . FunctionDef = self . generic_visit ( old_node ) node . decorator_list = [] node . body = [ ast . With ( items = [ ast . withitem ( context_expr = call_helper ( functiondef_wrapper , ast . Constant ( self . filename ), ast . Constant ( node . name )), optional_vars = None ) ], body = [ stmt for arg in node . args . posonlyargs + node . args . args if arg . annotation for stmt in self . handleType_AnnAssign ( location_helper ( ast . AnnAssign ( ast . Name ( arg . arg , ast . Store ( )), arg . annotation , None , 1 ), old_node )) ] + node . body ) ] for arg in [ node . args . vararg , node . args . kwarg ] + node . args . posonlyargs + node . args . args + node . args . kwonlyargs : if arg is not None : arg . annotation = None self . curr_func = prev_func self . nonlocals = prev_nonlocals return location_helper ( node , old_node ) def visit_Assert ( self , old_node : ast . Assert ) -> Any : node : ast . Assert = self . generic_visit ( old_node ) node = ast . Expr ( call_helper ( assert_stmt , node . test )) return location_helper ( node , old_node ) def visit_BoolOp ( self , old_node : ast . BoolOp ) -> Any : node : ast . BoolOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . And ): libfunc = and_expr elif isinstance ( node . op , ast . Or ): libfunc = or_expr else : return location_helper ( node , old_node ) node = call_helper ( libfunc , * [ ast . Lambda ( _empty_args , v ) for v in node . values ]) return location_helper ( node , old_node ) def visit_UnaryOp ( self , old_node : ast . UnaryOp ) -> Any : node : ast . UnaryOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . Not ): node = call_helper ( not_expr , node . operand ) return location_helper ( node , old_node ) def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( location_helper ( node , old_node )) def visit_Attribute ( self , old_node : ast . Attribute ) -> Any : node : ast . Attribute = self . generic_visit ( old_node ) if isinstance ( node . ctx , ast . Load ): node = call_helper ( load_attr , node . value , ast . Constant ( node . attr )) return location_helper ( node , old_node ) def visit_Return ( self , old_node : ast . Return ) -> Any : node : ast . Return = self . generic_visit ( old_node ) assert self . curr_func is not None node = ast . Return ( call_helper ( return_stmt , node . value , ast . Constant ( self . curr_func ))) return location_helper ( node , old_node ) def visit_Lambda ( self , old_node : ast . Lambda ) -> Any : with NonlocalTransformingScope ( self ): node : ast . Lambda = self . generic_visit ( old_node ) return location_helper ( node , old_node ) def visit_comprehension ( self , old_node : ast . comprehension ) -> Any : with NonlocalTransformingScope ( self ): node : ast . comprehension = self . generic_visit ( old_node ) return location_helper ( node , old_node ) def visit_Name ( self , node : ast . Name ) -> Any : if isinstance ( node . ctx , ast . Store ): self . nonlocals [ - 1 ] . append ( node . id ) return self . generic_visit ( node ) def visit_AsyncFunctionDef ( self , node : ast . AsyncFunctionDef ) -> Any : raise TransformError ( 'Async functions not supported.' , self . filename , self . base_lineno , node ) def visit_ClassDef ( self , node : ast . ClassDef ) -> Any : raise TransformError ( 'Class definitions not supported.' , self . filename , self . base_lineno , node )","title":"Transformer"},{"location":"api/#freetensor.core.transformer.Transformer.generic_visit","text":"Called if no explicit visitor function exists for a node. Source code in freetensor/core/transformer.py def generic_visit ( self , node ): for field , old_value in iter_fields ( node ): if isinstance ( old_value , list ): new_values = [] for value in old_value : if isinstance ( value , AST ): value = self . visit ( value ) if value is None : continue elif not isinstance ( value , AST ): new_values . extend ( value ) continue new_values . append ( value ) old_value [:] = new_values elif isinstance ( old_value , AST ): new_node = self . visit ( old_value ) if new_node is None : delattr ( node , field ) else : setattr ( node , field , new_node ) return node","title":"generic_visit()"},{"location":"api/#freetensor.core.transformer.Transformer.visit","text":"Visit a node. Source code in freetensor/core/transformer.py def visit ( self , node : ast . AST ): new_node = super () . visit ( node ) if isinstance ( node , ast . stmt ) and not isinstance ( node , ast . FunctionDef ): if not isinstance ( new_node , list ): new_node = [ new_node ] return location_helper ([ ast . Expr ( call_helper ( mark_position , ast . Constant ( self . base_lineno ), ast . Constant ( node . lineno ))) ] + new_node , node ) return new_node","title":"visit()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_AnnAssign","text":"Rule: x: Ty -> freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x : pure annotation Source code in freetensor/core/transformer.py def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node","title":"visit_AnnAssign()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_Assign","text":"Rule: lhs = rhs -> lhs = assign('lhs', rhs) x.lhs = rhs -> x.lhs = assign('lhs', rhs) Source code in freetensor/core/transformer.py def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = assign('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = assign('lhs', rhs)` ''' node : ast . Assign = self . generic_visit ( old_node ) # FIXME: multi-assign not implemented if len ( node . targets ) == 1 and ( isinstance ( node . targets [ 0 ], ast . Name ) or isinstance ( node . targets [ 0 ], ast . Attribute )): name = None if isinstance ( node . targets [ 0 ], ast . Name ): name = node . targets [ 0 ] . id elif isinstance ( node . targets [ 0 ], ast . Attribute ): name = node . targets [ 0 ] . attr if name is not None : node = ast . Assign ( node . targets , call_helper ( assign_stmt , ast . Constant ( name ), node . value )) return location_helper ( node , old_node )","title":"visit_Assign()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_Compare","text":"Expand multiple comparison into and expression. Source code in freetensor/core/transformer.py def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( location_helper ( node , old_node ))","title":"visit_Compare()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_For","text":"Rule: for x in iter: body -> def for_body(x): body foreach('x', iter, for_body) Source code in freetensor/core/transformer.py def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if isinstance ( old_node . target , ast . Name ) and len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # while opening a fake function, For loops initiates an iter name as well. # need to remove it from the outer nonlocals list to implement shadowing. # only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) if old_node . target . id in nonlocals : nonlocals . remove ( old_node . target . id ) nonlocals = list ( nonlocals ) node = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ node . target . id ], node . body , nonlocals ), ast . Expr ( call_helper ( foreach , ast . Constant ( node . target . id ), node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return location_helper ( node , old_node )","title":"visit_For()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_If","text":"Rule: if pred: body else: orelse -> def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) Source code in freetensor/core/transformer.py def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( if_then_else_stmt , test , then_body , else_body ))) return location_helper ( new_node , old_node )","title":"visit_If()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_IfExp","text":"Rule: body if test else orelse -> if_then_else_expr(test, body, orelse) Source code in freetensor/core/transformer.py def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( if_then_else_expr , node . test , ast . Lambda ( _empty_args , node . body ), ast . Lambda ( _empty_args , node . orelse )) return location_helper ( node , old_node )","title":"visit_IfExp()"},{"location":"api/#freetensor.core.transformer.Transformer.visit_While","text":"Rule: while pred: body -> def while_body(): body while_stmt(lambda: pred, while_body) Source code in freetensor/core/transformer.py def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( while_stmt , ast . Lambda ( _empty_args , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return location_helper ( node , old_node )","title":"visit_While()"},{"location":"api/#freetensor.core.transformer.Var","text":"Source code in freetensor/core/transformer.py class Var ( StagedTypeAnnotation ): def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype def annotate ( self , name : str ) -> VarRef : return StagingContext . register_implicit_scope ( _VarDef ( prepare_vardef ( name ), self . shape , self . dtype , self . atype , self . mtype ))","title":"Var"},{"location":"api/#freetensor.core.transformer.Var.__class__","text":"Source code in freetensor/core/transformer.py class StagedTypeAnnotationMeta ( abc . ABCMeta ): def __getitem__ ( self , args ): return self ( * args )","title":"__class__"},{"location":"api/#freetensor.core.transformer.Var.__class__.__base__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls ) __instancecheck__ ( cls , instance ) special Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) __new__ ( mcls , name , bases , namespace , ** kwargs ) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls __subclasscheck__ ( cls , subclass ) special Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"__base__"},{"location":"api/#freetensor.core.transformer.Var.__class__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.Var.__init__","text":"Declare a variable Parameters: name ( str ) \u2013 Name of the variable shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable atype ( str or AccessType ) \u2013 Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Source code in freetensor/core/transformer.py def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype","title":"__init__()"},{"location":"api/#freetensor.core.transformer.VarCreator","text":"VarCreator(shape: Union[Sequence, freetensor.core.expr.VarRef], dtype: str, mtype: str) Source code in freetensor/core/transformer.py @dataclass class VarCreator ( StagedAssignable ): shape : Union [ Sequence , VarRef ] dtype : str mtype : str def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' return StagingContext . register_implicit_scope ( _VarDef ( prepare_vardef ( name ), self . shape , self . dtype , 'cache' , self . mtype ))","title":"VarCreator"},{"location":"api/#freetensor.core.transformer.VarCreator.__class__","text":"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Source code in freetensor/core/transformer.py class ABCMeta ( type ): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass ) def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance ) def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass ) def _dump_registry ( cls , file = None ): \"\"\"Debug helper to print the ABC registry.\"\"\" print ( f \"Class: { cls . __module__ } . { cls . __qualname__ } \" , file = file ) print ( f \"Inv. counter: { get_cache_token () } \" , file = file ) ( _abc_registry , _abc_cache , _abc_negative_cache , _abc_negative_cache_version ) = _get_dump ( cls ) print ( f \"_abc_registry: { _abc_registry !r} \" , file = file ) print ( f \"_abc_cache: { _abc_cache !r} \" , file = file ) print ( f \"_abc_negative_cache: { _abc_negative_cache !r} \" , file = file ) print ( f \"_abc_negative_cache_version: { _abc_negative_cache_version !r} \" , file = file ) def _abc_registry_clear ( cls ): \"\"\"Clear the registry (for debugging or testing).\"\"\" _reset_registry ( cls ) def _abc_caches_clear ( cls ): \"\"\"Clear the caches (for debugging or testing).\"\"\" _reset_caches ( cls )","title":"__class__"},{"location":"api/#freetensor.core.transformer.VarCreator.__class__.__instancecheck__","text":"Override for isinstance(instance, cls). Source code in freetensor/core/transformer.py def __instancecheck__ ( cls , instance ): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck ( cls , instance )","title":"__instancecheck__()"},{"location":"api/#freetensor.core.transformer.VarCreator.__class__.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in freetensor/core/transformer.py def __new__ ( mcls , name , bases , namespace , ** kwargs ): cls = super () . __new__ ( mcls , name , bases , namespace , ** kwargs ) _abc_init ( cls ) return cls","title":"__new__()"},{"location":"api/#freetensor.core.transformer.VarCreator.__class__.__subclasscheck__","text":"Override for issubclass(subclass, cls). Source code in freetensor/core/transformer.py def __subclasscheck__ ( cls , subclass ): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck ( cls , subclass )","title":"__subclasscheck__()"},{"location":"api/#freetensor.core.transformer.VarCreator.__class__.register","text":"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. Source code in freetensor/core/transformer.py def register ( cls , subclass ): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register ( cls , subclass )","title":"register()"},{"location":"api/#freetensor.core.transformer.VarCreator.assign","text":"Customized assign behavior. Creates a VarDef with its full name. Source code in freetensor/core/transformer.py def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' return StagingContext . register_implicit_scope ( _VarDef ( prepare_vardef ( name ), self . shape , self . dtype , 'cache' , self . mtype ))","title":"assign()"},{"location":"api/#freetensor.core.transformer.dynamic_range","text":"Dynamic range that generates For loop in IR tree. Source code in freetensor/core/transformer.py class dynamic_range ( StagedIterable ): '''Dynamic range that generates For loop in IR tree.''' def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step def foreach ( self , name : str , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' with For ( StagingContext . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var )","title":"dynamic_range"},{"location":"api/#freetensor.core.transformer.dynamic_range.__init__","text":"Initialize a dynamic range. Arguments semantic identical to builtin range . Source code in freetensor/core/transformer.py def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step","title":"__init__()"},{"location":"api/#freetensor.core.transformer.dynamic_range.foreach","text":"Customized foreach behavior. Creates a For loop. Source code in freetensor/core/transformer.py def foreach ( self , name : str , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' with For ( StagingContext . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var )","title":"foreach()"},{"location":"api/#freetensor.core.transformer.assert_stmt","text":"Assert staging tool. Source code in freetensor/core/transformer.py def assert_stmt ( test ): '''Assert staging tool.''' if isinstance ( test , ffi . Expr ): StagingContext . register_implicit_scope ( Assert ( test )) else : assert test","title":"assert_stmt()"},{"location":"api/#freetensor.core.transformer.assign_stmt","text":"Customized assign wrapper. If value is instance of StagedAssignable , it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. Source code in freetensor/core/transformer.py def assign_stmt ( name : str , value ): '''Customized assign wrapper. If `value` is instance of `StagedAssignable`, it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. ''' if isinstance ( value , StagedAssignable ): return value . assign ( name ) else : return value","title":"assign_stmt()"},{"location":"api/#freetensor.core.transformer.call_helper","text":"Call helper that generates a python AST Call node with given callee and arguments AST node. Source code in freetensor/core/transformer.py def call_helper ( callee , * args : ast . expr , ** kwargs : ast . expr ): '''Call helper that generates a python AST Call node with given callee and arguments AST node.''' return ast . Call ( module_helper ( callee ), list ( args ), [ ast . keyword ( k , w ) for k , w in kwargs . items ()])","title":"call_helper()"},{"location":"api/#freetensor.core.transformer.capture_var","text":"Capture external array as tensor variable. Source code in freetensor/core/transformer.py def impl ( * args , ** kwargs ): if StagingContext . in_staging (): return staging ( * args , ** kwargs ) else : return original ( * args , ** kwargs )","title":"capture_var()"},{"location":"api/#freetensor.core.transformer.empty","text":"Create an empty variable Parameters: shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Source code in freetensor/core/transformer.py def impl ( * args , ** kwargs ): if StagingContext . in_staging (): return staging ( * args , ** kwargs ) else : return original ( * args , ** kwargs )","title":"empty()"},{"location":"api/#freetensor.core.transformer.foreach","text":"Customized foreach wrapper. If value is instance of StagedIterable , its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. Source code in freetensor/core/transformer.py def foreach ( name : str , iter , body : Callable [[ Any ], None ]) -> None : '''Customized foreach wrapper. If `value` is instance of `StagedIterable`, its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. ''' if isinstance ( iter , StagedIterable ): iter . foreach ( name , body ) else : for iter_var in iter : body ( iter_var )","title":"foreach()"},{"location":"api/#freetensor.core.transformer.function_helper","text":"Function helper that generates a python AST FunctionDef node with given name, arguments name, and body. Source code in freetensor/core/transformer.py def function_helper ( name : str , args : Sequence [ str ], body : List [ ast . stmt ], nonlocals : List [ str ]): '''Function helper that generates a python AST FunctionDef node with given name, arguments name, and body.''' nonlocal_body = ([ ast . Nonlocal ( nonlocals )] if len ( nonlocals ) > 0 else []) + body return ast . FunctionDef ( name = name , args = ast . arguments ( args = [], vararg = None , kwarg = None , posonlyargs = [ ast . arg ( a , None ) for a in args ], defaults = [], kwonlyargs = [], kw_defaults = []), body = nonlocal_body , returns = None , decorator_list = [])","title":"function_helper()"},{"location":"api/#freetensor.core.transformer.if_then_else_expr","text":"If-then-else expression staging tool. Source code in freetensor/core/transformer.py def if_then_else_expr ( predicate , then_expr , else_expr ): '''If-then-else expression staging tool.''' if isinstance ( predicate , StagedPredicate ): return predicate . if_then_else_expr ( then_expr , else_expr ) else : if predicate : return then_expr () else : return else_expr ()","title":"if_then_else_expr()"},{"location":"api/#freetensor.core.transformer.if_then_else_stmt","text":"If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. Source code in freetensor/core/transformer.py def if_then_else_stmt ( predicate , then_body , else_body = None ): '''If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. ''' if isinstance ( predicate , StagedPredicate ): predicate . if_then_else_stmt ( then_body , else_body ) else : if predicate : then_body () elif else_body : else_body ()","title":"if_then_else_stmt()"},{"location":"api/#freetensor.core.transformer.inline","text":"Enable a user function to be called by a transformed function at run time Parameters: func ( Python function ) \u2013 The user function src ( str (Optional) ) \u2013 The source code of func . This parameter is only required if the source code cannot be get automatically, e.g., if func is generated from a exec default_dynamic_range ( bool ) \u2013 If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose ( bool ) \u2013 True to print the generated Python code that is used for transforming Source code in freetensor/core/transformer.py def inline ( func = None , src = None , fallback = None , default_dynamic_range = True , verbose = False ): ''' Enable a user function to be called by a transformed function at run time Parameters ---------- func : Python function The user function src : str (Optional) The source code of `func`. This parameter is only required if the source code cannot be get automatically, e.g., if `func` is generated from a `exec` default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : bool True to print the generated Python code that is used for transforming ''' extra_locals = _prepare_extra_locals ( default_dynamic_range ) def decorator ( func ): return functools . wraps ( func )( staged_callable ( into_staging ( func , extra_locals , src , verbose = verbose )[ 0 ], fallback or func )) if callable ( func ): return decorator ( func ) else : return decorator","title":"inline()"},{"location":"api/#freetensor.core.transformer.load_attr","text":"Load attribute staging tool. Allows customization of reading attributes. Source code in freetensor/core/transformer.py def load_attr ( obj , attr : str ): '''Load attribute staging tool. Allows customization of reading attributes.''' try : return getattr ( obj , attr ) except AttributeError : if attr == \"ndim\" : return ndim ( obj ) if attr == \"shape\" : return lambda i = None : shape ( obj , i ) if attr == \"dtype\" : return dtype ( obj ) if attr == \"mtype\" : return mtype ( obj ) raise","title":"load_attr()"},{"location":"api/#freetensor.core.transformer.module_helper","text":"Helper to get an AST node with full path to given symbol, which should be in current module. Source code in freetensor/core/transformer.py def module_helper ( callee ): '''Helper to get an AST node with full path to given symbol, which should be in current module.''' return ast . Attribute ( ast . Attribute ( ast . Name ( '__ft__' , ast . Load ()), 'transformer' , ast . Load ()), callee . __name__ , ast . Load ())","title":"module_helper()"},{"location":"api/#freetensor.core.transformer.return_stmt","text":"Return staging tool. Only allow return in static control flow. Source code in freetensor/core/transformer.py def return_stmt ( value , funcname ): '''Return staging tool. Only allow return in static control flow.''' if not StagingContext . allow_return (): raise StagingError ( 'Return is only allowed in statically deterministic control flow.' ) if isinstance ( value , StagedAssignable ): value = value . assign ( funcname ) return value","title":"return_stmt()"},{"location":"api/#freetensor.core.transformer.transform","text":"Transform a user function to an AST Parameters: func ( Python function ) \u2013 The user function to transform. If not specified, a partial function will be returend, which can be used as a decorator default_dynamic_range ( bool ) \u2013 If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose ( int ) \u2013 0 = print nothing. 1 = print the resulting AST. 2 = 1 + print the generated Python code that is used for transforming Source code in freetensor/core/transformer.py def transform ( func = None , default_dynamic_range = True , verbose : int = 0 ): ''' Transform a user function to an AST Parameters ---------- func : Python function The user function to transform. If not specified, a partial function will be returend, which can be used as a decorator default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int 0 = print nothing. 1 = print the resulting AST. 2 = 1 + print the generated Python code that is used for transforming ''' if verbose is None : verbose = 0 extra_locals = _prepare_extra_locals ( default_dynamic_range ) def decorator ( func ): params = list ( inspect . signature ( func ) . parameters ) staging_func , filename , funcname = into_staging ( func , extra_locals , verbose = verbose >= 2 ) try : with LifetimeScope (): with NamingScope ( filename , funcname , None ): # for p in params: # StagingContext.id_stack[-1].ids[p] = 1 # StagingContext.name_dict[p] = 0 returns = staging_func ( * params ) if isinstance ( returns , VarRef ): returns = [ returns ] elif isinstance ( returns , tuple ): for ret in returns : if not isinstance ( ret , VarRef ): raise StagingError ( 'Illegal return at top level, need to be a `VarRef` or a tuple of `VarRef`s' ) returns = list ( returns ) elif returns is None : returns = [] else : raise StagingError ( 'Illegal return at top level, need to be a `VarRef` or a tuple of `VarRef`s' ) for ret in returns : if ret . vardef . atype == 'input' or ret . vardef . atype == 'inout' : ret . vardef . set_atype ( 'inout' ) else : ret . vardef . set_atype ( 'output' ) returns = [ ( ret . vardef . name , ret . vardef . dtype ) for ret in returns ] closure = StagingContext . closure except Exception as e : raise StagingError ( 'Exception occurred in staging' ) from e finally : StagingContext . reset () staged_ast = pop_ast () staged = Func ( func . __name__ , params + list ( closure . keys ()), returns , staged_ast , closure ) if verbose >= 1 : print ( \"The transformed AST is:\" , file = sys . stderr ) print ( staged , file = sys . stderr ) print ( file = sys . stderr ) return staged if callable ( func ): return decorator ( func ) else : return decorator","title":"transform()"},{"location":"api/#freetensor.core.transformer.var","text":"Create an with variable a given initializer Parameters: initializer ( Sequence[Sequence[...Sequence[Expr]...]] ) \u2013 (Multi-level of) sequence of expressions. Will be data of the variable shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Source code in freetensor/core/transformer.py def impl ( * args , ** kwargs ): if StagingContext . in_staging (): return staging ( * args , ** kwargs ) else : return original ( * args , ** kwargs )","title":"var()"},{"location":"api/#freetensor.core.transformer.while_stmt","text":"While statement staging tool. Source code in freetensor/core/transformer.py def while_stmt ( fpred , body ): '''While statement staging tool.''' first_pred = fpred () if isinstance ( first_pred , StagedPredicate ): first_pred . while_stmt ( body ) else : if first_pred : body () while fpred (): body ()","title":"while_stmt()"},{"location":"api/#freetensor.libop","text":"","title":"libop"},{"location":"api/#freetensor.libop.assign","text":"","title":"assign"},{"location":"api/#freetensor.libop.assign.add_to","text":"(Broadcasted) add to a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"add_to()"},{"location":"api/#freetensor.libop.assign.assign","text":"(Broadcasted) assign to a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"assign()"},{"location":"api/#freetensor.libop.assign.floordiv_to","text":"(Broadcasted) rounding-towards-negative-infinity integer division (following Python convention, but not C) from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"floordiv_to()"},{"location":"api/#freetensor.libop.assign.mod_to","text":"(Broadcasted) modulo (results are non-negative, following Python convention, but not C) from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"mod_to()"},{"location":"api/#freetensor.libop.assign.mul_to","text":"(Broadcasted) multiply to a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"mul_to()"},{"location":"api/#freetensor.libop.assign.sub_to","text":"(Broadcasted) subtract from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sub_to()"},{"location":"api/#freetensor.libop.assign.truediv_to","text":"(Broadcasted) floating-point division from a tensor two another tensor Parameters: y ( VarRef ) \u2013 The target tensor x ( VarRef ) \u2013 The source tensor Source code in freetensor/libop/assign.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"truediv_to()"},{"location":"api/#freetensor.libop.constant","text":"","title":"constant"},{"location":"api/#freetensor.libop.constant.zeros","text":"Create a zero tensor Parameters: shape ( Sequence[Expr] or Var ) \u2013 Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype ( str or DataType ) \u2013 Data type of the variable mtype ( str or MemType (Optional) ) \u2013 Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Returns: The zero tensor Source code in freetensor/libop/constant.py @core . inline def zeros ( shape , dtype , mtype = None ): ''' Create a zero tensor Parameters ---------- shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Returns ------- VarRef : The zero tensor ''' y = core . empty ( shape , dtype , mtype ) #! nid: recur zeros_ ( y ) return y","title":"zeros()"},{"location":"api/#freetensor.libop.constant.zeros_","text":"Fill zeros to a tensor Parameters: y ( VarRef ) \u2013 The tensor to fill Source code in freetensor/libop/constant.py @core . inline def zeros_ ( y ): ''' Fill zeros to a tensor Parameters ---------- y : VarRef The tensor to fill ''' if core . ndim ( y ) == 0 : y [()] = 0 else : #! nid: L_elem for i in range ( core . shape ( y , 0 )): #! nid: recur zeros_ ( y [ i ])","title":"zeros_()"},{"location":"api/#freetensor.libop.conv","text":"","title":"conv"},{"location":"api/#freetensor.libop.conv.conv","text":"Convolution. The result is returned Parameters follow ONNX convention. Currently only 2-D convolution is supported Source code in freetensor/libop/conv.py @core . inline def conv ( X , W , B = None , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , group : int = 1 , kernel_shape : Optional [ Sequence [ int ]] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Convolution. The result is returned Parameters follow ONNX convention. Currently only 2-D convolution is supported ''' n_spatial_dim = 2 # Currently only 2-D convolution is supported (TODO) if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" dtype = core . up_cast ( X . dtype , W . dtype ) mtype = core . same_mtype ( X . mtype , W . mtype ) if B is not None : dtype = core . up_cast ( dtype , B . dtype ) mtype = core . same_mtype ( mtype , B . mtype ) #! nid: V_Y Y = core . empty ([ X . shape ( 0 ), W . shape ( 0 ), calc_out_size ( X . shape ( 2 ), dilations [ 0 ], W . shape ( 2 ), pads [ 0 ], pads [ 2 ], strides [ 0 ]), calc_out_size ( X . shape ( 3 ), dilations [ 1 ], W . shape ( 3 ), pads [ 1 ], pads [ 3 ], strides [ 1 ]) ], dtype , mtype ) #! nid: recur conv_ ( X , W , B , Y , auto_pad , dilations , group , kernel_shape , pads , strides ) return Y","title":"conv()"},{"location":"api/#freetensor.libop.conv.conv_","text":"Convolution. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D convolution is supported Source code in freetensor/libop/conv.py @core . inline def conv_ ( X , W , B , Y , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , group : int = 1 , kernel_shape : Optional [ Sequence [ int ]] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Convolution. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D convolution is supported ''' n_spatial_dim = 2 # Currently only 2-D convolution is supported (TODO) if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : assert kernel_shape is not None , \"SAME_UPPER pad with dynamic kernel_shape is currently not supported\" # TODO pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" if B is None : # yapf: disable #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_g for g in range ( group ): #! nid: L_c_out for c_out in range ( W . shape ( 0 ) // group ): #! nid: L_h for h in range ( Y . shape ( 2 )): #! nid: L_w for w in range ( Y . shape ( 3 )): #! nid: init Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] = 0 #! nid: L_c_in for c_in in range ( W . shape ( 1 )): #! nid: L_kh for kh in range ( W . shape ( 2 )): #! nid: L_kw for kw in range ( W . shape ( 3 )): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! nid: compute Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] += X [ n , g * W . shape ( 1 ) + c_in , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] ] * W [ g * ( W . shape ( 0 ) // group ) + c_out , c_in , kh , kw ] # yapf: enable else : # yapf: disable #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_g for g in range ( group ): #! nid: L_c_out for c_out in range ( W . shape ( 0 ) // group ): #! nid: L_h for h in range ( Y . shape ( 2 )): #! nid: L_w for w in range ( Y . shape ( 3 )): #! nid: init Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] = B [ g * ( W . shape ( 0 ) // group ) + c_out ] #! nid: L_c_in for c_in in range ( W . shape ( 1 )): #! nid: L_kh for kh in range ( W . shape ( 2 )): #! nid: L_kw for kw in range ( W . shape ( 3 )): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! nid: compute Y [ n , g * ( W . shape ( 0 ) // group ) + c_out , h , w ] += X [ n , g * W . shape ( 1 ) + c_in , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] ] * W [ g * ( W . shape ( 0 ) // group ) + c_out , c_in , kh , kw ] # yapf: enable","title":"conv_()"},{"location":"api/#freetensor.libop.element_wise","text":"","title":"element_wise"},{"location":"api/#freetensor.libop.element_wise.abs","text":"Element-wise absolute value of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"abs()"},{"location":"api/#freetensor.libop.element_wise.abs_","text":"Element-wise absolute value of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"abs_()"},{"location":"api/#freetensor.libop.element_wise.add","text":"(Broadcasted) element-wise addition of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"add()"},{"location":"api/#freetensor.libop.element_wise.add_","text":"(Broadcasted) element-wise addition of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"add_()"},{"location":"api/#freetensor.libop.element_wise.ceil","text":"Element-wise ceil of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ceil()"},{"location":"api/#freetensor.libop.element_wise.ceil_","text":"Element-wise ceil of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ceil_()"},{"location":"api/#freetensor.libop.element_wise.ceildiv","text":"(Broadcasted) element-wise rounding-towards-positive-infinity integer division of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ceildiv()"},{"location":"api/#freetensor.libop.element_wise.ceildiv_","text":"(Broadcasted) element-wise rounding-towards-positive-infinity integer division of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ceildiv_()"},{"location":"api/#freetensor.libop.element_wise.eq","text":"(Broadcasted) element-wise equal of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"eq()"},{"location":"api/#freetensor.libop.element_wise.eq_","text":"(Broadcasted) element-wise equal of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"eq_()"},{"location":"api/#freetensor.libop.element_wise.exp","text":"Element-wise natrual exponent of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"exp()"},{"location":"api/#freetensor.libop.element_wise.exp_","text":"Element-wise natrual exponent of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"exp_()"},{"location":"api/#freetensor.libop.element_wise.floor","text":"Element-wise floor of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"floor()"},{"location":"api/#freetensor.libop.element_wise.floor_","text":"Element-wise floor of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"floor_()"},{"location":"api/#freetensor.libop.element_wise.floordiv","text":"(Broadcasted) element-wise rounding-towards-negative-infinity integer division (following Python convention, but not C, recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"floordiv()"},{"location":"api/#freetensor.libop.element_wise.floordiv_","text":"(Broadcasted) element-wise rounding-towards-negative-infinity integer division (following Python convention, but not C, recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"floordiv_()"},{"location":"api/#freetensor.libop.element_wise.ge","text":"(Broadcasted) element-wise greater-than-or-equal-to of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ge()"},{"location":"api/#freetensor.libop.element_wise.ge_","text":"(Broadcasted) element-wise greater-than-or-equal-to of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ge_()"},{"location":"api/#freetensor.libop.element_wise.gt","text":"(Broadcasted) element-wise greater-than of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"gt()"},{"location":"api/#freetensor.libop.element_wise.gt_","text":"(Broadcasted) element-wise greater-than of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"gt_()"},{"location":"api/#freetensor.libop.element_wise.l_and","text":"(Broadcasted) element-wise logical and of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"l_and()"},{"location":"api/#freetensor.libop.element_wise.l_and_","text":"(Broadcasted) element-wise logical and of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"l_and_()"},{"location":"api/#freetensor.libop.element_wise.l_not","text":"Element-wise logical not of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"l_not()"},{"location":"api/#freetensor.libop.element_wise.l_not_","text":"Element-wise logical not of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"l_not_()"},{"location":"api/#freetensor.libop.element_wise.l_or","text":"(Broadcasted) element-wise logical or of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"l_or()"},{"location":"api/#freetensor.libop.element_wise.l_or_","text":"(Broadcasted) element-wise logical or of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"l_or_()"},{"location":"api/#freetensor.libop.element_wise.le","text":"(Broadcasted) element-wise less-than-or-equal-to of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"le()"},{"location":"api/#freetensor.libop.element_wise.le_","text":"(Broadcasted) element-wise less-than-or-equal-to of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"le_()"},{"location":"api/#freetensor.libop.element_wise.lt","text":"(Broadcasted) element-wise less-than of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"lt()"},{"location":"api/#freetensor.libop.element_wise.lt_","text":"(Broadcasted) element-wise less-than of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"lt_()"},{"location":"api/#freetensor.libop.element_wise.max","text":"(Broadcasted) element-wise maximum of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"max()"},{"location":"api/#freetensor.libop.element_wise.max_","text":"(Broadcasted) element-wise maximum of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"max_()"},{"location":"api/#freetensor.libop.element_wise.min","text":"(Broadcasted) element-wise minimum of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"min()"},{"location":"api/#freetensor.libop.element_wise.min_","text":"(Broadcasted) element-wise minimum of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"min_()"},{"location":"api/#freetensor.libop.element_wise.mod","text":"(Broadcasted) element-wise modulo (results are non-negative, following Python convention, but not C, recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"mod()"},{"location":"api/#freetensor.libop.element_wise.mod_","text":"(Broadcasted) element-wise modulo (results are non-negative, following Python convention, but not C, recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"mod_()"},{"location":"api/#freetensor.libop.element_wise.mul","text":"(Broadcasted) element-wise multiplication of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"mul()"},{"location":"api/#freetensor.libop.element_wise.mul_","text":"(Broadcasted) element-wise multiplication of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"mul_()"},{"location":"api/#freetensor.libop.element_wise.ne","text":"(Broadcasted) element-wise non-equal of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ne()"},{"location":"api/#freetensor.libop.element_wise.ne_","text":"(Broadcasted) element-wise non-equal of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"ne_()"},{"location":"api/#freetensor.libop.element_wise.neg","text":"Element-wise negation of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"neg()"},{"location":"api/#freetensor.libop.element_wise.neg_","text":"Element-wise negation of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"neg_()"},{"location":"api/#freetensor.libop.element_wise.relu","text":"Element-wise ReLU of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"relu()"},{"location":"api/#freetensor.libop.element_wise.relu_","text":"Element-wise ReLU of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"relu_()"},{"location":"api/#freetensor.libop.element_wise.remainder","text":"(Broadcasted) element-wise remainder (results can be positive or negative, following C convention, but not Python, NOT recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"remainder()"},{"location":"api/#freetensor.libop.element_wise.remainder_","text":"(Broadcasted) element-wise remainder (results can be positive or negative, following C convention, but not Python, NOT recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"remainder_()"},{"location":"api/#freetensor.libop.element_wise.round_towards_0_div","text":"(Broadcasted) element-wise rounding-towards-0 integer division (following C convention, but not Python, NOT recommended for performance) of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"round_towards_0_div()"},{"location":"api/#freetensor.libop.element_wise.round_towards_0_div_","text":"(Broadcasted) element-wise rounding-towards-0 integer division (following C convention, but not Python, NOT recommended for performance) of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"round_towards_0_div_()"},{"location":"api/#freetensor.libop.element_wise.sigmoid","text":"Element-wise sigmoid of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sigmoid()"},{"location":"api/#freetensor.libop.element_wise.sigmoid_","text":"Element-wise sigmoid of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sigmoid_()"},{"location":"api/#freetensor.libop.element_wise.sqrt","text":"Element-wise square root of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sqrt()"},{"location":"api/#freetensor.libop.element_wise.sqrt_","text":"Element-wise square root of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sqrt_()"},{"location":"api/#freetensor.libop.element_wise.square","text":"Element-wise square of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"square()"},{"location":"api/#freetensor.libop.element_wise.square_","text":"Element-wise square of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"square_()"},{"location":"api/#freetensor.libop.element_wise.sub","text":"(Broadcasted) element-wise subtraction of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sub()"},{"location":"api/#freetensor.libop.element_wise.sub_","text":"(Broadcasted) element-wise subtraction of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"sub_()"},{"location":"api/#freetensor.libop.element_wise.tanh","text":"Element-wise tanh of a tensor and return the result Parameters: x ( VarRef ) \u2013 The input tensor Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"tanh()"},{"location":"api/#freetensor.libop.element_wise.tanh_","text":"Element-wise tanh of a tensor. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"tanh_()"},{"location":"api/#freetensor.libop.element_wise.truediv","text":"(Broadcasted) element-wise floating-point division of two tensors and return the result Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"truediv()"},{"location":"api/#freetensor.libop.element_wise.truediv_","text":"(Broadcasted) element-wise floating-point division of two tensors. The result is written to another tensor Parameters: a ( VarRef ) \u2013 Left-hand-side operand b ( VarRef ) \u2013 Right-hand-side operand out ( VarRef ) \u2013 The result tensor Source code in freetensor/libop/element_wise.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"truediv_()"},{"location":"api/#freetensor.libop.matmul","text":"","title":"matmul"},{"location":"api/#freetensor.libop.matmul.einsum","text":"Einstein summation. The result is returned Parameters: fmt ( str ) \u2013 The format string. E.g. \"ik,kj->ij\" represents a matrix multiplcation args ( Sequence[VarRef] ) \u2013 All inputs arguments. E.g. if fmt is \"ik,kj->ij\" , it iterates axis i and k of args[0] , axis k and j of args[1] , axis i and j of the returned value Returns: The result tensor Source code in freetensor/libop/matmul.py @core . inline def einsum ( fmt : str , * args ): ''' Einstein summation. The result is returned Parameters ---------- fmt : str The format string. E.g. `\"ik,kj->ij\"` represents a matrix multiplcation args : Sequence[VarRef] All inputs arguments. E.g. if `fmt` is `\"ik,kj->ij\"`, it iterates axis `i` and `k` of `args[0]`, axis `k` and `j` of `args[1]`, axis `i` and `j` of the returned value Returns ------- VarRef : The result tensor ''' lefts , right = fmt . split ( '->' ) lefts = lefts . split ( ',' ) shapes = [] for v in right : offsets = [ left . find ( v ) for left in lefts ] iter_args , iter_offsets = zip ( * filter ( lambda x : x [ 1 ] != - 1 , zip ( args , offsets ))) assert len ( iter_args ) > 0 shapes . append ( iter_args [ 0 ] . shape ( iter_offsets [ 0 ])) # FIXME: compute dtype and mtype from every inputs Y = core . empty ( shapes , args [ 0 ] . dtype , args [ 0 ] . mtype ) einsum_ ( fmt , * args , Y ) return Y","title":"einsum()"},{"location":"api/#freetensor.libop.matmul.einsum_","text":"Einstein summation. The result is written to the last argument Parameters: fmt ( str ) \u2013 The format string. E.g. \"ik,kj->ij\" represents a matrix multiplcation args ( Sequence[VarRef] ) \u2013 All arguments including inputs and the output. E.g. if fmt is \"ik,kj->ij\" , it iterates axis i and k of args[0] , axis k and j of args[1] , axis i and j of args[2] Source code in freetensor/libop/matmul.py @core . inline def einsum_ ( fmt : str , * args ): ''' Einstein summation. The result is written to the last argument Parameters ---------- fmt : str The format string. E.g. `\"ik,kj->ij\"` represents a matrix multiplcation args : Sequence[VarRef] All arguments including inputs and the output. E.g. if `fmt` is `\"ik,kj->ij\"`, it iterates axis `i` and `k` of `args[0]`, axis `k` and `j` of `args[1]`, axis `i` and `j` of `args[2]` ''' lefts , right = fmt . split ( '->' ) lefts = lefts . split ( ',' ) order = right for left in lefts : for idx in left : if idx not in order : order += idx _einsum_ ( lefts , right , order , True , * args )","title":"einsum_()"},{"location":"api/#freetensor.libop.matmul.gemm","text":"General matrix multiplcation following BLAS convention and return the result It performs Y = alpha tr?(A) @ tr?(B) + C , where @ represents matrix multiplication, tr? represents an optional transposition Parameters: A ( VarRef ) \u2013 The left-hand-side operand of matrix multiplication B ( VarRef ) \u2013 The right-hand-side operand of matrix multiplication C ( VarRef (Optional) ) \u2013 The bias tensor trans_A ( bool ) \u2013 If true, transpose A . Defaults to False trans_B ( bool ) \u2013 If true, transpose B . Defaults to False alpha ( float ) \u2013 Coefficient of tr?(A) @ tr?(B) . Defaults to 1.0 beta ( float ) \u2013 Coefficient of C . Defaults to 1.0 Returns: The resulting tensor Source code in freetensor/libop/matmul.py @core . inline def gemm ( A , B , C = None , has_bias : bool = False , trans_A : bool = False , trans_B : bool = False , alpha : float = 1.0 , beta : float = 1.0 ): ''' General matrix multiplcation following BLAS convention and return the result It performs `Y = alpha tr?(A) @ tr?(B) + C`, where `@` represents matrix multiplication, `tr?` represents an optional transposition Parameters ---------- A : VarRef The left-hand-side operand of matrix multiplication B : VarRef The right-hand-side operand of matrix multiplication C : VarRef (Optional) The bias tensor trans_A : bool (Optional) If true, transpose `A`. Defaults to False trans_B : bool (Optional) If true, transpose `B`. Defaults to False alpha : Number (Optional) Coefficient of `tr?(A) @ tr?(B)`. Defaults to 1.0 beta : Number (Optional) Coefficient of `C`. Defaults to 1.0 Returns ------- VarRef : The resulting tensor ''' dtype = core . up_cast ( A . dtype , B . dtype ) mtype = core . same_mtype ( A . mtype , B . mtype ) if C is not None : dtype = core . up_cast ( dtype , C . dtype ) mtype = core . same_mtype ( mtype , C . mtype ) Y = core . empty ( _comp_shape ( A , B , trans_A , trans_B ), dtype , mtype ) #! nid: recur gemm_ ( A , B , C , Y , trans_A , trans_B , alpha , beta ) return Y","title":"gemm()"},{"location":"api/#freetensor.libop.matmul.gemm_","text":"General matrix multiplcation following BLAS convention. The result is written to an existing tensor It performs Y = alpha tr?(A) @ tr?(B) + C , where @ represents matrix multiplication, tr? represents an optional transposition Parameters: A ( VarRef ) \u2013 The left-hand-side operand of matrix multiplication B ( VarRef ) \u2013 The right-hand-side operand of matrix multiplication C ( VarRef (Optional) ) \u2013 The bias tensor Y ( VarRef ) \u2013 The resulting tensor trans_A ( bool ) \u2013 If true, transpose A . Defaults to False trans_B ( bool ) \u2013 If true, transpose B . Defaults to False alpha ( float ) \u2013 Coefficient of tr?(A) @ tr?(B) . Defaults to 1.0 beta ( float ) \u2013 Coefficient of C . Defaults to 1.0 Source code in freetensor/libop/matmul.py @core . inline def gemm_ ( A , B , C , Y , trans_A : bool = False , trans_B : bool = False , alpha : float = 1.0 , beta : float = 1.0 ): ''' General matrix multiplcation following BLAS convention. The result is written to an existing tensor It performs `Y = alpha tr?(A) @ tr?(B) + C`, where `@` represents matrix multiplication, `tr?` represents an optional transposition Parameters ---------- A : VarRef The left-hand-side operand of matrix multiplication B : VarRef The right-hand-side operand of matrix multiplication C : VarRef (Optional) The bias tensor Y : VarRef The resulting tensor trans_A : bool (Optional) If true, transpose `A`. Defaults to False trans_B : bool (Optional) If true, transpose `B`. Defaults to False alpha : Number (Optional) Coefficient of `tr?(A) @ tr?(B)`. Defaults to 1.0 beta : Number (Optional) Coefficient of `C`. Defaults to 1.0 ''' a_fmt = 'ki' if trans_A else 'ik' b_fmt = 'jk' if trans_B else 'kj' fmt = f \" { a_fmt } , { b_fmt } ->ij\" if C is None : #! nid: einsum einsum_ ( fmt , A , B , Y ) #! nid: mul_to mul_to ( Y , alpha ) else : #! nid: einsum einsum_ ( fmt , A , B , Y ) #! nid: mul_to mul_to ( Y , alpha ) #! nid: add_to add_to ( Y , mul ( beta , C ))","title":"gemm_()"},{"location":"api/#freetensor.libop.matmul.matmul","text":"Matrix multiplcation. The result is returned Parameters: A ( VarRef ) \u2013 The left-hand-side operand B ( VarRef ) \u2013 The right-hand-side operand Returns: The resulting tensor Source code in freetensor/libop/matmul.py @core . inline def matmul ( A , B ): ''' Matrix multiplcation. The result is returned Parameters ---------- A : VarRef The left-hand-side operand B : VarRef The right-hand-side operand Returns ------- VarRef : The resulting tensor ''' #! nid: einsum Y = einsum ( _make_matmul_fmt ( A . ndim , B . ndim ), A , B ) return Y","title":"matmul()"},{"location":"api/#freetensor.libop.matmul.matmul_","text":"Matrix multiplcation. The result is written to an existing tensor Parameters: A ( VarRef ) \u2013 The left-hand-side operand B ( VarRef ) \u2013 The right-hand-side operand C ( VarRef ) \u2013 The resulting tensor Source code in freetensor/libop/matmul.py @core . inline def matmul_ ( A , B , Y ): ''' Matrix multiplcation. The result is written to an existing tensor Parameters ---------- A : VarRef The left-hand-side operand B : VarRef The right-hand-side operand C : VarRef The resulting tensor ''' #! nid: einsum einsum_ ( _make_matmul_fmt ( A . ndim , B . ndim ), A , B , Y )","title":"matmul_()"},{"location":"api/#freetensor.libop.pooling","text":"","title":"pooling"},{"location":"api/#freetensor.libop.pooling.global_avg_pool","text":"Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def global_avg_pool ( X ): ''' Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 )], X . dtype , X . mtype ) #! nid: recur global_avg_pool_ ( X , Y ) return Y","title":"global_avg_pool()"},{"location":"api/#freetensor.libop.pooling.global_avg_pool_","text":"Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def global_avg_pool_ ( X , Y ): ''' Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_c for c in range ( X . shape ( 1 )): #! nid: init Y [ n , c ] = 0 #! nid: L_h for h in range ( X . shape ( 2 )): #! nid: L_w for w in range ( X . shape ( 3 )): #! nid: compute Y [ n , c ] += X [ n , c , h , w ] #! nid: flush Y [ n , c ] /= X . shape ( 2 ) * X . shape ( 3 )","title":"global_avg_pool_()"},{"location":"api/#freetensor.libop.pooling.max_pool","text":"Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def max_pool ( X , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 ), calc_out_size ( X . shape ( 2 ), dilations [ 0 ], kernel_shape [ 0 ], pads [ 0 ], pads [ 2 ], strides [ 0 ]), calc_out_size ( X . shape ( 3 ), dilations [ 1 ], kernel_shape [ 1 ], pads [ 1 ], pads [ 3 ], strides [ 1 ]) ], X . dtype , X . mtype ) #! nid: recur max_pool_ ( X , Y , auto_pad , dilations , kernel_shape , pads , strides ) return Y","title":"max_pool()"},{"location":"api/#freetensor.libop.pooling.max_pool_","text":"Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in freetensor/libop/pooling.py @core . inline def max_pool_ ( X , Y , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" # yapf: disable #! nid: L_n for n in range ( X . shape ( 0 )): #! nid: L_c for c in range ( X . shape ( 1 )): #! nid: L_h for h in range ( Y . shape ( 2 )): #! nid: L_w for w in range ( Y . shape ( 3 )): #! nid: init Y [ n , c , h , w ] = core . min_value ( X . dtype ) #! nid: L_kh for kh in range ( kernel_shape [ 0 ]): #! nid: L_kw for kw in range ( kernel_shape [ 1 ]): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! nid: compute Y [ n , c , h , w ] = core . max ( Y [ n , c , h , w ], X [ n , c , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ]]) # yapf: enable","title":"max_pool_()"},{"location":"api/#freetensor.libop.reduction","text":"","title":"reduction"},{"location":"api/#freetensor.libop.reduction.all","text":"Reduction of logical and of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"all()"},{"location":"api/#freetensor.libop.reduction.all_","text":"Reduction of logical and of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"all_()"},{"location":"api/#freetensor.libop.reduction.any","text":"Reduction of logical or of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"any()"},{"location":"api/#freetensor.libop.reduction.any_","text":"Reduction of logical or of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"any_()"},{"location":"api/#freetensor.libop.reduction.reduce_max","text":"Maximum of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py @core . inline def reduce_max ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! nid: impl y = _general_reduce ( core . max , core . min_value ( core . dtype ( x )), x , axes , keepdims ) return y","title":"reduce_max()"},{"location":"api/#freetensor.libop.reduction.reduce_max_","text":"Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py @core . inline def reduce_max_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! nid: impl _general_reduce_ ( core . max , core . min_value ( core . dtype ( x )), x , y , axes , keepdims )","title":"reduce_max_()"},{"location":"api/#freetensor.libop.reduction.reduce_min","text":"Minimum of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py @core . inline def reduce_min ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! nid: impl y = _general_reduce ( core . min , core . max_value ( core . dtype ( x )), x , axes , keepdims ) return y","title":"reduce_min()"},{"location":"api/#freetensor.libop.reduction.reduce_min_","text":"Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py @core . inline def reduce_min_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! nid: impl _general_reduce_ ( core . min , core . max_value ( core . dtype ( x )), x , y , axes , keepdims )","title":"reduce_min_()"},{"location":"api/#freetensor.libop.reduction.reduce_prod","text":"Product of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"reduce_prod()"},{"location":"api/#freetensor.libop.reduction.reduce_prod_","text":"Product of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"reduce_prod_()"},{"location":"api/#freetensor.libop.reduction.reduce_sum","text":"Sum of a tensor through one or more dimensions and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Returns: VarRef \u2013 The result tensor Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"reduce_sum()"},{"location":"api/#freetensor.libop.reduction.reduce_sum_","text":"Sum of a tensor through one or more dimensions. The result is written to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axes ( Sequence[int] (Optional) ) \u2013 Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims ( bool (Optional) ) \u2013 Keep the reduced dimensions as singleton dimensions. Defaults to True Source code in freetensor/libop/reduction.py def g ( * _args , ** _kvs ): return f ( * args , * _args , ** kvs , ** _kvs )","title":"reduce_sum_()"},{"location":"api/#freetensor.libop.reshape","text":"","title":"reshape"},{"location":"api/#freetensor.libop.reshape.expand","text":"Broadcast a tensor to a given shape, following the broadcasting rules Parameters: a ( VarRef ) \u2013 The input tensor b ( Sequence of expressions ) \u2013 The broadcasted shape Returns: The broadcasted tensor Source code in freetensor/libop/reshape.py @core . inline def expand ( a , expand_shape ): ''' Broadcast a tensor to a given shape, following the broadcasting rules Parameters ---------- a : VarRef The input tensor b : Sequence of expressions The broadcasted shape Returns ------- VarRef : The broadcasted tensor ''' # FIXME: out_shape = broadcast(a.shape, expand_shape) out = core . empty ( expand_shape , core . dtype ( a ), core . mtype ( a )) #! nid: recur expand_ ( a , out ) return out","title":"expand()"},{"location":"api/#freetensor.libop.reshape.expand_","text":"Broadcast a tensor to an existing tensor, following the broadcasting rules Parameters: a ( VarRef ) \u2013 The input tensor b ( VarRef ) \u2013 The broadcasted tensor Source code in freetensor/libop/reshape.py @core . inline def expand_ ( a , out ): ''' Broadcast a tensor to an existing tensor, following the broadcasting rules Parameters ---------- a : VarRef The input tensor b : VarRef The broadcasted tensor ''' if out . ndim == 0 : out [()] = a else : #! nid: L_elem for i in range ( out . shape ( 0 )): if core . ndim ( a ) < out . ndim : #! nid: recur expand_ ( a , out [ i ]) else : #! nid: recur expand_ ( a [ i % a . shape ( 0 )], out [ i ])","title":"expand_()"},{"location":"api/#freetensor.libop.reshape.flatten","text":"Flatten a tensor to have fewer dimensions, and return the result Parameters: x ( VarRef ) \u2013 The input tensor axis ( int (Optional) ) \u2013 The result tensor will have up to axis dimensions. All dimensions after axis will be flatten to 1-D. Negative axis means counting form the last dimension Returns: The result tensor Source code in freetensor/libop/reshape.py @core . inline def flatten ( x , axis = 1 ): ''' Flatten a tensor to have fewer dimensions, and return the result Parameters ---------- x : VarRef The input tensor axis : int (Optional) The result tensor will have up to `axis` dimensions. All dimensions after `axis` will be flatten to 1-D. Negative axis means counting form the last dimension Returns ------- VarRef : The result tensor ''' y = core . empty ( _flatten_comp_shape ( x , axis ), core . dtype ( x ), core . mtype ( x )) #! nid: recur flatten_ ( x , y , axis ) return y","title":"flatten()"},{"location":"api/#freetensor.libop.reshape.flatten_","text":"Flatten a tensor to have fewer dimensions, and write to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axis ( int ) \u2013 The result tensor will have up to axis dimensions. All dimensions after axis will be flatten to 1-D. Negative axis means counting form the last dimension Source code in freetensor/libop/reshape.py @core . inline def flatten_ ( x , y , axis : int = 1 ): ''' Flatten a tensor to have fewer dimensions, and write to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axis : int (Optional) The result tensor will have up to `axis` dimensions. All dimensions after `axis` will be flatten to 1-D. Negative axis means counting form the last dimension ''' if axis == 0 : #! nid: recur _flatten_inner_ ( x , y [ 0 ]) else : #! nid: L_outer for i in range ( x . shape ( 0 )): #! nid: recur flatten_ ( x [ i ], y [ i * ( y . shape ( 0 ) // x . shape ( 0 )):( i + 1 ) * ( y . shape ( 0 ) // x . shape ( 0 ))], axis - 1 )","title":"flatten_()"},{"location":"api/#freetensor.libop.reshape.unsqueeze","text":"Insert singleton dimensions to a tensor, and return the result Parameters: x ( VarRef ) \u2013 The input tensor axes ( Sequence[int] ) \u2013 Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension Returns: VarRef \u2013 The resulting tensor Source code in freetensor/libop/reshape.py @core . inline def unsqueeze ( x , axes : Sequence [ int ]): ''' Insert singleton dimensions to a tensor, and return the result Parameters ---------- x : VarRef The input tensor axes : Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension Returns ------- VarRef The resulting tensor ''' y = core . empty ( _unsqueeze_comp_shape ( _circular_axes ( axes , core . ndim ( x )), x ), core . dtype ( x ), core . mtype ( x )) #! nid: recur unsqueeze_ ( x , y , axes ) return y","title":"unsqueeze()"},{"location":"api/#freetensor.libop.reshape.unsqueeze_","text":"Insert singleton dimensions to a tensor, and write the result to another tensor Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The resulting tensor axes ( Sequence[int] ) \u2013 Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension Source code in freetensor/libop/reshape.py @core . inline def unsqueeze_ ( x , y , axes : Sequence [ int ]): ''' Insert singleton dimensions to a tensor, and write the result to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The resulting tensor axes : Dimension numbers of the new singleton dimensions. Negative axis means counting from the last dimension ''' axes = _circular_axes ( axes , core . ndim ( x )) if y . ndim == 0 : y [()] = x elif begin_with_0 ( axes ): #! nid: recur unsqueeze_ ( x , y [ 0 ], all_minus_one ( axes [ 1 :])) else : #! nid: L for i in range ( x . shape ( 0 )): #! nid: recur unsqueeze_ ( x [ i ], y [ i ], all_minus_one ( axes ))","title":"unsqueeze_()"},{"location":"api/#freetensor.libop.softmax","text":"","title":"softmax"},{"location":"api/#freetensor.libop.softmax.softmax","text":"Softmax of tensor x along an axis and return the result Parameters: x ( VarRef ) \u2013 The input tensor axis ( int (Optional) ) \u2013 Axis that the softmax is performed along. Negative axis means count from the last dimension Returns: The result tensor Source code in freetensor/libop/softmax.py @core . inline def softmax ( x , axis =- 1 ): ''' Softmax of tensor `x` along an axis and return the result Parameters ---------- x : VarRef The input tensor axis : int (Optional) Axis that the softmax is performed along. Negative axis means count from the last dimension Returns ------- VarRef : The result tensor ''' #! nid: max maxval = reduce_max ( x , axes = [ axis ], keepdims = True ) #! nid: sub corrected = sub ( x , maxval ) #! nid: exp exponent = exp ( corrected ) #! nid: sum summation = reduce_sum ( exponent , axes = [ axis ], keepdims = True ) #! nid: div out = truediv ( exponent , summation ) return out","title":"softmax()"},{"location":"api/#freetensor.libop.softmax.softmax_","text":"Softmax of tensor x along an axis, and write to tensor y Parameters: x ( VarRef ) \u2013 The input tensor y ( VarRef ) \u2013 The result tensor axis ( int ) \u2013 Axis that the softmax is performed along. Negative axis means count from the last dimension Source code in freetensor/libop/softmax.py @core . inline def softmax_ ( x , y , axis : int = - 1 ): ''' Softmax of tensor `x` along an axis, and write to tensor `y` Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axis : int (Optional) Axis that the softmax is performed along. Negative axis means count from the last dimension ''' #! nid: max maxval = reduce_max ( x , axes = [ axis ], keepdims = True ) #! nid: sub corrected = sub ( x , maxval ) #! nid: exp exponent = exp ( corrected ) #! nid: sum summation = reduce_sum ( exponent , axes = [ axis ], keepdims = True ) #! nid: div truediv_ ( exponent , summation , y )","title":"softmax_()"},{"location":"about/contrib/","text":"Contributing Pull Requests are welcome! Please configure (or install some plugins for) your editor, to support clang-format , yapf and editorconfig , for code formating. And please note that we use different naming styles in Python and C++ parts.","title":"Contributing"},{"location":"about/contrib/#contributing","text":"Pull Requests are welcome! Please configure (or install some plugins for) your editor, to support clang-format , yapf and editorconfig , for code formating. And please note that we use different naming styles in Python and C++ parts.","title":"Contributing"},{"location":"about/pub/","text":"Publication Shizhi Tang, Jidong Zhai, Haojie Wang, Lin Jiang, Liyan Zheng, Zhenhao Yuan, and Chen Zhang. 2022. FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs. In Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI \u201922), June 13-17, 2022, San Diego, CA, USA . ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3519939.3523448. ( Download ) @inproceedings{10.1145/3519939.3523448, author = {Tang, Shizhi and Zhai, Jidong and Wang, Haojie and Jiang, Lin and Zheng, Liyan and Yuan, Zhenhao and Zhang, Chen}, title = {FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs}, year = {2022}, isbn = {9781450392655}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3519939.3523448}, doi = {10.1145/3519939.3523448}, booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation}, pages = {872\u2013887}, numpages = {16}, keywords = {tensor computing, optimizing compilers, DSL}, location = {San Diego, CA, USA}, series = {PLDI 2022} } Evaluation code can be found in this repository . NOTE: API of FreeTensor has been changed since submission. To reproduce the exact result in the paper, please consider the Artifact Evaluation version of FreeTensor, published here .","title":"Publication"},{"location":"about/pub/#publication","text":"Shizhi Tang, Jidong Zhai, Haojie Wang, Lin Jiang, Liyan Zheng, Zhenhao Yuan, and Chen Zhang. 2022. FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs. In Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI \u201922), June 13-17, 2022, San Diego, CA, USA . ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3519939.3523448. ( Download ) @inproceedings{10.1145/3519939.3523448, author = {Tang, Shizhi and Zhai, Jidong and Wang, Haojie and Jiang, Lin and Zheng, Liyan and Yuan, Zhenhao and Zhang, Chen}, title = {FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs}, year = {2022}, isbn = {9781450392655}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3519939.3523448}, doi = {10.1145/3519939.3523448}, booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation}, pages = {872\u2013887}, numpages = {16}, keywords = {tensor computing, optimizing compilers, DSL}, location = {San Diego, CA, USA}, series = {PLDI 2022} } Evaluation code can be found in this repository . NOTE: API of FreeTensor has been changed since submission. To reproduce the exact result in the paper, please consider the Artifact Evaluation version of FreeTensor, published here .","title":"Publication"},{"location":"guide/","text":"Get Started Build and Run Your First Program with FreeTenor Optimize a Program with Schedules Running on a GPU Automatic Differentiation","title":"Get Started"},{"location":"guide/#get-started","text":"Build and Run Your First Program with FreeTenor Optimize a Program with Schedules Running on a GPU Automatic Differentiation","title":"Get Started"},{"location":"guide/ad/","text":"Automatic Differentiation Automatic Differentiation (AD) transforms a program to another program that computes the original one's derivative or gradient. FreeTensor supports Reverse-Mode AD, and there is a plan to support Forward-Mode AD in the future. Reverse-Mode AD Suppose there is a program x -> y -> z -> w that computes an output w from intermediate variables z and y , and an input variable x . Reverse-Mode AD generates a gradient program dw/dw=1 -> dw/dz -> dw/dy -> dw/dx that computes dw/dx by Chain Rule. y , z and w may be saved in a \"tape\" when evaluation the original program, to be reused in the gradient one. Here is an example of Reverse-Mode AD in FreeTensor: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy()) You need to call ft.grad (or the inplace version ft.grad_ ) to generate a forward function and a backward function. Please note that the forward function fwd is not the same as the original function test , because fwd may save some intermediate tensors to a global tape , and fwd must be executed before the backward one bwd . After that, you call ft.optimize to optimize and compile the program just as in previous examples, but for both fwd and bwd this time. Finally, you execute fwd and bwd . The parameters and return values of bwd are the gradients of a , b and y , which have their own names. To set and get these parameters and return values, you look up for them in two dictionaries input_grads and output_grads returned from ft.grad (in type ft.ArgRetDict . input_grads and output_grads accept either a name of a parameter, or a special ft.Return to specify a return value. When invoking bwd , parameters can be set via keyword arguments, and return values can be collect via a bracket (from a special type ft.ReturnValuesPack . Intermediate variables are not always have to be saved to the \"tape\" from the forward function. If a variable is need in the backward function but not saved, it will be re-computed, which is sometimes even faster than saving it due to better locality. By default, FreeTensor uses heuristics to determine which variable to save. To get better performance, you may want to control which intermediate variables should be saved by setting an optional tapes parameter in ft.grad . tapes can either be a different mode, or a explicit list of AST node IDs of all VarDef nodes of the variables you want to save.","title":"Automatic Differentiation"},{"location":"guide/ad/#automatic-differentiation","text":"Automatic Differentiation (AD) transforms a program to another program that computes the original one's derivative or gradient. FreeTensor supports Reverse-Mode AD, and there is a plan to support Forward-Mode AD in the future.","title":"Automatic Differentiation"},{"location":"guide/ad/#reverse-mode-ad","text":"Suppose there is a program x -> y -> z -> w that computes an output w from intermediate variables z and y , and an input variable x . Reverse-Mode AD generates a gradient program dw/dw=1 -> dw/dz -> dw/dy -> dw/dx that computes dw/dx by Chain Rule. y , z and w may be saved in a \"tape\" when evaluation the original program, to be reused in the gradient one. Here is an example of Reverse-Mode AD in FreeTensor: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy()) You need to call ft.grad (or the inplace version ft.grad_ ) to generate a forward function and a backward function. Please note that the forward function fwd is not the same as the original function test , because fwd may save some intermediate tensors to a global tape , and fwd must be executed before the backward one bwd . After that, you call ft.optimize to optimize and compile the program just as in previous examples, but for both fwd and bwd this time. Finally, you execute fwd and bwd . The parameters and return values of bwd are the gradients of a , b and y , which have their own names. To set and get these parameters and return values, you look up for them in two dictionaries input_grads and output_grads returned from ft.grad (in type ft.ArgRetDict . input_grads and output_grads accept either a name of a parameter, or a special ft.Return to specify a return value. When invoking bwd , parameters can be set via keyword arguments, and return values can be collect via a bracket (from a special type ft.ReturnValuesPack . Intermediate variables are not always have to be saved to the \"tape\" from the forward function. If a variable is need in the backward function but not saved, it will be re-computed, which is sometimes even faster than saving it due to better locality. By default, FreeTensor uses heuristics to determine which variable to save. To get better performance, you may want to control which intermediate variables should be saved by setting an optional tapes parameter in ft.grad . tapes can either be a different mode, or a explicit list of AST node IDs of all VarDef nodes of the variables you want to save.","title":"Reverse-Mode AD"},{"location":"guide/build-and-run/","text":"Build and Run Dependencies Linux Python (>= 3.8, for the Python frontend) GCC (>= 10, to support C++20 and the \"unroll\" pragma) CUDA (>= 11.4.1, to support GCC 10, Optional) MKL (Optional) PyTorch (Optional, see below) Java (= 11, Build-time dependency only) Other Python dependencies: pip3 install --user numpy sourceinspect astor Pygments xgboost Note on Python version Because we are analyzing Python AST, which is sensitive to Python version, there may be potential bugs for Python strictly later than 3.8. Please file an issue if something goes wrong PyTorch support FreeTensor can optionally link PyTorch to support a copy-free interface between FreeTensor and PyTorch. Please note that, if you are using CUDA, FreeTensor and PyTorch should link CUDA of the same version . PyTorch can be installed in any way you like, see PyTorch's guide . Build First, clone this repo. Don't forget there are some submodules. git clone --recursive <path-to-this-repo> Then, build. mkdir build cd build cmake .. make -j # Or use Ninja There are some options to cmake : -DFT_WITH_CUDA=ON/OFF : build with/without CUDA (defaults to ON ). -DFT_WITH_MKL=<path/to/mkl/root> : build with MKL (path to MKL is required, defaults to building without it). -DFT_WITH_PYTORCH=ON/OFF : build with/without copy-free interface from/to PyTorch, requring PyTorch installed on the system (defaults to OFF ). -DFT_DEBUG_LOG_NODE=ON (for developers): enables tracing to tell by which pass a specific AST node is modified. -DFT_DEBUG_PROFILE (for developers): profiles some heavy functions in the compiler. It will build a shared library with a name like freetensor_ffi.cpython-37m-x86_64-linux-gnu.so , which can be used in Python via import freetensor . Run a Program with FreeTensor To run any program with FreeTensor, one should add the python/ and build/ directory to PYTHONPATH first. E.g. to run a python program a.py with FreeTensor in the build/ directory, PYTHONPATH=../python:../build:$PYTHONPATH python3 a.py Global Configurations There are serveral global configurations can be set via environment variables: FT_PRETTY_PRINT=ON/OFF . Enable/disable colored printing. FT_PRINT_ALL_ID=ON/OFF . Print (or not) IDs of all statements in an AST. FT_WERROR=ON/OFF . Treat warnings as errors (or not). FT_BACKEND_COMPILER_CXX . The C++ compiler used to compiler the optimized program. Default to the same compiler found when building FreeTensor itself. FT_BACKEND_COMPILER_NVCC . The CUDA compiler used to compiler the optimized program (if built with CUDA). Default to the same compiler found when building FreeTensor itself. This configurations can also set at runtime in ft.config . Run the Tests To run the test, first change into the test/ directory, then PYTHONPATH=../python:../build:$PYTHONPATH pytest To run a single test case, specify the test case name, and optionally use pytest -s to display the standard output. E.g, PYTHONPATH=../python:../build:$PYTHONPATH pytest -s 00.hello_world/test_basic.py::test_hello_world Debugging (for developers) If using GDB, one should invoke PyTest with python3 -m : PYTHONPATH=../python:../build:$PYTHONPATH gdb --args python3 -m pytest If using Valgrind, one should set Python to use the system malloc: PYTHONPATH=../python:../build:$PYTHONPATH PYTHONMALLOC=malloc valgrind python3 -m pytest Sometimes Valgrind is not enough to detect some errors. An alternative is to use the sanitizer from GCC. To use it, first edit CMakeLists.txt to add a -fsanitize=address compiler flag (or other mode like -fsanitize=undefined ), then: PYTHONPATH=../python:../build:$PYTHONPATH LD_PRELOAD=`gcc -print-file-name=libasan.so` pytest -s Build this Document First install some dependencies: pip3 install --user mkdocs mkdocstrings==0.18.1 \"pytkdocs[numpy-style]\" From the root directory of FreeTensor, run a HTTP server to serve the document (recommended, but without document on C++ interface due to a limitation ): PYTHONPATH=./python:./build:$PYTHONPATH mkdocs serve Or build and save the pages (with document on C++ interface, requiring Doxygen and Graphviz): doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs build Publish the documents to GitHub Pages (for developers) doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs gh-deploy","title":"Build and Run"},{"location":"guide/build-and-run/#build-and-run","text":"","title":"Build and Run"},{"location":"guide/build-and-run/#dependencies","text":"Linux Python (>= 3.8, for the Python frontend) GCC (>= 10, to support C++20 and the \"unroll\" pragma) CUDA (>= 11.4.1, to support GCC 10, Optional) MKL (Optional) PyTorch (Optional, see below) Java (= 11, Build-time dependency only) Other Python dependencies: pip3 install --user numpy sourceinspect astor Pygments xgboost Note on Python version Because we are analyzing Python AST, which is sensitive to Python version, there may be potential bugs for Python strictly later than 3.8. Please file an issue if something goes wrong PyTorch support FreeTensor can optionally link PyTorch to support a copy-free interface between FreeTensor and PyTorch. Please note that, if you are using CUDA, FreeTensor and PyTorch should link CUDA of the same version . PyTorch can be installed in any way you like, see PyTorch's guide .","title":"Dependencies"},{"location":"guide/build-and-run/#build","text":"First, clone this repo. Don't forget there are some submodules. git clone --recursive <path-to-this-repo> Then, build. mkdir build cd build cmake .. make -j # Or use Ninja There are some options to cmake : -DFT_WITH_CUDA=ON/OFF : build with/without CUDA (defaults to ON ). -DFT_WITH_MKL=<path/to/mkl/root> : build with MKL (path to MKL is required, defaults to building without it). -DFT_WITH_PYTORCH=ON/OFF : build with/without copy-free interface from/to PyTorch, requring PyTorch installed on the system (defaults to OFF ). -DFT_DEBUG_LOG_NODE=ON (for developers): enables tracing to tell by which pass a specific AST node is modified. -DFT_DEBUG_PROFILE (for developers): profiles some heavy functions in the compiler. It will build a shared library with a name like freetensor_ffi.cpython-37m-x86_64-linux-gnu.so , which can be used in Python via import freetensor .","title":"Build"},{"location":"guide/build-and-run/#run-a-program-with-freetensor","text":"To run any program with FreeTensor, one should add the python/ and build/ directory to PYTHONPATH first. E.g. to run a python program a.py with FreeTensor in the build/ directory, PYTHONPATH=../python:../build:$PYTHONPATH python3 a.py","title":"Run a Program with FreeTensor"},{"location":"guide/build-and-run/#global-configurations","text":"There are serveral global configurations can be set via environment variables: FT_PRETTY_PRINT=ON/OFF . Enable/disable colored printing. FT_PRINT_ALL_ID=ON/OFF . Print (or not) IDs of all statements in an AST. FT_WERROR=ON/OFF . Treat warnings as errors (or not). FT_BACKEND_COMPILER_CXX . The C++ compiler used to compiler the optimized program. Default to the same compiler found when building FreeTensor itself. FT_BACKEND_COMPILER_NVCC . The CUDA compiler used to compiler the optimized program (if built with CUDA). Default to the same compiler found when building FreeTensor itself. This configurations can also set at runtime in ft.config .","title":"Global Configurations"},{"location":"guide/build-and-run/#run-the-tests","text":"To run the test, first change into the test/ directory, then PYTHONPATH=../python:../build:$PYTHONPATH pytest To run a single test case, specify the test case name, and optionally use pytest -s to display the standard output. E.g, PYTHONPATH=../python:../build:$PYTHONPATH pytest -s 00.hello_world/test_basic.py::test_hello_world Debugging (for developers) If using GDB, one should invoke PyTest with python3 -m : PYTHONPATH=../python:../build:$PYTHONPATH gdb --args python3 -m pytest If using Valgrind, one should set Python to use the system malloc: PYTHONPATH=../python:../build:$PYTHONPATH PYTHONMALLOC=malloc valgrind python3 -m pytest Sometimes Valgrind is not enough to detect some errors. An alternative is to use the sanitizer from GCC. To use it, first edit CMakeLists.txt to add a -fsanitize=address compiler flag (or other mode like -fsanitize=undefined ), then: PYTHONPATH=../python:../build:$PYTHONPATH LD_PRELOAD=`gcc -print-file-name=libasan.so` pytest -s","title":"Run the Tests"},{"location":"guide/build-and-run/#build-this-document","text":"First install some dependencies: pip3 install --user mkdocs mkdocstrings==0.18.1 \"pytkdocs[numpy-style]\" From the root directory of FreeTensor, run a HTTP server to serve the document (recommended, but without document on C++ interface due to a limitation ): PYTHONPATH=./python:./build:$PYTHONPATH mkdocs serve Or build and save the pages (with document on C++ interface, requiring Doxygen and Graphviz): doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs build Publish the documents to GitHub Pages (for developers) doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs gh-deploy","title":"Build this Document"},{"location":"guide/first-program/","text":"Your First Program with FreeTenor In this page, we introduce some basic concepts of FreeTensor. Example: Vector addition import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is a basic example program in FreeTensor. You write a Python function that manipulates FreeTensor's tensor type ft.Var , decorate the function with ft.optimize , and finally invoke the decorated function. FreeTensor will generate C++ code for this vector addition, compile it using a native compiler, and finally load it back to Python. Set verbose = 1 to optimize if you are interested in the generated native code. To write such a function, you need to follow some basic concept described in this page. Declare and Define Tensors All tensors, including function parameters, intermediate tensors and return values should be properly declared or defined. Scalars are 0-D tensors in FreeTensor. Declare or define a tensor with an empty shape, and you will get a scalar. Function parameters should be declared like x : ft.Var[shape, data_type] . Declaring a parameter either in the function signature or as a stand-alone statment is acceptable. If your parameter uses another parameter as shape, you will need the latter manner. An optional parameter atype can be set to \"output\" or \"inout\" if you want to mutate a function argument. Intermediate and returning tensors can be created by ft.empty , ft.var or ft.zeros . If you are using FreeTensor for GPU computing, an optional parameter mtype can be set to specify where to store the tensor. It defaults to the main memory of your currently chosen computing device. All tensors and their slices are implemented by an internal ft.VarRef type. If you are looking for a tensor's API, ft.VarRef is the right place. Manipulating Tensors To read or write tensors in a function, just write for ... in range(...) loops that iterate through elements in the tensors, and do arithmetic operations on them. We also provide some functions that operates on a whole tensor or a tensor slice in libop . Special note on tensor assignments We follow Python convention for tensor assignments, but sometimes it is a little counterintuitive. Suppose you have two list s in Python: a and b . a = b replaces the object a with the object b , while a[...] = b assigns data in b to a . FreeTensor does not support replacing a tensor object with another one. It supports assignments only. Therefore, we need to write a[...] = b to assign tensor. a[:] = b (for non-scalars), a[None] = b and a[()] = b is also supported. Dynamic or Static Another concept is that statements and expressions in your program are divided into two categories: dynamic and static . Dynamic statements or expressions are restricted to a small subset of Python, and are compiled to native code. Static statements or expressions can be any Python statements or expressions, and are executed before compilation. In other words, static statements or expressions are like macros or templates in C++, while dynamic ones are actually quotations in Multi-Stage Programming . The following statements and expressions are considered dynamic: Declarations, definitions and operations of FreeTensor's tensor type ft.Var (or its internal implementation ft.VarRef ). if statements, for ... in range(...) and assert statements that have a ft.Var condition or range. All other statements and expressions are considered static. With the help of dynamic and static categories, you can utilize complex Python functions as the static part, while still generate high-performance native code using dynamic loops. For example, the following code combines static and dynamic code to sum multiple vectors together: import freetensor as ft import numpy as np n = 4 @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"], c: ft.Var[(n,), \"int32\"]): inputs = [a, b, c] # Static y = ft.empty((n,), \"int32\") # Dynamic for i in range(n): # Dyanmic y[i] = 0 # Dynamic for item in inputs: # Static y[i] += item[i] # Dynamic return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\"), np.array([3, 4, 5, 6], dtype=\"int32\")).numpy() print(y) However, there might be some counterintuitive behaviours when using static statments or expressions. Please remember that static static statements or expressions are executed before compilation, so the following piece of code will result in a list containing only one item: the expression i , instead of 10 numbers: lst = [] for i in range(10): # Dynamic lst.append(i) # Static. Appends only once Dynamic Tensor Shapes In the example of vector addition above, we support any vector length, but only in a static way. This means each time you change the vector length n , you need to recompile (run optimize again) the function. FreeTensor supports defining tensors with dynamic shapes, just by setting their shapes to a dynamic values. The following code shows an example: import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) In this way, in only have to compile your program once. But you will expect a longer compiling time, and some optimizations are not possible with dynamic shapes. Copy-free interface from/to PyTorch If FreeTensor is built with WITH_PYTORCH=ON , you can directly pass PyTorch tensors to or get them from FreeTensor. For example, import freetensor as ft import torch n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(torch.tensor([1, 2, 3, 4], dtype=torch.int32), torch.tensor([2, 3, 4, 5], dtype=torch.int32)).torch() print(y)","title":"Your First Program with FreeTenor"},{"location":"guide/first-program/#your-first-program-with-freetenor","text":"In this page, we introduce some basic concepts of FreeTensor.","title":"Your First Program with FreeTenor"},{"location":"guide/first-program/#example-vector-addition","text":"import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is a basic example program in FreeTensor. You write a Python function that manipulates FreeTensor's tensor type ft.Var , decorate the function with ft.optimize , and finally invoke the decorated function. FreeTensor will generate C++ code for this vector addition, compile it using a native compiler, and finally load it back to Python. Set verbose = 1 to optimize if you are interested in the generated native code. To write such a function, you need to follow some basic concept described in this page.","title":"Example: Vector addition"},{"location":"guide/first-program/#declare-and-define-tensors","text":"All tensors, including function parameters, intermediate tensors and return values should be properly declared or defined. Scalars are 0-D tensors in FreeTensor. Declare or define a tensor with an empty shape, and you will get a scalar. Function parameters should be declared like x : ft.Var[shape, data_type] . Declaring a parameter either in the function signature or as a stand-alone statment is acceptable. If your parameter uses another parameter as shape, you will need the latter manner. An optional parameter atype can be set to \"output\" or \"inout\" if you want to mutate a function argument. Intermediate and returning tensors can be created by ft.empty , ft.var or ft.zeros . If you are using FreeTensor for GPU computing, an optional parameter mtype can be set to specify where to store the tensor. It defaults to the main memory of your currently chosen computing device. All tensors and their slices are implemented by an internal ft.VarRef type. If you are looking for a tensor's API, ft.VarRef is the right place.","title":"Declare and Define Tensors"},{"location":"guide/first-program/#manipulating-tensors","text":"To read or write tensors in a function, just write for ... in range(...) loops that iterate through elements in the tensors, and do arithmetic operations on them. We also provide some functions that operates on a whole tensor or a tensor slice in libop . Special note on tensor assignments We follow Python convention for tensor assignments, but sometimes it is a little counterintuitive. Suppose you have two list s in Python: a and b . a = b replaces the object a with the object b , while a[...] = b assigns data in b to a . FreeTensor does not support replacing a tensor object with another one. It supports assignments only. Therefore, we need to write a[...] = b to assign tensor. a[:] = b (for non-scalars), a[None] = b and a[()] = b is also supported.","title":"Manipulating Tensors"},{"location":"guide/first-program/#dynamic-or-static","text":"Another concept is that statements and expressions in your program are divided into two categories: dynamic and static . Dynamic statements or expressions are restricted to a small subset of Python, and are compiled to native code. Static statements or expressions can be any Python statements or expressions, and are executed before compilation. In other words, static statements or expressions are like macros or templates in C++, while dynamic ones are actually quotations in Multi-Stage Programming . The following statements and expressions are considered dynamic: Declarations, definitions and operations of FreeTensor's tensor type ft.Var (or its internal implementation ft.VarRef ). if statements, for ... in range(...) and assert statements that have a ft.Var condition or range. All other statements and expressions are considered static. With the help of dynamic and static categories, you can utilize complex Python functions as the static part, while still generate high-performance native code using dynamic loops. For example, the following code combines static and dynamic code to sum multiple vectors together: import freetensor as ft import numpy as np n = 4 @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"], c: ft.Var[(n,), \"int32\"]): inputs = [a, b, c] # Static y = ft.empty((n,), \"int32\") # Dynamic for i in range(n): # Dyanmic y[i] = 0 # Dynamic for item in inputs: # Static y[i] += item[i] # Dynamic return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\"), np.array([3, 4, 5, 6], dtype=\"int32\")).numpy() print(y) However, there might be some counterintuitive behaviours when using static statments or expressions. Please remember that static static statements or expressions are executed before compilation, so the following piece of code will result in a list containing only one item: the expression i , instead of 10 numbers: lst = [] for i in range(10): # Dynamic lst.append(i) # Static. Appends only once","title":"Dynamic or Static"},{"location":"guide/first-program/#dynamic-tensor-shapes","text":"In the example of vector addition above, we support any vector length, but only in a static way. This means each time you change the vector length n , you need to recompile (run optimize again) the function. FreeTensor supports defining tensors with dynamic shapes, just by setting their shapes to a dynamic values. The following code shows an example: import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) In this way, in only have to compile your program once. But you will expect a longer compiling time, and some optimizations are not possible with dynamic shapes.","title":"Dynamic Tensor Shapes"},{"location":"guide/first-program/#copy-free-interface-fromto-pytorch","text":"If FreeTensor is built with WITH_PYTORCH=ON , you can directly pass PyTorch tensors to or get them from FreeTensor. For example, import freetensor as ft import torch n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(torch.tensor([1, 2, 3, 4], dtype=torch.int32), torch.tensor([2, 3, 4, 5], dtype=torch.int32)).torch() print(y)","title":"Copy-free interface from/to PyTorch"},{"location":"guide/gpu/","text":"Running on a GPU Example: Vector addition on a GPU If FreeTensor is built with a CUDA backend, you can compile your program to a GPU. We still take a vector addition as an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.Device(ft.GPU(), 0): n = 4 # Add verbose=1 to see the resulting native code @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize('Li', 'threadIdx.x')) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! nid: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Similar to parallelizing to OpenMP threads , in this example, we parallelize Loop Li to the threadIdx.x dimension of CUDA. There are two major differences: You are now calling parallelize schedule with a threadIdx.x parameter, instead of openmp . All the code are enclosed by a with ft.Device(ft.GPU(), 0) scope. Usually, you not only parallelize your loops to threadIdx.x , but also other CUDA dimensions like blockIdx.x . To achieve this, you either parallelize different loops in a loop nests to different CUDA dimensions, or split your loops before parallelizing them. As for the with ft.Device(ft.GPU(), 0) scope, ft.GPU() specifies a Target (a GPU architecture), and ft.Device(ft.GPU(), 0) specifies a Device of that target (a specific hardware device of GPU). By calling with on a device, default values of several classes and functions are set, but currently you only need to be aware of two things: It sets the targeting Target and Device of optimize . It sets the default mtype of all tensors in the program, which is an optional parameter of ft.Var , ft.empty , etc. mtype refers to memory type. It controls where a tensor is stored. It defaults to \"cpu\" for a CPU program, and \"gpu/global\" for a GPU program. You probably GPU requires putting each variable to a right place (global memory, shared memory, registers, etc.), and this can be done by setting mtype s of each tensor. There are several ways to set mtype s: (Recommended) Leave them to the default \"gpu/global\" first, and modify them with the set_mem_type schedule. In this way, you write some architecture-dependent schedules, but keep your function architecture-independent. (Experimental) Leave them to the default \"gpu/global\" first, and modify them automatically using auto_schedule , or the auto_set_mem_type schedule (which is a part of auto_schedule ). Set them explicitly in the program by setting an optional mtype parameter of ft.Var , ft.empty , etc. mtype=\"byvalue\" for Dynamic Tensor Shapes Tensors with normal mtypes ( \"cpu\" , \"gpu/global\" , etc.) are passed by references, which means a \"cpu\" tensor can only be accessed from a CPU, and a \"gpu/global\" tensor can only be accessed from a GPU. However, sometimes, and especially for dynamic tensor shapes, we want the shapes to be passed by values, and accessible from both CPUs and GPUs (remember we need tensor's shape both when launching a kernel from the CPU side, and during actual computatoin on the GPU side). In this case, we can set the shape-related tensors a \"byvalue\" mtype , and here is an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.Device(ft.GPU(), 0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! nid: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y)","title":"Running on a GPU"},{"location":"guide/gpu/#running-on-a-gpu","text":"","title":"Running on a GPU"},{"location":"guide/gpu/#example-vector-addition-on-a-gpu","text":"If FreeTensor is built with a CUDA backend, you can compile your program to a GPU. We still take a vector addition as an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.Device(ft.GPU(), 0): n = 4 # Add verbose=1 to see the resulting native code @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize('Li', 'threadIdx.x')) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! nid: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Similar to parallelizing to OpenMP threads , in this example, we parallelize Loop Li to the threadIdx.x dimension of CUDA. There are two major differences: You are now calling parallelize schedule with a threadIdx.x parameter, instead of openmp . All the code are enclosed by a with ft.Device(ft.GPU(), 0) scope. Usually, you not only parallelize your loops to threadIdx.x , but also other CUDA dimensions like blockIdx.x . To achieve this, you either parallelize different loops in a loop nests to different CUDA dimensions, or split your loops before parallelizing them. As for the with ft.Device(ft.GPU(), 0) scope, ft.GPU() specifies a Target (a GPU architecture), and ft.Device(ft.GPU(), 0) specifies a Device of that target (a specific hardware device of GPU). By calling with on a device, default values of several classes and functions are set, but currently you only need to be aware of two things: It sets the targeting Target and Device of optimize . It sets the default mtype of all tensors in the program, which is an optional parameter of ft.Var , ft.empty , etc. mtype refers to memory type. It controls where a tensor is stored. It defaults to \"cpu\" for a CPU program, and \"gpu/global\" for a GPU program. You probably GPU requires putting each variable to a right place (global memory, shared memory, registers, etc.), and this can be done by setting mtype s of each tensor. There are several ways to set mtype s: (Recommended) Leave them to the default \"gpu/global\" first, and modify them with the set_mem_type schedule. In this way, you write some architecture-dependent schedules, but keep your function architecture-independent. (Experimental) Leave them to the default \"gpu/global\" first, and modify them automatically using auto_schedule , or the auto_set_mem_type schedule (which is a part of auto_schedule ). Set them explicitly in the program by setting an optional mtype parameter of ft.Var , ft.empty , etc.","title":"Example: Vector addition on a GPU"},{"location":"guide/gpu/#mtypebyvalue-for-dynamic-tensor-shapes","text":"Tensors with normal mtypes ( \"cpu\" , \"gpu/global\" , etc.) are passed by references, which means a \"cpu\" tensor can only be accessed from a CPU, and a \"gpu/global\" tensor can only be accessed from a GPU. However, sometimes, and especially for dynamic tensor shapes, we want the shapes to be passed by values, and accessible from both CPUs and GPUs (remember we need tensor's shape both when launching a kernel from the CPU side, and during actual computatoin on the GPU side). In this case, we can set the shape-related tensors a \"byvalue\" mtype , and here is an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.Device(ft.GPU(), 0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! nid: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y)","title":"mtype=\"byvalue\" for Dynamic Tensor Shapes"},{"location":"guide/schedules/","text":"Optimize a Program with Schedules Oftentimes, only compiling your programs to native code is not enough, and you need further optimizations. This can be done by applying \"schedules\" (explicit program transformations) to you program. Example: Parallel Vector addition import freetensor as ft import numpy as np n = 4 # Add verbose=1 to see the resulting native code @ft.optimize(schedule_callback=lambda s: s.parallelize('Li', 'openmp') ) # <-- 2. Apply the schedule def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! nid: Li # <-- 1. Name the loop as Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is an example of a parallel vector addition executed with OpenMP multithreading. Each element is computed by one thread. To achieve this, there are two steps: Name the loop to be parallelized with a #! nid: comment. Here nid refers to node ID (of an AST node). Apply a parallelize schedule to Li in the schedule_callback argument to optimize . And you are done. You can have a look at the generated OpenMP multithreaded code by setting verbose=1 . Parameter s in schedule_callback is a Schedule object. Besides parallelize , there are more supported scheduling primitives. Combining Multiple Schdules Some optimizations can be done by applying multiple schedules. For example, a tiled matrix-multiplication can be done by first split the loops, then reorder them, and finally apply cache s to create tile tensors. In order to demonstrate the idea, we show a simplier example here: still a vector addtion, but with the loop split and only the outer one parallelize d. Please note that this is an example only for demonstration. Usually you do not need it because OpenMP has its own \"schedule(static)\" for parallelized loops. import freetensor as ft import numpy as np n = 1024 def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') # Set verbose=1 to see the resulting native code # Set verbose=2 to see the code after EVERY schedule @ft.optimize(schedule_callback=sch) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! nid: Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(np.arange(1024), dtype=\"int32\"), np.array(np.arange(1024), dtype=\"int32\")).numpy() print(y) One important thing is to track names of the loops, because the names will change after schedules. You get names of new loops generated from one schedule from its return values ( outer and inner in this case), and pass them to a next schedule. Auto Scheduling (Experimental) Manually scheduling a program requires a lot of efforts. We provide an experimental automatic scheduling functions in Schedule . You can call s.auto_schedule to pick schedules fully automatically. s.auto_schedule calls other s.auto_xxxxxx functions internally, you can also call one or some of them instead. Please note that these auto-scheduling functions are experimental, and their API is subject to changes.","title":"Optimize a Program with Schedules"},{"location":"guide/schedules/#optimize-a-program-with-schedules","text":"Oftentimes, only compiling your programs to native code is not enough, and you need further optimizations. This can be done by applying \"schedules\" (explicit program transformations) to you program.","title":"Optimize a Program with Schedules"},{"location":"guide/schedules/#example-parallel-vector-addition","text":"import freetensor as ft import numpy as np n = 4 # Add verbose=1 to see the resulting native code @ft.optimize(schedule_callback=lambda s: s.parallelize('Li', 'openmp') ) # <-- 2. Apply the schedule def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! nid: Li # <-- 1. Name the loop as Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is an example of a parallel vector addition executed with OpenMP multithreading. Each element is computed by one thread. To achieve this, there are two steps: Name the loop to be parallelized with a #! nid: comment. Here nid refers to node ID (of an AST node). Apply a parallelize schedule to Li in the schedule_callback argument to optimize . And you are done. You can have a look at the generated OpenMP multithreaded code by setting verbose=1 . Parameter s in schedule_callback is a Schedule object. Besides parallelize , there are more supported scheduling primitives.","title":"Example: Parallel Vector addition"},{"location":"guide/schedules/#combining-multiple-schdules","text":"Some optimizations can be done by applying multiple schedules. For example, a tiled matrix-multiplication can be done by first split the loops, then reorder them, and finally apply cache s to create tile tensors. In order to demonstrate the idea, we show a simplier example here: still a vector addtion, but with the loop split and only the outer one parallelize d. Please note that this is an example only for demonstration. Usually you do not need it because OpenMP has its own \"schedule(static)\" for parallelized loops. import freetensor as ft import numpy as np n = 1024 def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') # Set verbose=1 to see the resulting native code # Set verbose=2 to see the code after EVERY schedule @ft.optimize(schedule_callback=sch) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! nid: Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(np.arange(1024), dtype=\"int32\"), np.array(np.arange(1024), dtype=\"int32\")).numpy() print(y) One important thing is to track names of the loops, because the names will change after schedules. You get names of new loops generated from one schedule from its return values ( outer and inner in this case), and pass them to a next schedule.","title":"Combining Multiple Schdules"},{"location":"guide/schedules/#auto-scheduling-experimental","text":"Manually scheduling a program requires a lot of efforts. We provide an experimental automatic scheduling functions in Schedule . You can call s.auto_schedule to pick schedules fully automatically. s.auto_schedule calls other s.auto_xxxxxx functions internally, you can also call one or some of them instead. Please note that these auto-scheduling functions are experimental, and their API is subject to changes.","title":"Auto Scheduling (Experimental)"}]}