{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"FreeTensor \u00b6 A language and compiler for irregular tensor programs. GitHub User Guide API Reference Publication License Features by Example \u00b6 Write a simple vector addition with loops that compiles to native code: import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) If you are not willing to compile the program once for each different n , you can set n as another function argument (but you may lose some performance). In FreeTensor, all variables are tensors, where scalars are 0-D tensors. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) If building with CUDA, you can also run the program on a GPU. This time, a \" schedule \" (an explicit program transformation) is needed, and memory types of variables should be properly set. import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.GPU(0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Some common tensor operations, including tensor addition (broadcasting is supported), are pre-defined functions in FreeTensor. They are defiend in freetensor.libop , and they can also be invoked using operator overloading. These functions are pure Python functions, which will be inlined into your code, and will enjoy a joint optimization. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = a + b # Or y = ft.add(a, b) return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) FreeTensor also supports reverse-mode Automatic Differentiation: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy())","title":"Home"},{"location":"#features-by-example","text":"Write a simple vector addition with loops that compiles to native code: import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) If you are not willing to compile the program once for each different n , you can set n as another function argument (but you may lose some performance). In FreeTensor, all variables are tensors, where scalars are 0-D tensors. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) If building with CUDA, you can also run the program on a GPU. This time, a \" schedule \" (an explicit program transformation) is needed, and memory types of variables should be properly set. import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.GPU(0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li # Name the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Some common tensor operations, including tensor addition (broadcasting is supported), are pre-defined functions in FreeTensor. They are defiend in freetensor.libop , and they can also be invoked using operator overloading. These functions are pure Python functions, which will be inlined into your code, and will enjoy a joint optimization. import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = a + b # Or y = ft.add(a, b) return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) FreeTensor also supports reverse-mode Automatic Differentiation: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy())","title":"Features by Example"},{"location":"api/","text":"Python API \u00b6 core \u00b6 autograd \u00b6 ArgRetDict \u00b6 Look an object using either a function argument or return value's name or its position Source code in python/freetensor/core/autograd.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ArgRetDict : ''' Look an object using either a function argument or return value's name or its position ''' def __init__ ( self , func , d ): self . func = func self . d = d def __getitem__ ( self , key ): if type ( key ) is Return : key = key . get_name ( self . func ) return self . d [ key ] def __contains__ ( self , key ): # Python's auto fallback from __getitem__ to __contains__ only works for # integer index if type ( key ) is Return : key = key . get_name ( self . func ) return key in self . d def __str__ ( self ): return str ( self . d ) Return \u00b6 Alias of a return value of a function Return(n) represents the n-th return value (counted from 0) Return() can be used if there is only one return value Source code in python/freetensor/core/autograd.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Return : ''' Alias of a return value of a function `Return(n)` represents the n-th return value (counted from 0) `Return()` can be used if there is only one return value ''' def __init__ ( self , n : Optional [ int ] = None ): self . n = n def get_name ( self , func ): assert len ( func . returns ) > 0 , f \" { func . name } has no return value\" if self . n is not None : return func . returns [ self . n ] . name else : assert len ( func . returns ) == 1 , f \" { func . name } has more than one return value, and you need to specify the number of a return value\" return func . returns [ 0 ] . name def __str__ ( self ): return f \"Return( { self . n } )\" grad ( func , requires , provides , tapes = GradTapeMode . NoReuseOnly , tape_in_closure = True , invert = True , user_grads = None , verbose = None ) \u00b6 Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad is an out-of-place version. The resulting gradient are returned from the backward function. Parameters: Name Type Description Default func AST The original function required requires Sequence [ str ] Name of input variables that need gradients required provides Sequence [ Union [ str , Return ]] Name of output variables whose gradients are known. A return value of a function can be specified with a Return object required tapes Union [ Sequence , GradTapeMode ] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history GradTapeMode.NoReuseOnly tape_in_closure bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True True invert bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults True user_grads Optional [ Sequence [ ffi . StmtSetToUserGrad ]] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating func by yourself (not getting it from the Python frontend). See UserGrad for details None verbose Optional [ int ] Verbosity level None Returns: Type Description tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in python/freetensor/core/autograd.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def grad ( func : ffi . Func , requires : Sequence [ str ], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , tape_in_closure : bool = True , invert : bool = True , user_grads : Optional [ Sequence [ ffi . StmtSetToUserGrad ]] = None , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad` is an out-of-place version. The resulting gradient are returned from the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history tape_in_closure : bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True invert: bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults user_grads: List[ffi.StmtSetToUserGrad] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating `func` by yourself (not getting it from the Python frontend). See `UserGrad` for details verbose: int Verbosity level Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad , func , requires , provides , tapes , tape_in_closure , invert , user_grads , verbose = verbose ) grad_ ( func , requires , provides , tapes = GradTapeMode . NoReuseOnly , tape_in_closure = True , invert = True , user_grads = None , verbose = None ) \u00b6 Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad_ is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters: Name Type Description Default func AST The original function required requires Sequence [ str ] Name of input variables that need gradients required provides Sequence [ Union [ str , Return ]] Name of output variables whose gradients are known. A return value of a function can be specified with a Return object required tapes Union [ Sequence , GradTapeMode ] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history GradTapeMode.NoReuseOnly tape_in_closure bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True True invert bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults to true. True user_grads Optional [ Sequence [ ffi . StmtSetToUserGrad ]] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating func by yourself (not getting it from the Python frontend). See UserGrad for details None verbose Optional [ int ] Verbosity level None Returns: Type Description tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in python/freetensor/core/autograd.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def grad_ ( func : ffi . Func , requires : Sequence [ str ], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , tape_in_closure : bool = True , invert : bool = True , user_grads : Optional [ Sequence [ ffi . StmtSetToUserGrad ]] = None , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad_` is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history tape_in_closure : bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True invert: bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults to true. user_grads: List[ffi.StmtSetToUserGrad] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating `func` by yourself (not getting it from the Python frontend). See `UserGrad` for details verbose: int Verbosity level Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad_ , func , requires , provides , tapes , tape_in_closure , invert , user_grads , verbose = verbose ) grad_body ( stmt , requires , provides , tapes = GradTapeMode . NoReuseOnly , invert = True , user_grads = []) \u00b6 grad or grad_ on a function body (for internal tests only) Source code in python/freetensor/core/autograd.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def grad_body ( stmt : ffi . Stmt , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , invert : bool = True , user_grads : Sequence [ ffi . StmtSetToUserGrad ] = []): ''' `grad` or `grad_` on a function body (for internal tests only) ''' req = set ( requires ) prov = set ( provides ) if type ( tapes ) is not GradTapeMode : tapes = { find_stmt ( stmt , t ) . id for t in tapes } return ffi . grad_body ( stmt , req , prov , tapes , invert , user_grads ) codegen \u00b6 codegen ( ast = None , target = None , verbose = None ) \u00b6 Generate native code Parameters: Name Type Description Default ast AST The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator None target Target ( Optional ) The target architecture. If omitted, use the default one in config None Source code in python/freetensor/core/codegen.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def codegen ( ast = None , target : Optional [ ffi . Target ] = None , verbose : Optional [ bool ] = None ) -> NativeCode : ''' Generate native code Parameters ---------- ast : AST The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator target : Target (Optional) The target architecture. If omitted, use the default one in config ''' if ast is not None : if target is None : target = config . default_target () raw_code = ffi . code_gen ( ast , target ) if verbose : print ( debug . with_line_no ( raw_code ), file = sys . stderr ) return NativeCode ( ast , raw_code , target ) else : f = codegen if target is not None : f = functools . partial ( f , target = target ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f config \u00b6 Global configurations context \u00b6 Facility to pick statements to build an AST Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module. ContextStack \u00b6 Source code in python/freetensor/core/context.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class ContextStack : def __init__ ( self ): self . reset () def reset ( self ): self . stack = [ Context ( self )] self . user_grads = [] # [fn(ffi.Stmt)], invoked for every `append_stmt` self . append_stmt_callbacks = [] def top ( self ) -> Context : return self . stack [ - 1 ] def push ( self ): self . stack . append ( Context ( self , self . top () . caller_metadata )) def pop ( self ): return self . stack . pop () def get_stack ( self ) -> List [ Context ]: return self . stack def set_stack ( self , stack : List [ Context ]): self . stack = stack def get_last_stmt_id ( self ): ''' Can be used inside the staged code, to get the ID of the immediately preceding statement ''' for ctx in reversed ( self . stack ): if len ( ctx . stmt_seq ) > 0 : return ctx . stmt_seq [ - 1 ] . id raise ft . InvalidProgram ( \"There is no statement yet\" ) def push_append_stmt_callback ( self , callback : Callable [[ ffi . Stmt ], None ]): ''' Add a callback to be called with all next statements to be appended. For `If` statement, it can be called twice, one without \"else\" branch, and then maybe one more with \"else\" branch ''' self . append_stmt_callbacks . append ( callback ) def pop_append_stmt_callback ( self ): self . append_stmt_callbacks . pop () get_last_stmt_id () \u00b6 Can be used inside the staged code, to get the ID of the immediately preceding statement Source code in python/freetensor/core/context.py 147 148 149 150 151 152 153 154 def get_last_stmt_id ( self ): ''' Can be used inside the staged code, to get the ID of the immediately preceding statement ''' for ctx in reversed ( self . stack ): if len ( ctx . stmt_seq ) > 0 : return ctx . stmt_seq [ - 1 ] . id raise ft . InvalidProgram ( \"There is no statement yet\" ) push_append_stmt_callback ( callback ) \u00b6 Add a callback to be called with all next statements to be appended. For If statement, it can be called twice, one without \"else\" branch, and then maybe one more with \"else\" branch Source code in python/freetensor/core/context.py 156 157 158 159 160 161 def push_append_stmt_callback ( self , callback : Callable [[ ffi . Stmt ], None ]): ''' Add a callback to be called with all next statements to be appended. For `If` statement, it can be called twice, one without \"else\" branch, and then maybe one more with \"else\" branch ''' self . append_stmt_callbacks . append ( callback ) StmtRange \u00b6 Record a set of statement in a program, can be used for custom gradient Usage: with StmtRange() as rng: # Some statements StmtRange can be used interleaved with AST scopes. In these cases, you can directly call __enter__ and __exit__ . E.g., rng = StmtRange() rng.__enter__() # Some statements with VarDef(...) # Some scopes # Some other statements rng.__exit__(None, None, None) Source code in python/freetensor/core/context.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 class StmtRange : ''' Record a set of statement in a program, can be used for custom gradient Usage: ``` with StmtRange() as rng: # Some statements ``` `StmtRange` can be used interleaved with AST scopes. In these cases, you can directly call `__enter__` and `__exit__`. E.g., ``` rng = StmtRange() rng.__enter__() # Some statements with VarDef(...) # Some scopes # Some other statements rng.__exit__(None, None, None) ``` ''' def __init__ ( self ): self . ids = set () self . entered = False self . exited = False def __enter__ ( self ): def callback ( stmt ): self . ids . add ( stmt . id ) ctx_stack . push_append_stmt_callback ( callback ) self . entered = True return self def __exit__ ( self , exc_type , exc_value , traceback ): ctx_stack . pop_append_stmt_callback () self . exited = True def make ( self ): if not self . entered : raise ffi . InvalidProgram ( \"StmtRange is not properly entered\" ) if not self . exited : raise ffi . InvalidProgram ( \"StmtRange is not properly exited\" ) return self . ids pop_ast ( verbose = False ) \u00b6 Get AST and reset context Internally used by transformer and tests Source code in python/freetensor/core/context.py 170 171 172 173 174 175 176 177 178 179 180 181 182 def pop_ast ( verbose : bool = False ): \"\"\" Get AST and reset context Internally used by `transformer` and tests \"\"\" ret = ctx_stack . pop () . make_stmt () ctx_stack . reset () if verbose : print ( \"The popped AST is:\" , file = sys . stderr ) print ( ret , file = sys . stderr ) print ( file = sys . stderr ) return ret pop_ast_and_user_grads ( verbose = False ) \u00b6 Get AST and reset context. Return an extra list for custom gradients Set UserGrad for details Source code in python/freetensor/core/context.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 def pop_ast_and_user_grads ( verbose : bool = False ): \"\"\" Get AST and reset context. Return an extra list for custom gradients Set `UserGrad` for details \"\"\" ast = ctx_stack . pop () . make_stmt () user_grads = ctx_stack . user_grads ctx_stack . reset () if verbose : print ( \"The popped AST is:\" , file = sys . stderr ) print ( ret , file = sys . stderr ) print ( file = sys . stderr ) return ast , user_grads driver \u00b6 Device \u00b6 Bases: ffi . Device A computing device can be constructed from 1. (TargetType, DeviceNumber) 2. (TargetType, getDeviceByName): cuda uses best matches criteria. 3. (TargetType, FullName, nth): get nth(from 0) device named Fullname . E.g. Device(TargetType::GPU, 0) means the 0-th GPU (device) Device(TargetType::GPU, \"V100\") means a GPU which best matches \"V100\" Device(TargetType::GPU, \"NVIDIA GeForce RTX 3060 Laptop GPU\", 0) A Device can be used as a \"with\" scope, then all the Array s and Driver s will use it by default. In this style, it also sets the default Target. E.g: with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default Source code in python/freetensor/core/driver.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 class Device ( ffi . Device ): ''' A computing device can be constructed from 1. (TargetType, DeviceNumber) 2. (TargetType, getDeviceByName): cuda uses best matches criteria. 3. (TargetType, FullName, nth): get nth(from 0) device named `Fullname`. E.g. Device(TargetType::GPU, 0) means the 0-th GPU (device) Device(TargetType::GPU, \"V100\") means a GPU which best matches \"V100\" Device(TargetType::GPU, \"NVIDIA GeForce RTX 3060 Laptop GPU\", 0) A Device can be used as a \"with\" scope, then all the `Array`s and `Driver`s will use it by default. In this style, it also sets the default Target. E.g: ``` with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default ``` ''' def __enter__ ( self ): _old_target_device_stack . append ( ( config . default_target (), config . default_device ())) config . set_default_target ( self . target ()) config . set_default_device ( self ) return self def __exit__ ( self , exc_type , exc_value , traceback ): old_target , old_device = _old_target_device_stack . pop () config . set_default_target ( old_target ) config . set_default_device ( old_device ) Driver \u00b6 Bases: ffi . Driver Source code in python/freetensor/core/driver.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 class Driver ( ffi . Driver ): def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' self . src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , self . src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , self . src , device , host_device , verbose ) self . func = func # When we pass numpy or pytorch tensors to `set_args`, they are # converted to `Array` objects by reference. In `Array`'s FFI, we # keep these tensors alive whenever the `Array`'s PYTHON objects # alive. We need to also keep the `Array`'s PYTHON objects here. # Please note that we cannot hold the reference count in `Driver`'s # C++ implementation, where we can only hold the `Array`'s C++ # objects alive. self . args_ref_cnt_holder = [] def native_code ( self ): ''' Get native code compiled by backend compiler ''' return self . src def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' # No need to hold reference of the last run any more self . args_ref_cnt_holder = [] args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ], dont_drop_borrow = not isinstance ( args [ i ], Array )) for key in kws : kws [ key ] = array ( kws [ key ], dont_drop_borrow = not isinstance ( kws [ key ], Array )) for arg in args : self . args_ref_cnt_holder . append ( arg ) for key in kws : self . args_ref_cnt_holder . append ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws ) def collect_returns ( self , always_return_pack : bool = False ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, or if `always_return_pack` is set, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 and not always_return_pack : return None elif len ( values ) == 1 and not always_return_pack : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values ) def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns () __call__ ( * args , ** kws ) \u00b6 Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call self.set_args first, then self.time , and finally self.collect_returns Source code in python/freetensor/core/driver.py 330 331 332 333 334 335 336 337 338 339 340 341 342 343 def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns () __init__ ( func , src , device = None , host_device = None , verbose = None ) \u00b6 Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using build_binary Parameters: Name Type Description Default func ffi . Func AST of the function, where the function signature is needed to determine the parameters and return values required src str Native code generated from codegen required device Device ( Optional ) The device to run the program. If omitted, use the default device in config None verbose bool ( Optional ) True to print extra infomation None Source code in python/freetensor/core/driver.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' self . src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , self . src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , self . src , device , host_device , verbose ) self . func = func # When we pass numpy or pytorch tensors to `set_args`, they are # converted to `Array` objects by reference. In `Array`'s FFI, we # keep these tensors alive whenever the `Array`'s PYTHON objects # alive. We need to also keep the `Array`'s PYTHON objects here. # Please note that we cannot hold the reference count in `Driver`'s # C++ implementation, where we can only hold the `Array`'s C++ # objects alive. self . args_ref_cnt_holder = [] collect_returns ( always_return_pack = False ) \u00b6 Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, or if always_return_pack is set, the return values are packed in a ReturnValuesPack Source code in python/freetensor/core/driver.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 def collect_returns ( self , always_return_pack : bool = False ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, or if `always_return_pack` is set, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 and not always_return_pack : return None elif len ( values ) == 1 and not always_return_pack : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values ) native_code () \u00b6 Get native code compiled by backend compiler Source code in python/freetensor/core/driver.py 282 283 284 def native_code ( self ): ''' Get native code compiled by backend compiler ''' return self . src set_args ( * args , ** kws ) \u00b6 Set argument for an invocation Source code in python/freetensor/core/driver.py 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' # No need to hold reference of the last run any more self . args_ref_cnt_holder = [] args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ], dont_drop_borrow = not isinstance ( args [ i ], Array )) for key in kws : kws [ key ] = array ( kws [ key ], dont_drop_borrow = not isinstance ( kws [ key ], Array )) for arg in args : self . args_ref_cnt_holder . append ( arg ) for key in kws : self . args_ref_cnt_holder . append ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws ) ReturnValuesPack \u00b6 Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: x, y, z = pack , or in a named manner: pack['x'] Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values Source code in python/freetensor/core/driver.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 class ReturnValuesPack : ''' Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: `x, y, z = pack`, or in a named manner: `pack['x']` Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values ''' def __init__ ( self , keys : Sequence [ str ], values : Sequence [ Array ]): keys = list ( keys ) values = list ( values ) assert len ( keys ) == len ( values ) self . keys = keys self . values = values def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key ) def __contains__ ( self , key ): ''' Test if a return value exists ''' for k , v in zip ( self . keys , self . values ): if k == key : return True return False __contains__ ( key ) \u00b6 Test if a return value exists Source code in python/freetensor/core/driver.py 227 228 229 230 231 232 def __contains__ ( self , key ): ''' Test if a return value exists ''' for k , v in zip ( self . keys , self . values ): if k == key : return True return False __getitem__ ( key ) \u00b6 Get a return value with a name. Tuple is supported for multiple values Source code in python/freetensor/core/driver.py 215 216 217 218 219 220 221 222 223 224 225 def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key ) __iter__ () \u00b6 Get all return values in the order declared in Func Source code in python/freetensor/core/driver.py 211 212 213 def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values array ( data , dtype = None , dont_drop_borrow = False , moved = False ) \u00b6 Factory function for Array This function is preferred over directly calling Array 's constructor, because it accepts more data format. If data is another FreeTensor Array , the original object will be returned, with dont_drop_borrow and moved set to new values. If dtype is set and different from the original data type, the Array will be copied first to convert the data type. If data is Numpy Array or PyTorch Tensor , it will be converted to FreeTensor Array . Memory copy will be avoided in most cases, but it is inevitable if the data is strided. If dtype is set and different from the original data type, the Array or Tensor will be copied first to convert the data type. Otherwise, the data will be treated as an n-dimensional array-like object, and will be parsed according the rules in NumPy. The data type is also set accordingly, unless dtype is set. Parameters: Name Type Description Default data FreeTensor Array, Numpy Array, PyTorch Tensor, or other array-like objects Data to be copied to or borrowed by the new Array object required dtype ft.DataType or str If data is not in dtype , convert it to dtype first before constructing the Array None dont_drop_borrow bool If true, report an error if we have to drop a borrwed data. This flag is set to true when the Array is cunstructed IMPLICITLY (not by this function) from a user object by borrowing from it, where users may expect they are acutually manipulating the their user object, instead of this Array False moved bool If true, it means we do not care about data in this Array any more after the program runs. Variables with \"input-mutable\" access type may modify the Array False Source code in python/freetensor/core/driver.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def array ( data , dtype = None , dont_drop_borrow : bool = False , moved : bool = False ): ''' Factory function for Array This function is preferred over directly calling `Array`'s constructor, because it accepts more data format. - If `data` is another FreeTensor `Array`, the original object will be returned, with `dont_drop_borrow` and `moved` set to new values. If `dtype` is set and different from the original data type, the `Array` will be copied first to convert the data type. - If `data` is Numpy `Array` or PyTorch `Tensor`, it will be converted to FreeTensor `Array`. Memory copy will be avoided in most cases, but it is inevitable if the data is strided. If `dtype` is set and different from the original data type, the `Array` or `Tensor` will be copied first to convert the data type. - Otherwise, the data will be treated as an n-dimensional array-like object, and will be parsed according the rules in NumPy. The data type is also set accordingly, unless `dtype` is set. Parameters ---------- data : FreeTensor Array, Numpy Array, PyTorch Tensor, or other array-like objects Data to be copied to or borrowed by the new Array object dtype : ft.DataType or str If `data` is not in `dtype`, convert it to `dtype` first before constructing the `Array` dont_drop_borrow : bool If true, report an error if we have to drop a borrwed data. This flag is set to true when the Array is cunstructed IMPLICITLY (not by this function) from a user object by borrowing from it, where users may expect they are acutually manipulating the their user object, instead of this Array moved : bool If true, it means we do not care about data in this Array any more after the program runs. Variables with \"input-mutable\" access type may modify the Array ''' if dtype is not None : dtype = DataType ( dtype ) if type ( data ) is Array : if dtype is not None and dtype != data . dtype : # Must be contiguous data = Array ( data . numpy () . astype ( to_numpy_dtype ( dtype ))) data . set_dont_drop_borrow ( dont_drop_borrow ) data . set_moved ( moved ) return data # For NumPy, Although Pybind11's `array_t` type provides a flag `forcecast` to # cast from a strided array to a contiguous one. But it always casts to a specific # type, e.g. float64. I have no idea how to support multiple types. Therfore, # we have to call NumPy's `.copy(order='C')` to make a new NumPy array. This # function can only be called from Python side (not from PyBind11's `py::array` # type). if type ( data ) is np . ndarray : if dtype is not None and to_numpy_dtype ( dtype ) != data . dtype : data = data . astype ( to_numpy_dtype ( dtype ), order = 'C' ) elif not data . flags [ 'C_CONTIGUOUS' ]: data = data . copy ( order = 'C' ) return Array ( data , dont_drop_borrow , moved ) if data . __class__ . __module__ == 'torch' : import torch if type ( data ) is torch . Tensor : if not config . with_pytorch (): raise ffi . InvalidIO ( \"FreeTensor should be built with WITH_PYTORCH to accept a PyTorch tensor\" ) if dtype is not None and to_torch_dtype ( dtype ) != data . dtype : data = data . to ( to_torch_dtype ( dtype ), memory_format = torch . contiguous_format ) elif not data . is_contiguous (): data = data . contiguous () return Array ( data , dont_drop_borrow , moved ) return array ( np . array ( data , dtype = None if dtype is None else to_numpy_dtype ( dtype )), dtype = dtype , dont_drop_borrow = dont_drop_borrow , moved = moved ) build_binary ( code = None , device = None , host_device = None , verbose = None ) \u00b6 Compile a program using a backend compiler and load it into memory Parameters: Name Type Description Default code NativeCode Native code generated by codegen . If not specified, a partial function is returned, which can be used as a decorator None device Device ( Optional ) The device to run the program. If omitted, use the default device in config None Source code in python/freetensor/core/driver.py 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 def build_binary ( code : Optional [ NativeCode ] = None , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory Parameters ---------- code : NativeCode Native code generated by `codegen`. If not specified, a partial function is returned, which can be used as a decorator device : Device (Optional) The device to run the program. If omitted, use the default device in config ''' if code is not None : if device is None : device = config . default_device () if device . target () != code . target : raise ffi . DriverError ( f \"Codegen target ( { code . target } ) is inconsistent with device target ( { device . target () } )\" ) return Driver ( code . func , code . code , device , host_device , verbose ) else : f = build_binary if device is not None : f = functools . partial ( f , device = device ) if host_device is not None : f = functools . partial ( f , host_device = host_device ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f move ( data ) \u00b6 Alias for array(data, dont_drop_borrow=False, moved=True) Source code in python/freetensor/core/driver.py 102 103 104 105 def move ( data ): ''' Alias for array(data, dont_drop_borrow=False, moved=True) ''' return array ( data , dont_drop_borrow = False , moved = True ) expr \u00b6 Facility to build AST expressions Classes and functions in this module are not only used internally for constructing AST nodes, and also exposed to users via multi-stage programming AlreadyMadeReduceTo \u00b6 A single-value type that marks a ReduceTo node is already made, and there is no need to make another Store node In standard Python data model, functions like iadd returns the modified self, and setitem does a self-assignment. We do the augmenting assignment directly in iadd and return AlreadyMadeReduceTo, so we do not have to Store it again Source code in python/freetensor/core/expr.py 29 30 31 32 33 34 35 36 37 38 class AlreadyMadeReduceTo : \"\"\" A single-value type that marks a ReduceTo node is already made, and there is no need to make another Store node In standard Python data model, functions like __iadd__ returns the modified self, and __setitem__ does a self-assignment. We do the augmenting assignment directly in __iadd__ and return AlreadyMadeReduceTo, so we do not have to Store it again \"\"\" pass VarRef \u00b6 Bases: ffi . FrontendVar Variable of FreeTensor All variables in FreeTensor DSL (declared via Var , created by empty or var , returned by libop , etc.), and their slices, are VarRef objects. Operations on VarRef objects generates AST nodes Source code in python/freetensor/core/expr.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 class VarRef ( ffi . FrontendVar ): ''' Variable of FreeTensor All variables in FreeTensor DSL (declared via `Var`, created by `empty` or `var`, returned by `libop`, etc.), and their slices, are `VarRef` objects. Operations on `VarRef` objects generates AST nodes ''' def __init__ ( self , name : str , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = [], is_load_at_version : bool = False ): super ( VarRef , self ) . __init__ ( name , full_shape , dtype , mtype , indices , is_load_at_version ) from .stmt import find_borrowed_vardefs self . borrowed_vardefs = find_borrowed_vardefs ( indices ) for item in self . borrowed_vardefs : item . lend_out () def __del__ ( self ): for item in self . borrowed_vardefs : item . reclaim () def __getitem__ ( self , key ): return self . __class__ ( self . name , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) def __setitem__ ( self , key , value ): var = self . __class__ ( self . name , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) if var . ndim > 0 : if value is AlreadyMadeReduceTo : return from .. import libop libop . assign ( var , value ) return if value is AlreadyMadeReduceTo : return top = ctx_stack . top () top . append_stmt ( var . as_store ( top . get_metadata (), value )) def as_store ( self , metadata , value ): if ( not isinstance ( value , ffi . AnyExpr ) and ffi . up_cast ( dtype ( value ), self . dtype ) . base != self . dtype . base ): # Add explicit cast node, to avoid confusion after propagation value = cast ( value , self . dtype ) return super ( VarRef , self ) . as_store ( metadata , value ) def as_reduce_to ( self , reduce_op , metadata , value , atomic = False ): if ( not isinstance ( value , ffi . AnyExpr ) and ffi . up_cast ( dtype ( value ), self . dtype ) . base != self . dtype . base ): # Add explicit cast node, to avoid confusion after propagation value = cast ( value , self . dtype ) return super ( VarRef , self ) . as_reduce_to ( reduce_op , metadata , value , atomic ) def select ( self , idx , dim ): assert isinstance ( dim , int ) assert dim >= 0 and dim < self . ndim indices = [ slice ( None , None ) if d != dim else idx for d in range ( self . ndim ) ] return self [ indices ] def shape ( self , dim = None ): ''' Return lengths of all dimensions or the length of one dimension `.shape()` -> list of lengths of all dimensions `.shape(dim)` -> length of dimension `dim`, where `dim` can be `int` or `Expr` All lengths can be `Expr` (if the length is dynamically decided) or `int` (if statically decided) ''' intOrExpr = lambda x : x . val if isinstance ( x , ffi . IntConst ) else x if dim is None : return [ intOrExpr ( d ) for d in super ( VarRef , self ) . shape ()] else : return intOrExpr ( super ( VarRef , self ) . shape ( dim )) def _parse_key ( self , key ): if key is None or key is ... : key = () if not isinstance ( key , collections . abc . Sequence ): key = ( key ,) ffiIdx = [] for idx , length in zip ( key , self . shape ()): if isinstance ( idx , slice ): start = idx . start if idx . start is not None else 0 stop = idx . stop if idx . stop is not None else length assert idx . step is None or idx . step == 1 ffiIdx . append ( ffi . FrontendVarIdx ( start , stop )) elif isinstance ( idx , VarRef ): if len ( idx . full_shape ) == len ( idx . indices ): ffiIdx . append ( ffi . FrontendVarIdx ( idx . as_load ())) else : assert len ( key ) == 1 , f \"Shape of an index of { self . name } should be 1-D, instead of { idx . name } \" assert type ( idx . full_shape [ 0 ] ) is ffi . IntConst , \"Dynamic number of dimensions is not supported\" ndim = idx . full_shape [ 0 ] . val ffiIdx += [ ffi . FrontendVarIdx ( idx [ i ] . as_load ()) for i in range ( ndim ) ] else : ffiIdx . append ( ffi . FrontendVarIdx ( idx )) return ffiIdx def __add__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( self , other ) return self . as_load () + other def __radd__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( other , self ) return other + self . as_load () def __iadd__ ( self , other ): if self . ndim > 0 : from .. import libop libop . add_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Add , top . get_metadata (), other )) return AlreadyMadeReduceTo def __sub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( self , other ) return self . as_load () - other def __rsub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( other , self ) return other - self . as_load () def __isub__ ( self , other ): if self . ndim > 0 : from .. import libop libop . sub_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Add , top . get_metadata (), - other )) return AlreadyMadeReduceTo def __mul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( self , other ) return self . as_load () * other def __rmul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( other , self ) return other * self . as_load () def __imul__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mul_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Mul , top . get_metadata (), other )) return AlreadyMadeReduceTo def __truediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( self , other ) return self . as_load () / other def __rtruediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( other , self ) return other / self . as_load () def __itruediv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . truediv_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Mul , top . get_metadata (), 1. / other )) return AlreadyMadeReduceTo def __floordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( self , other ) return self . as_load () // other def __rfloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( other , self ) return other // self . as_load () def __ifloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . floordiv_to ( self , other ) return AlreadyMadeReduceTo return NotImplemented # Fallback to x = x // y def __mod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( self , other ) return self . as_load () % other def __rmod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( other , self ) return other % self . as_load () def __imod__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mod_to ( self , other ) return AlreadyMadeReduceTo return NotImplemented # Fallback to x = x % y def __lt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . lt ( self , other ) return self . as_load () < other def __le__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . le ( self , other ) return self . as_load () <= other def __gt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . gt ( self , other ) return self . as_load () > other def __ge__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ge ( self , other ) return self . as_load () >= other def __eq__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . eq ( self , other ) return self . as_load () == other def __ne__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ne ( self , other ) return self . as_load () != other def __neg__ ( self ): if self . ndim > 0 : from .. import libop return libop . neg ( self ) return 0 - self . as_load () def __matmul__ ( self , other ): from .. import libop return libop . matmul ( self , other ) def __rmatmul__ ( self , other ): from .. import libop return libop . matmul ( other , self ) shape ( dim = None ) \u00b6 Return lengths of all dimensions or the length of one dimension .shape() -> list of lengths of all dimensions .shape(dim) -> length of dimension dim , where dim can be int or Expr All lengths can be Expr (if the length is dynamically decided) or int (if statically decided) Source code in python/freetensor/core/expr.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def shape ( self , dim = None ): ''' Return lengths of all dimensions or the length of one dimension `.shape()` -> list of lengths of all dimensions `.shape(dim)` -> length of dimension `dim`, where `dim` can be `int` or `Expr` All lengths can be `Expr` (if the length is dynamically decided) or `int` (if statically decided) ''' intOrExpr = lambda x : x . val if isinstance ( x , ffi . IntConst ) else x if dim is None : return [ intOrExpr ( d ) for d in super ( VarRef , self ) . shape ()] else : return intOrExpr ( super ( VarRef , self ) . shape ( dim )) VarRefFromVarDef \u00b6 Bases: VarRef VarRef with extra checks Source code in python/freetensor/core/expr.py 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 class VarRefFromVarDef ( VarRef ): ''' VarRef with extra checks ''' def __init__ ( self , name : str , vardef , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = []): super ( VarRefFromVarDef , self ) . __init__ ( name , full_shape , dtype , mtype , indices ) self . vardef = vardef def __getitem__ ( self , key ): return VarRefFromVarDef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) def __setitem__ ( self , key , value ): var = VarRefFromVarDef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) if var . ndim > 0 : if value is AlreadyMadeReduceTo : return from .. import libop libop . assign ( var , value ) return if not is_writable ( var . vardef . atype ): raise ffi . InvalidProgram ( f \"Cannot modify an \\\" { var . vardef . atype } \\\" tensor ` { self . name } `\" ) if var . vardef . borrower_cnt > 0 : raise ffi . InvalidProgram ( \"Cannot modify tensor `\" + self . name + \"` becuase it has been borrowed in another tensor's shape, \" \"a tensor slice, or a range of a loop\" ) if value is AlreadyMadeReduceTo : # Following the checks above return top = ctx_stack . top () top . append_stmt ( var . as_store ( top . get_metadata (), value )) VarVersionRef \u00b6 Bases: VarRef Special VarRef used for custom gradient, generated from mark_version Source code in python/freetensor/core/expr.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 class VarVersionRef ( VarRef ): ''' Special VarRef used for custom gradient, generated from `mark_version` ''' def __init__ ( self , name : str , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = []): for dim in full_shape : if not isinstance ( dim , int ) and not isinstance ( dim , ffi . IntConst ): raise ffi . InvalidAutoGrad ( \"`mark_version` on dynamic-shaped variables is not supported\" \" yet\" ) super ( VarVersionRef , self ) . __init__ ( name , full_shape , dtype , mtype , indices , True ) abs ( expr ) \u00b6 Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The absolute value Source code in python/freetensor/core/expr.py 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 def abs ( expr ): ''' Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The absolute value ''' if _istensor ( expr ): from .. import libop return libop . abs ( expr ) if isinstance ( expr , Number ): return builtins . abs ( expr ) return ffi . makeAbs ( expr ) add ( lhs , rhs ) \u00b6 lhs + rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The sum Source code in python/freetensor/core/expr.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 def add ( lhs , rhs ): ''' `lhs + rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The sum ''' return lhs + rhs any () \u00b6 Create an AnyExpr node (only for testing and type inference) Any nodes matches any expression nodes in ast.match Source code in python/freetensor/core/expr.py 1203 1204 1205 1206 1207 1208 1209 def any (): ''' Create an AnyExpr node (only for testing and type inference) Any nodes matches any expression nodes in `ast.match` ''' return ffi . makeAnyExpr () cast ( expr , dtype ) \u00b6 Cast to another type Parameters: Name Type Description Default expr VarRef or Number The operand required dtype DataTypr or str The target data type required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 def cast ( expr , dtype ): ''' Cast to another type Parameters ---------- expr : VarRef or Number The operand dtype : DataTypr or str The target data type Returns ------- VarRef or Number The result ''' return ffi . makeCast ( expr , ffi . DataType ( dtype )) ceil ( expr ) \u00b6 Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 def ceil ( expr ): ''' Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . ceil ( expr ) return ffi . makeCeil ( expr ) ceildiv ( lhs , rhs ) \u00b6 Ceiling integer division of lhs dividing by rhs The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 def ceildiv ( lhs , rhs ): ''' Ceiling integer division of `lhs` dividing by `rhs` The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . ceildiv ( lhs , rhs ) if type ( lhs ) is int and type ( rhs ) is int : return lhs // rhs + ( lhs % rhs > 0 ) return ffi . makeCeilDiv ( lhs , rhs ) dtype ( var ) \u00b6 Get element data type of a variable Source code in python/freetensor/core/expr.py 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 def dtype ( var ): ''' Get element data type of a variable ''' if isinstance ( var , VarRef ): return var . dtype elif isinstance ( var , ffi . Expr ): return var . dtype else : # TODO: Config default type if isinstance ( var , bool ): # NOTE: before int, because bool in Python is a sub-class of int return ffi . DataType ( \"bool\" ) elif isinstance ( var , float ): return ffi . DataType ( \"float32\" ) elif isinstance ( var , int ): return ffi . DataType ( \"int32\" ) else : raise Exception ( 'Unknown scalar type: ' + str ( type ( var ))) eq ( lhs , rhs ) \u00b6 lhs == rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 def eq ( lhs , rhs ): ''' `lhs == rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs == rhs exp ( expr ) \u00b6 Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The exponent Source code in python/freetensor/core/expr.py 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 def exp ( expr ): ''' Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The exponent ''' if _istensor ( expr ): from .. import libop return libop . exp ( expr ) if isinstance ( expr , Number ): return math . exp ( expr ) return ffi . makeExp ( expr ) floor ( expr ) \u00b6 Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 def floor ( expr ): ''' Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . floor ( expr ) return ffi . makeFloor ( expr ) floordiv ( lhs , rhs ) \u00b6 Floored integer division of lhs dividing by rhs The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over round_towards_0_div , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 def floordiv ( lhs , rhs ): ''' Floored integer division of `lhs` dividing by `rhs` The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over `round_towards_0_div`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs // rhs ge ( lhs , rhs ) \u00b6 lhs >= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 def ge ( lhs , rhs ): ''' `lhs >= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs >= rhs gt ( lhs , rhs ) \u00b6 lhs > rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 def gt ( lhs , rhs ): ''' `lhs > rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs > rhs if_then_else ( cond , then_case , else_case ) \u00b6 Similar to then_case if cond else else_case NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use if_then_else to guard an out-of-bound array indexing Parameters: Name Type Description Default cond VarRef of Number Condition required lhs VarRef or Number Then-case experssion required rhs VarRef or Number Else-case expression required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 def if_then_else ( cond , then_case , else_case ): ''' Similar to `then_case if cond else else_case` NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use `if_then_else` to guard an out-of-bound array indexing Parameters ---------- cond : VarRef of Number Condition lhs : VarRef or Number Then-case experssion rhs : VarRef or Number Else-case expression Returns ------- VarRef or Number The result ''' if type ( cond ) is bool : return then_case if cond else else_case return ffi . makeIfExpr ( cond , then_case , else_case ) intrinsic ( fmt , * params , ** kws ) \u00b6 Invoke whatever target code Parameters: Name Type Description Default fmt str What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) required The Parameters to fmt required ret_type DataType or str (Keyword argument only) The return type. Void for no return type. Defaults to Void required has_side_effect (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false required Source code in python/freetensor/core/expr.py 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 def intrinsic ( fmt , * params , ** kws ): \"\"\" Invoke whatever target code Parameters ---------- fmt : str What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) The following variadic arguments : Expr Parameters to `fmt` ret_type : DataType or str (Keyword argument only) The return type. Void for no return type. Defaults to Void has_side_effect: bool (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false \"\"\" ret_type = ffi . DataType ( \"void\" ) has_side_effect = False if \"ret_type\" in kws : ret_type = ffi . DataType ( kws [ \"ret_type\" ]) del kws [ \"ret_type\" ] if \"has_side_effect\" in kws : has_side_effect = kws [ \"has_side_effect\" ] del kws [ \"has_side_effect\" ] assert len ( kws ) == 0 , \"Unrecognized keyword arguments: %s \" % kws return ffi . makeIntrinsic ( fmt , params , ret_type , has_side_effect ) l_and ( lhs , rhs ) \u00b6 Logical and of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The logical and Source code in python/freetensor/core/expr.py 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 def l_and ( lhs , rhs ): ''' Logical and of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical and ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_and ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs and rhs else : return ffi . makeLAnd ( lhs , rhs ) l_not ( expr ) \u00b6 Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The logical not Source code in python/freetensor/core/expr.py 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 def l_not ( expr ): ''' Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The logical not ''' if _istensor ( expr ): from .. import libop return libop . l_not ( expr ) if type ( expr ) is bool : return not expr else : return ffi . makeLNot ( expr ) l_or ( lhs , rhs ) \u00b6 Logical or of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The logical or Source code in python/freetensor/core/expr.py 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 def l_or ( lhs , rhs ): ''' Logical or of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical or ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_or ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs or rhs else : return ffi . makeLOr ( lhs , rhs ) le ( lhs , rhs ) \u00b6 lhs <= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 def le ( lhs , rhs ): ''' `lhs <= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs <= rhs ln ( expr ) \u00b6 Natural logarithm For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ln Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The exponent Source code in python/freetensor/core/expr.py 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 def ln ( expr ): ''' Natural logarithm For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ln Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The exponent ''' if _istensor ( expr ): from .. import libop return libop . ln ( expr ) if isinstance ( expr , Number ): return math . log ( expr ) # Defaults to ln without the base return ffi . makeLn ( expr ) load_at_version ( tape_name , dtype , * indices ) \u00b6 Create an LoadAtVersion node (only for custom gradient) This node is only used for custom gradient. See UserGradForPrevStmt . Source code in python/freetensor/core/expr.py 1212 1213 1214 1215 1216 1217 1218 def load_at_version ( tape_name : str , dtype , * indices ): ''' Create an LoadAtVersion node (only for custom gradient) This node is only used for custom gradient. See `UserGradForPrevStmt`. ''' return ffi . makeLoadAtVersion ( tape_name , indices , ffi . DataType ( dtype )) lt ( lhs , rhs ) \u00b6 lhs < rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 def lt ( lhs , rhs ): ''' `lhs < rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs < rhs max ( lhs , rhs ) \u00b6 Maximum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The maximum Source code in python/freetensor/core/expr.py 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 def max ( lhs , rhs ): ''' Maximum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The maximum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . max ( lhs , rhs ) if isinstance ( lhs , Number ) and isinstance ( rhs , Number ): return builtins . max ( lhs , rhs ) return ffi . makeMax ( lhs , rhs ) min ( lhs , rhs ) \u00b6 Minimum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The minimum Source code in python/freetensor/core/expr.py 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 def min ( lhs , rhs ): ''' Minimum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The minimum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . min ( lhs , rhs ) if isinstance ( lhs , Number ) and isinstance ( rhs , Number ): return builtins . min ( lhs , rhs ) return ffi . makeMin ( lhs , rhs ) mod ( lhs , rhs ) \u00b6 lhs modulus rhs The result is always non-negative (following Python convention, instead of C). This function is recommended over remainder , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The modulo Source code in python/freetensor/core/expr.py 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 def mod ( lhs , rhs ): ''' `lhs` modulus `rhs` The result is always non-negative (following Python convention, instead of C). This function is recommended over `remainder`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The modulo ''' return lhs % rhs mtype ( var ) \u00b6 Get memory type of a variable Source code in python/freetensor/core/expr.py 1260 1261 1262 1263 1264 1265 def mtype ( var ): ''' Get memory type of a variable ''' if isinstance ( var , VarRef ): return var . mtype else : return 'byvalue' mul ( lhs , rhs ) \u00b6 lhs * rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The product Source code in python/freetensor/core/expr.py 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 def mul ( lhs , rhs ): ''' `lhs * rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The product ''' return lhs * rhs ndim ( var ) \u00b6 Get the number of dimensions of a variable Source code in python/freetensor/core/expr.py 1221 1222 1223 1224 1225 1226 def ndim ( var ): ''' Get the number of dimensions of a variable ''' if isinstance ( var , VarRef ): return var . ndim else : return 0 ne ( lhs , rhs ) \u00b6 lhs != rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 def ne ( lhs , rhs ): ''' `lhs != rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs != rhs remainder ( lhs , rhs ) \u00b6 Remainder of lhs dividing rhs The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use lhs % rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The remainder Source code in python/freetensor/core/expr.py 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 def remainder ( lhs , rhs ): ''' Remainder of `lhs` dividing `rhs` The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use `lhs % rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The remainder ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . remainder ( lhs , rhs ) return ffi . makeRemainder ( lhs , rhs ) round_towards_0_div ( lhs , rhs ) \u00b6 C-style integer division of lhs dividing by rhs The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use lhs // rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 def round_towards_0_div ( lhs , rhs ): ''' C-style integer division of `lhs` dividing by `rhs` The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use `lhs // rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . round_towards_0_div ( lhs , rhs ) return ffi . makeRoundTowards0Div ( lhs , rhs ) shape ( var , i = None ) \u00b6 shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable Source code in python/freetensor/core/expr.py 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 def shape ( var , i = None ): ''' shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable ''' if isinstance ( var , VarRef ): return var . shape ( i ) else : if i is None : return () else : raise Exception ( f 'Getting size of dimension { i } of scalar { var } ' ) sigmoid ( expr ) \u00b6 Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 def sigmoid ( expr ): ''' Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . sigmoid ( expr ) return ffi . makeSigmoid ( expr ) sqrt ( expr ) \u00b6 Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The square root Source code in python/freetensor/core/expr.py 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 def sqrt ( expr ): ''' Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square root ''' if _istensor ( expr ): from .. import libop return libop . sqrt ( expr ) if isinstance ( expr , Number ): return math . sqrt ( expr ) return ffi . makeSqrt ( expr ) square ( expr ) \u00b6 Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The square Source code in python/freetensor/core/expr.py 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 def square ( expr ): ''' Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square ''' if _istensor ( expr ): from .. import libop return libop . square ( expr ) if isinstance ( expr , Number ): return expr * expr return ffi . makeSquare ( expr ) sub ( lhs , rhs ) \u00b6 lhs - rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The difference Source code in python/freetensor/core/expr.py 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 def sub ( lhs , rhs ): ''' `lhs - rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The difference ''' return lhs - rhs tanh ( expr ) \u00b6 Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 def tanh ( expr ): ''' Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . tanh ( expr ) if isinstance ( expr , Number ): return math . tanh ( expr ) return ffi . makeTanh ( expr ) truediv ( lhs , rhs ) \u00b6 Floating point division of lhs dividing by rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 def truediv ( lhs , rhs ): ''' Floating point division of `lhs` dividing by `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs / rhs frontend \u00b6 A frontend transforming user Python functions to ASTs via staging. FreeTensorOverload \u00b6 Bases: StagingOverload Helper class managing context in IR staging. Source code in python/freetensor/core/frontend.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 class FreeTensorOverload ( StagingOverload ): '''Helper class managing context in IR staging.''' def __init__ ( self ): super () . __init__ () self . lifetime_stack : List [ LifetimeScope ] = [] self . closure : Dict [ str , Any ] = {} self . name_dict : Dict [ str , int ] = {} def register_vardef ( self , name , shape , dtype , atype , mtype = None , capture = None ): fullname = self . fullname ( name ) if capture : self . closure [ fullname ] = capture return self . lifetime_stack [ - 1 ] . register_inner_scope ( _VarDef ( fullname , shape , dtype , atype , mtype )) def register_inlined_invoke ( self , ret_names : Sequence [ str ], func : ffi . Func , args , kvs ): ret_names = [ self . fullname ( name ) for name in ret_names ] return self . lifetime_stack [ - 1 ] . register_inner_scope ( Invoke ( ret_names , func , args , kvs )) def register_assert ( self , pred ): self . lifetime_stack [ - 1 ] . register_inner_scope ( Assert ( pred )) def fullname ( self , name : str ) -> str : '''Get distinct name.''' if name in self . name_dict : self . name_dict [ name ] += 1 return f ' { name } _ { self . name_dict [ name ] } ' else : self . name_dict [ name ] = 0 return name def in_staging ( self ,): return len ( self . lifetime_stack ) > 0 def custom_attr ( self , obj : Any , attr : str ) -> Any : if attr == \"ndim\" : return ndim ( obj ) if attr == \"shape\" : return lambda i = None : shape ( obj , i ) if attr == \"dtype\" : return dtype ( obj ) if attr == \"mtype\" : return mtype ( obj ) raise AttributeError () def functiondef_wrapper ( self , filename : str , func ): basic_wrapped = super () . functiondef_wrapper ( filename , func ) def wrapped ( * args , __freetensor_transform_outermost__ = False , ** kwargs ): if __freetensor_transform_outermost__ : call_metadata = None else : call_metadata = ctx_stack . top () . get_metadata () ctx_stack . top () . clear_metadata () prev = ctx_stack . top () . caller_metadata ctx_stack . top () . set_caller_metadata ( call_metadata ) result = basic_wrapped ( * args , ** kwargs ) ctx_stack . top () . set_caller_metadata ( prev ) return result return wrapped def metadata ( self , entry : str ) -> None : parts = entry . split () if len ( parts ) == 0 : return key = parts [ 0 ] val = None if len ( parts ) > 1 : val = parts [ 1 ] if key == 'label:' : if val is not None : ctx_stack . top () . add_label ( val ) return elif key == 'no_deps:' : if val is not None : back = inspect . currentframe () . f_back if val in back . f_locals : var = back . f_locals [ val ] elif val in back . f_globals : var = back . f_globals [ val ] else : raise self . error ( f 'Variable { val } not found for annotating comment ( { key } : { val } )' ) if not isinstance ( var , VarRef ): raise self . error ( f 'Variable { val } = { var } is not a VarRef, which is required by annotating comment ( { key } : { val } )' ) ctx_stack . top () . add_next_no_deps ( var . name ) return elif key == 'prefer_libs' : ctx_stack . top () . set_next_prefer_libs () return raise ffi . InvalidProgram ( '''Invalid metadata. Possible metadata are: `label: <label_name>`: to label the following statement, `no_deps: <variable_name>`: to mark a variable to have no dependence along the following loop, `prefer_libs`: to indicate the following statement should preferably be executed using external libraries. ''' ) def at_position ( self , filename : str , lineno : int ) -> None : ctx_stack . top () . set_next_location ( filename , lineno ) fullname ( name ) \u00b6 Get distinct name. Source code in python/freetensor/core/frontend.py 99 100 101 102 103 104 105 106 def fullname ( self , name : str ) -> str : '''Get distinct name.''' if name in self . name_dict : self . name_dict [ name ] += 1 return f ' { name } _ { self . name_dict [ name ] } ' else : self . name_dict [ name ] = 0 return name LifetimeScope \u00b6 This scope is used to register multiple scopes inside a single lifetime scope. The inner scopes might be used to register variables, etc. They will be exited in reverse order of their registration. Source code in python/freetensor/core/frontend.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class LifetimeScope : '''This scope is used to register multiple scopes inside a single lifetime scope. The inner scopes might be used to register variables, etc. They will be exited in reverse order of their registration. ''' def __init__ ( self ): self . inner_scopes = [] def __enter__ ( self ): lang_overload . lifetime_stack . append ( self ) def __exit__ ( self , exc_type , exc_val , exc_tb ): for scope in reversed ( self . inner_scopes ): scope . __exit__ ( exc_type , exc_val , exc_tb ) popped = lang_overload . lifetime_stack . pop () if popped != self : raise lang_overload . error ( 'LifetimeScope enter/exit not match, must be FILO' ) def register_inner_scope ( self , scope ): self . inner_scopes . append ( scope ) return scope . __enter__ () UserGrad \u00b6 Bases: UserGradStaged Define a custom gradient Follow the following steps to define custom gradient: Add some mark_version statements in the program. mark_version('y0', y) marks the specific versions of variable y at the program position of the statement and at all iterations as 'y0' . Add a UserGrad scope. 2.1. UserGrad optionally receives parameter stmt_range , recorded by the StmtRange helper class, which means the gradient is for the code specified in the range. Ignoring the parameter means setting gradient for the previous statement of the scope. 2.2. Other parameters of UserGrad sets the mapping from original variables to gradient variables. with UserGradForPrevStmt(x, y) as (dx, dy) provides VarRef dx and dy as gradient variables to be used inside the scope. In order to use the value from the forward pass in the backward pass, do not access the forward variables directly in the scope. Instead, use load_at_version expressions. load_at_version(y0, i, j) loads from y[i, j] at the specific version marked by y0 = mark_version(y) , saved from the same iteration in the forward pass . (If directly writing staged code, it is MarkVersion('y0', y) ). In other words, after AD, the position of mark_version and the dynamic loop iterator together makes up the actual version number for the tape. Build the AST with pop_ast_and_user_grads instead of pop_ast . An extra list will be returned together with the AST, which you need to pass as grad 's user_grads argument. This list records the forward-to-backward relation of the nodes. If you are directly writing staged code, use UserGradStaged instead. Parameters: Name Type Description Default stmt_range The range in the original program that we are setting custom gradient for required args Sequence [ VarRef ] (Positional variadic) Mapping from original variables to gradient variables () Source code in python/freetensor/core/frontend.py 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 class UserGrad ( UserGradStaged ): ''' Define a custom gradient Follow the following steps to define custom gradient: 1. Add some `mark_version` statements in the program. `mark_version('y0', y)` marks the specific versions of variable `y` **at the program position of the statement** and **at all iterations** as `'y0'`. 2. Add a `UserGrad` scope. 2.1. `UserGrad` optionally receives parameter `stmt_range`, recorded by the `StmtRange` helper class, which means the gradient is for the code specified in the range. Ignoring the parameter means setting gradient for the previous statement of the scope. 2.2. Other parameters of `UserGrad` sets the mapping from original variables to gradient variables. `with UserGradForPrevStmt(x, y) as (dx, dy)` provides `VarRef` `dx` and `dy` as gradient variables to be used inside the scope. 3. In order to use the value from the forward pass in the backward pass, do not access the forward variables directly in the scope. Instead, use `load_at_version` expressions. `load_at_version(y0, i, j)` loads from `y[i, j]` **at the specific version marked by `y0 = mark_version(y)`**, saved from **the same iteration in the forward pass**. (If directly writing staged code, it is `MarkVersion('y0', y)`). In other words, after AD, the position of `mark_version` and the dynamic loop iterator together makes up the actual version number for the tape. 4. Build the AST with `pop_ast_and_user_grads` instead of `pop_ast`. An extra list will be returned together with the AST, which you need to pass as `grad`'s `user_grads` argument. This list records the forward-to-backward relation of the nodes. If you are directly writing staged code, use `UserGradStaged` instead. Parameters ---------- stmt_range: Optional[StmtRange] The range in the original program that we are setting custom gradient for args: Sequence[VarRef] (Positional variadic) Mapping from original variables to gradient variables ''' def __init__ ( self , * args : Sequence [ VarRef ], ** kvs ): super ( UserGrad , self ) . __init__ ( * args , ** kvs ) self . lifetime_scope = LifetimeScope () def __enter__ ( self ): ret = super ( UserGrad , self ) . __enter__ () self . lifetime_scope . __enter__ () return ret def __exit__ ( self , exc_type , exc_value , traceback ): self . lifetime_scope . __exit__ ( exc_type , exc_value , traceback ) return super ( UserGrad , self ) . __exit__ ( exc_type , exc_value , traceback ) Var \u00b6 Bases: StagedTypeAnnotation Source code in python/freetensor/core/frontend.py 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 class Var ( StagedTypeAnnotation ): def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype def annotate ( self , name : str ) -> VarRef : return lang_overload . register_vardef ( name , self . shape , self . dtype , self . atype , self . mtype ) __init__ ( shape , dtype , atype = 'input' , mtype = None ) \u00b6 Declare a variable Parameters: Name Type Description Default name str Name of the variable required shape Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape required dtype str or DataType Data type of the variable required atype str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" 'input' mtype str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used None Source code in python/freetensor/core/frontend.py 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype VarCreator dataclass \u00b6 Bases: StagedAssignable Source code in python/freetensor/core/frontend.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 @dataclass class VarCreator ( StagedAssignable ): shape : Union [ Sequence , VarRef ] dtype : str mtype : str assigned : bool = False def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' if not self . assigned : self . assigned = True return lang_overload . register_vardef ( name , self . shape , self . dtype , 'cache' , self . mtype ) else : raise lang_overload . error ( \"Create new tensors in an `a = b = c`-like multi-assignment \" \"is not supported\" ) assign ( name ) \u00b6 Customized assign behavior. Creates a VarDef with its full name. Source code in python/freetensor/core/frontend.py 244 245 246 247 248 249 250 251 252 253 def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' if not self . assigned : self . assigned = True return lang_overload . register_vardef ( name , self . shape , self . dtype , 'cache' , self . mtype ) else : raise lang_overload . error ( \"Create new tensors in an `a = b = c`-like multi-assignment \" \"is not supported\" ) VersionMarker dataclass \u00b6 Bases: StagedAssignable Source code in python/freetensor/core/frontend.py 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 @dataclass class VersionMarker ( StagedAssignable ): var : VarRef assigned : bool = False def assign ( self , tape_name : str ) -> VarRef : '''Customized assign behavior. Creates a MarkVersion with its full name.''' if not self . assigned : self . assigned = True full_tape_name = lang_overload . fullname ( tape_name ) MarkVersion ( full_tape_name , self . var ) return VarVersionRef ( full_tape_name , self . var . full_shape , self . var . dtype , self . var . mtype , self . var . indices ) else : raise lang_overload . error ( \"Marking version in an `a = b = c`-like multi-assignment is not\" \" supported\" ) assign ( tape_name ) \u00b6 Customized assign behavior. Creates a MarkVersion with its full name. Source code in python/freetensor/core/frontend.py 393 394 395 396 397 398 399 400 401 402 403 404 405 def assign ( self , tape_name : str ) -> VarRef : '''Customized assign behavior. Creates a MarkVersion with its full name.''' if not self . assigned : self . assigned = True full_tape_name = lang_overload . fullname ( tape_name ) MarkVersion ( full_tape_name , self . var ) return VarVersionRef ( full_tape_name , self . var . full_shape , self . var . dtype , self . var . mtype , self . var . indices ) else : raise lang_overload . error ( \"Marking version in an `a = b = c`-like multi-assignment is not\" \" supported\" ) dynamic_range \u00b6 Bases: StagedIterable Dynamic range that generates For loop in IR tree. Source code in python/freetensor/core/frontend.py 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 class dynamic_range ( StagedIterable ): '''Dynamic range that generates For loop in IR tree.''' def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step def foreach ( self , name , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' if not isinstance ( name , str ): raise lang_overload . error ( 'dynamic_range only supports exactly one target variable' ) # Early optimizations if isinstance ( self . start , Number ) and isinstance ( self . stop , Number ) and isinstance ( self . step , Number ): if not range ( self . start , self . stop , self . step ): return if len ( range ( self . start , self . stop , self . step )) == 1 : with LifetimeScope (): body ( self . start ) return with lang_overload . allow_shortcut_scope ( False ): with For ( lang_overload . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var ) __init__ ( start , stop = None , step = 1 ) \u00b6 Initialize a dynamic range. Arguments semantic identical to builtin range . Source code in python/freetensor/core/frontend.py 482 483 484 485 486 487 488 489 490 491 def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step foreach ( name , body ) \u00b6 Customized foreach behavior. Creates a For loop. Source code in python/freetensor/core/frontend.py 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 def foreach ( self , name , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' if not isinstance ( name , str ): raise lang_overload . error ( 'dynamic_range only supports exactly one target variable' ) # Early optimizations if isinstance ( self . start , Number ) and isinstance ( self . stop , Number ) and isinstance ( self . step , Number ): if not range ( self . start , self . stop , self . step ): return if len ( range ( self . start , self . stop , self . step )) == 1 : with LifetimeScope (): body ( self . start ) return with lang_overload . allow_shortcut_scope ( False ): with For ( lang_overload . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var ) push_for_backward ( var ) \u00b6 Push the current value from the forward pass to be used at the backward pass This function is for custom gradients. See UserGrad for details on how to provide custom gradients. You may imagine there is a virtual stack for each variable. Each time you call x_handle = push_for_backward(x) in the forward pass, the value of x at the current iteration will be \"pushed\" to the virtual stack. You can access x_handle at the backward pass. Each time you access x_handle , you will \"pop\" the stack and get the value of x pushed at the same iteration . Since the \"stack\" is virtual, you do NOT need to \"pop\" the same count as \"push\"es: the version numbering is fully automatic. Besides, there may not be a real stack at runtime: it can be compiled to any data structure. This function will be staged to mark_version statement in the IR. Source code in python/freetensor/core/frontend.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def push_for_backward ( var : VarRef ): ''' Push the current value from the forward pass to be used at the backward pass This function is for custom gradients. See `UserGrad` for details on how to provide custom gradients. You may imagine there is a virtual stack for each variable. Each time you call `x_handle = push_for_backward(x)` in the forward pass, the value of `x` **at the current iteration** will be \"pushed\" to the virtual stack. You can access `x_handle` at the backward pass. Each time you access `x_handle`, you will \"pop\" the stack and get the value of `x` **pushed at the same iteration**. Since the \"stack\" is virtual, you do NOT need to \"pop\" the same count as \"push\"es: the version numbering is fully automatic. Besides, there may not be a real stack at runtime: it can be compiled to any data structure. This function will be staged to `mark_version` statement in the IR. ''' return VersionMarker ( var ) func \u00b6 Func \u00b6 Bases: ffi . Func Source code in python/freetensor/core/func.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class Func ( ffi . Func ): def __init__ ( self , name : str , params : Sequence [ FuncParam ], returns : Sequence [ FuncRet ], body : ffi . Stmt , extra_closure = {}, user_grads = []): super () . __init__ ( name , params , returns , body , extra_closure ) self . user_grads = user_grads # Mimic a Python function self . __name__ = name def __call__ ( self , * args , ** kvs ): ''' Enable invoking a transformed AST in another function being transformed, via `inlined_invoke` ''' if lang_overload . in_staging (): if len ( self . returns ) == 1 : names = ( self . name ,) else : names = tuple ( f \" { self . name } . { i } \" for i in range ( len ( self . returns ))) return lang_overload . register_inlined_invoke ( names , self , args , kvs ) else : raise lang_overload . error ( 'Unexpected call on a transformed AST. A transformed AST can only ' 'be called in the following two ways: 1) called with actual data ' 'after `@optimize`, and 2) called from another function to be ' '`@transform`ed' ) __call__ ( * args , ** kvs ) \u00b6 Enable invoking a transformed AST in another function being transformed, via inlined_invoke Source code in python/freetensor/core/func.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __call__ ( self , * args , ** kvs ): ''' Enable invoking a transformed AST in another function being transformed, via `inlined_invoke` ''' if lang_overload . in_staging (): if len ( self . returns ) == 1 : names = ( self . name ,) else : names = tuple ( f \" { self . name } . { i } \" for i in range ( len ( self . returns ))) return lang_overload . register_inlined_invoke ( names , self , args , kvs ) else : raise lang_overload . error ( 'Unexpected call on a transformed AST. A transformed AST can only ' 'be called in the following two ways: 1) called with actual data ' 'after `@optimize`, and 2) called from another function to be ' '`@transform`ed' ) optimize \u00b6 optimize ( func = None , schedule_callback = None , target = None , device = None , default_dynamic_range = True , verbose = None ) \u00b6 An one-click optimization from Python function to binary executable Usage: @optimize def f(...): ... It is equivalent to: @build_binary @codegen @lower @transform def f(...): ... Parameters: Name Type Description Default func Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator None schedule_callback Callable ( Optional ) Schedule(s) to apply None target Target ( Optional ) The target architecture. You don't have to set target if you set device None device Device ( Optional ) Where to run the program None default_dynamic_range bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True True verbose int ( Optional ) Verbosity level. Can be 0, 1 or 2 None Source code in python/freetensor/core/optimize.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def optimize ( func = None , schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , target : Optional [ Target ] = None , device : Optional [ Device ] = None , default_dynamic_range : bool = True , verbose : Optional [ int ] = None ): ''' An one-click optimization from Python function to binary executable Usage: ``` @optimize def f(...): ... ``` It is equivalent to: ``` @build_binary @codegen @lower @transform def f(...): ... ``` Parameters ---------- func : Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator schedule_callback : Callable (Optional) Schedule(s) to apply target : Target (Optional) The target architecture. You don't have to set target if you set device device : Device (Optional) Where to run the program default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int (Optional) Verbosity level. Can be 0, 1 or 2 ''' if func is not None : if target is None and device is not None : target = device . target () if not issubclass ( type ( func ), ffi . AST ): ast = transform ( func , default_dynamic_range = default_dynamic_range , verbose = verbose ) else : ast = func ast = schedule ( ast , schedule_callback , verbose = verbose ) ast = lower ( ast , target , verbose = verbose ) code = codegen ( ast , target , verbose = verbose ) exe = build_binary ( code , device , verbose = verbose ) return exe else : return functools . partial ( optimize , schedule_callback = schedule_callback , target = target , device = device , default_dynamic_range = default_dynamic_range , verbose = verbose ) optimize_to_pytorch ( func = None , tapes = GradTapeMode . NoReuseOnly , forward_schedule_callback = None , backward_schedule_callback = None , target = None , device = None , default_dynamic_range = True , verbose = None ) \u00b6 Compile a FreeTensor function to a PyTorch call, whose gradient can be recognized by PyTorch The compiled function will be a typical PyTorch's \"function\" (rather than a PyTorch's \"module\"). Technically, this means it is a wrapper function around a PyTorch's Function 's apply method Schedules (if any) must be applied to the forward function and the backward function separated. For this reason, currently only first-order gradient is supported Parameters: Name Type Description Default func Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator None tapes Union [ Sequence , GradTapeMode ] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history GradTapeMode.NoReuseOnly forward_schedule_callback Callable ( Optional ) Schedule(s) to apply to the forward function None backward_schedule_callback Callable ( Optional ) Schedule(s) to apply to the backward function None target Target ( Optional ) The target architecture. You don't have to set target if you set device None device Device ( Optional ) Where to run the program None default_dynamic_range bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True True verbose int ( Optional ) Verbosity level. Can be 0, 1 or 2 None Source code in python/freetensor/core/optimize.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def optimize_to_pytorch ( func = None , tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , forward_schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , backward_schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , target : Optional [ Target ] = None , device : Optional [ Device ] = None , default_dynamic_range : bool = True , verbose : Optional [ int ] = None ): ''' Compile a FreeTensor function to a PyTorch call, whose gradient can be recognized by PyTorch The compiled function will be a typical PyTorch's \"function\" (rather than a PyTorch's \"module\"). Technically, this means it is a wrapper function around a PyTorch's `Function`'s `apply` method Schedules (if any) must be applied to the forward function and the backward function separated. For this reason, currently only first-order gradient is supported Parameters ---------- func : Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history forward_schedule_callback : Callable (Optional) Schedule(s) to apply to the forward function backward_schedule_callback : Callable (Optional) Schedule(s) to apply to the backward function target : Target (Optional) The target architecture. You don't have to set target if you set device device : Device (Optional) Where to run the program default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int (Optional) Verbosity level. Can be 0, 1 or 2 ''' if func is not None : import torch # Transform from Python source to AST if not issubclass ( type ( func ), ffi . AST ): ast = transform ( func , default_dynamic_range = default_dynamic_range , verbose = verbose ) else : ast = func # Compile lazily because we know `requires` and `provides` only when # executing. Re-compile when gradient requirements changes saved_requires = set () saved_provides = set () cur_requires = None cur_provides = None fwd_exe = None bwd_exe = None input_grad_map = None output_grad_map = None tape_rets = None def lazy_compile (): nonlocal saved_requires , saved_provides , cur_requires , cur_provides nonlocal fwd_exe , bwd_exe , input_grad_map , output_grad_map , tape_rets if saved_requires == cur_requires and saved_provides == cur_provides : return saved_requires = cur_requires saved_provides = cur_provides if len ( cur_requires ) != 0 : fwd_ast , bwd_ast , input_grad_map , output_grad_map = grad ( ast , requires = saved_requires , provides = saved_provides , tapes = tapes , # PyTorch requires explicitly marking saved states via # `save_for_backward()` tape_in_closure = False , verbose = verbose ) tape_rets = fwd_ast . returns [ len ( ast . returns ):] fwd_exe = optimize ( fwd_ast , forward_schedule_callback , target , device , default_dynamic_range , verbose ) bwd_exe = optimize ( bwd_ast , backward_schedule_callback , target , device , default_dynamic_range , verbose ) else : # No one needs grad. No need to do autograd fwd_ast = ast fwd_exe = optimize ( fwd_ast , forward_schedule_callback , target , device , default_dynamic_range , verbose ) bwd_exe = None input_grad_map = {} output_grad_map = {} tape_rets = [] # Generate a PyTorch Function class GeneratedPyTorchFunction ( torch . autograd . Function ): @staticmethod def forward ( ctx , * args , ** kvs ): nonlocal cur_requires , cur_provides # We only get to know provided gradients of output tensors when we # run `backward`, but we need to run autograd and compile the program # here in `forward`. We can only assume gradients are provided for # every output tensors, even if they are unrelated to the inputs. # Setting this option to True makes PyTorch generate zero gradient # for such outputs. (TODO: better solution?) ctx . set_materialize_grads ( True ) # Gather required gradients of the inputs cur_requires = set () for param , arg in zip ( ast . params , args ): if arg . requires_grad : cur_requires . add ( param . name ) for key , value in kvs . items (): if value . requires_grad : cur_requires . add ( key ) # For the reason above, we assume gradients are provided for every # output tensors cur_provides = set () for ret in ast . returns : cur_provides . add ( ret . name ) lazy_compile () fwd_exe . set_args ( * args , ** kvs ) fwd_exe . run () returns = fwd_exe . collect_returns ( always_return_pack = True ) returns = tuple ( item . torch () for item in returns ) # Save states for 1) all inputs and 2) all taped tensors (taped # outputs are also taped tensors). For taped tensors, we need to # make them output tensors, so PyTorch can recognize them. This is # an officially recommanded trick at # https://pytorch.org/tutorials/intermediate/custom_function_double_backward_tutorial.html#saving-intermediate-results # So, please be aware that only the first part in `returns` are real # return tensors saved_tensors = [] for arg in args : # 1) saved_tensors . append ( arg ) for ret in returns : # 2) and maybe other junks saved_tensors . append ( ret ) ctx . save_for_backward ( * saved_tensors ) return returns [ 0 ] if len ( returns ) == 1 else returns @staticmethod @torch . autograd . function . once_differentiable def backward ( ctx , * args , ** kvs ): saved_tensors = ctx . saved_tensors internal_kvs = {} for ret , arg in zip ( ast . returns , args ): internal_kvs [ output_grad_map [ ret . name ]] = arg for key , value in kvs : internal_kvs [ output_grad_map [ key ]] = value for param , saved in zip ( ast . params , saved_tensors ): # NOTE: Now we only support \"input\" parameters for PyTorch # interface (no \"inout\" or \"output\"), so we can forward all # parameters. If we support \"inout\" or \"output\" in the future, # we need to filter only \"input\" parameters here internal_kvs [ param . name ] = saved for tape_ret , saved in zip ( tape_rets , saved_tensors [ len ( ast . params ) + len ( ast . returns ):]): internal_kvs [ tape_ret . name ] = saved bwd_exe . set_args ( ** internal_kvs ) bwd_exe . run () input_grads = bwd_exe . collect_returns ( always_return_pack = True ) # PyTorch requires returning gradient of inputs in their original # order. If no gradient is required for an input, set it to None returns = tuple ( input_grads [ input_grad_map [ param . name ]] . torch ( ) if param . name in input_grad_map else None for param in ast . params ) return returns [ 0 ] if len ( returns ) == 1 else returns # Wrap around the PyTorch `Function`, to be a real Python \"function\", and # remove our extra tape outputs def generatedPyTorchFunction ( * args , ** kvs ): returns = GeneratedPyTorchFunction . apply ( * args , ** kvs ) returns_tuple = returns if isinstance ( returns , Sequence ) else ( returns ,) returns_tuple = returns_tuple [: len ( ast . returns )] return returns_tuple [ 0 ] if len ( returns_tuple ) == 1 else returns_tuple # If called inside a FreeTensor funcion, don't care about PyTorch, just # inline the transformed AST return staged_callable ( ast , generatedPyTorchFunction ) else : return functools . partial ( optimize_to_pytorch , tapes = tapes , forward_schedule_callback = forward_schedule_callback , backward_schedule_callback = backward_schedule_callback , target = target , device = device , default_dynamic_range = default_dynamic_range , verbose = verbose ) passes \u00b6 lower ( ast = None , target = None , skip_passes = None , verbose = None ) \u00b6 Lower an AST using a series of passes Parameters: Name Type Description Default ast AST The AST to be lowered. Can be a Func or a Stmt . If not specified, a partial function of lower will be returned, which can be used as a decorator None target Target ( Optional ) Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config None skip_passes Sequence [ str ]( Optional ) Skip some pass for testing or debugging. Names in skip_passes are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes None verbose int ( Optional ) 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes None Source code in python/freetensor/core/passes.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def lower ( ast = None , target : Optional [ ffi . Target ] = None , skip_passes : Optional [ Sequence [ str ]] = None , verbose : Optional [ int ] = None ): ''' Lower an AST using a series of passes Parameters ---------- ast : AST The AST to be lowered. Can be a `Func` or a `Stmt`. If not specified, a partial function of `lower` will be returned, which can be used as a decorator target : Target (Optional) Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config skip_passes : Sequence[str] (Optional) Skip some pass for testing or debugging. Names in `skip_passes` are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes verbose : int (Optional) 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes ''' if ast is not None : return ffi . lower ( ast , target , set () if skip_passes is None else set ( skip_passes ), 0 if verbose is None else verbose ) else : _lower = lower if target is not None : _lower = functools . partial ( _lower , target = target ) if skip_passes is not None : _lower = functools . partial ( _lower , skip_passes = skip_passes ) if verbose is not None : _lower = functools . partial ( _lower , verbose = verbose ) return _lower staging \u00b6 A staging framework to support the FreeTensor frontend. AllowShortcutScope dataclass \u00b6 Allow return scope. This is a context manager that allows return in statically deterministic control flow. Source code in python/freetensor/core/staging.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 @dataclass class AllowShortcutScope : '''Allow return scope. This is a context manager that allows return in statically deterministic control flow. ''' overload : StagingOverload should_allow : bool def __enter__ ( self ): self . prev = self . overload . is_shortcut_allowed self . overload . is_shortcut_allowed = self . should_allow def __exit__ ( self , exc_class , exc_value , traceback ): self . overload . is_shortcut_allowed = self . prev BreakException \u00b6 Bases: Exception Exception to be raised by StagingOverload.break_stmt. Breaks from a for loop. Source code in python/freetensor/core/staging.py 68 69 70 71 class BreakException ( Exception ): '''Exception to be raised by StagingOverload.break_stmt. Breaks from a for loop.''' pass ContinueException \u00b6 Bases: Exception Exception to be raised by StagingOverload.continue_stmt. Continues a for loop. Source code in python/freetensor/core/staging.py 74 75 76 77 class ContinueException ( Exception ): '''Exception to be raised by StagingOverload.continue_stmt. Continues a for loop.''' pass ReturnException \u00b6 Bases: Exception Exception to be raised by StagingOverload.return_stmt. Holds a return value that will be passed through to the function wrapper. Source code in python/freetensor/core/staging.py 60 61 62 63 64 65 class ReturnException ( Exception ): '''Exception to be raised by StagingOverload.return_stmt. Holds a return value that will be passed through to the function wrapper.''' def __init__ ( self , value : Any ) -> None : self . value = value StagingError \u00b6 Bases: Exception Error occurred during staging function execution (i.e. IR tree generation). Source code in python/freetensor/core/staging.py 33 34 35 36 37 38 39 40 class StagingError ( Exception ): '''Error occurred during staging function execution (i.e. IR tree generation).''' def __init__ ( self , overload : StagingOverload , message : str ) -> None : # TODO: add output of StagingContext.call_stack super () . __init__ ( f ' { message } : \\n { \"\" . join ( traceback . format_list ( overload . debug_call_stack )) } ' . lstrip ()) StagingOverload \u00b6 Source code in python/freetensor/core/staging.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 class StagingOverload : def __init__ ( self ) -> None : self . is_shortcut_allowed : bool = True self . debug_call_stack : List [ traceback . FrameSummary ] = [] def custom_attr ( self , obj : Any , attr : str ) -> Any : ''' Customized attribute accessor. The framework first looks for a Python native attribute. If not found, it looks for this overloaded custom attribute resolver. The default implementation provides no custom attribute. Can be overridden by subclasses. Parameters ---------- obj : Any Object to access attribute. attr : str Attribute name. Returns ------- Any : The attribute value. Throws ------ AttributeError : If the attribute is not found. ''' return None def metadata ( self , content ) -> None : ''' Metadata handler. A metadata line is a comment starting with `#! ` and followed by a metadata, represented as a string parameter. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- content : str The metadata content. ''' pass def at_position ( self , filename : str , lineno : int ) -> None : ''' Code position handler. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- filename : str Name of the file containing code for the next statement. lineno : int Line number of the next statement. ''' pass def error ( self , content : str ): return StagingError ( self , content ) def allow_shortcut_scope ( self , allow : bool ): '''Opens a scope that allows shortcut control flows in a statically deterministic context. Need to be closed by `with` statement.''' return AllowShortcutScope ( self , allow ) def foreach ( self , names , iter , body : Callable [[ Any ], None ]) -> None : '''Customized foreach wrapper. If `value` is instance of `StagedIterable`, its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. ''' if isinstance ( iter , StagedIterable ): iter . foreach ( names , body ) else : for iter_var in iter : try : body ( iter_var ) except BreakException : break except ContinueException : continue def unpack_assign_stmt ( self , names , values ): '''Customized assign wrapper for one or more targets. If `values` is instance of `StagedUnpackAssignable`, it's regarded as a customized assign behavior and gets executed with all the assigned targets' names. Otherwise, it calls `assign_stmt` with each sub-assignments. Please note that `names` can be nested tuples like `(\"a\", (\"b\", \"c\"))`. Please also note that `names` can also be a single string like \"a\" even if `values` is a tuple. There is no unpacking in this case ''' if isinstance ( values , StagedUnpackAssignable ): return values . assign ( names ) elif isinstance ( names , str ): return self . assign_stmt ( names , values ) else : assert isinstance ( names , Sequence ) values = tuple ( values ) if len ( names ) != len ( values ): raise self . error ( \"Number of return values does not match when unpacking\" ) returns = [] for name , value in zip ( names , values ): returns . append ( self . unpack_assign_stmt ( name , value )) return tuple ( returns ) def assign_stmt ( self , name : str , value ): '''Customized assign wrapper. If `value` is instance of `StagedAssignable`, it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. ''' if isinstance ( value , StagedAssignable ): return value . assign ( name ) else : return value def if_then_else_stmt ( self , predicate , then_body , else_body = None ): '''If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. ''' if isinstance ( predicate , StagedPredicate ): predicate . if_then_else_stmt ( then_body , else_body ) else : if predicate : then_body () elif else_body : else_body () def if_then_else_expr ( self , predicate , then_expr , else_expr ): '''If-then-else expression staging tool.''' if isinstance ( predicate , StagedPredicate ): return predicate . if_then_else_expr ( then_expr , else_expr ) else : if predicate : return then_expr () else : return else_expr () def while_stmt ( self , fpred , body ): '''While statement staging tool.''' first_pred = fpred () if isinstance ( first_pred , StagedPredicate ): first_pred . while_stmt ( body ) else : if first_pred : try : body () except BreakException : return except ContinueException : pass while fpred (): try : body () except BreakException : break except ContinueException : continue def assert_stmt ( self , test ): '''Assert staging tool.''' if isinstance ( test , StagedPredicate ): test . assert_stmt () else : assert test def return_stmt ( self , value , funcname ): '''Return staging tool. Only allow return in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Return is only allowed in statically deterministic control flow.' ) if isinstance ( value , StagedUnpackAssignable ): # We don't know how many items are there, so no unpacking value = value . assign ( funcname ) if isinstance ( value , StagedAssignable ): value = value . assign ( funcname ) raise ReturnException ( value ) def break_stmt ( self ): '''Break staging tool. Only allow break in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Break is only allowed in statically deterministic control flow.' ) raise BreakException () def continue_stmt ( self ): '''Continue staging tool. Only allow continue in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Continue is only allowed in statically deterministic control flow.' ) raise ContinueException () def load_attr ( self , obj , attr : str ): '''Load attribute staging tool. Allows customization of reading attributes.''' try : return getattr ( obj , attr ) except AttributeError : try : # Have to use AttributeError again, since a custom attribute might have # a None value result = self . custom_attr ( obj , attr ) successful = True except AttributeError : successful = False if successful : return result else : raise def and_expr ( self , * lazy_args ): def reducer ( a , fb ): if isinstance ( a , StagedPredicate ): return a . logical_and ( fb ) else : # This is not a simple logical and; it's equivalent to a if-then-else. # Thus, if a is True, fb() is returned, preserving the original value, # which might be a StagedPredicate. return a and fb () return functools . reduce ( reducer , lazy_args , True ) def or_expr ( self , * lazy_args ): def reducer ( a , fb ): if isinstance ( a , StagedPredicate ): return a . logical_or ( fb ) else : return a or fb () return functools . reduce ( reducer , lazy_args , False ) def not_expr ( self , arg ): if isinstance ( arg , StagedPredicate ): return arg . logical_not () else : return not arg def functiondef_decorator ( self , filename ): return functools . partial ( self . functiondef_wrapper , filename ) def functiondef_wrapper ( self , filename , func ): '''Function definition wrapper. This wrapper performs extra initialization and cleanup for function definition. ''' def wrapped ( * args , ** kwargs ): # Push debug call stack with some random line number. # It will be updated by `mark_position` calls in the function. self . debug_call_stack . append ( traceback . FrameSummary ( filename , 1 , func . __name__ )) # The called function can now return from itself, despite what the outer # control flow is. with self . allow_shortcut_scope ( True ): try : func ( * args , ** kwargs ) except ReturnException as e : result = e . value else : # No return_stmt was called, naturally returns None result = None # Pop debug call stack. self . debug_call_stack . pop () return result return wrapped def annotate_stmt ( self , name : str , ty ): if isinstance ( ty , StagedTypeAnnotation ): return ty . annotate ( name ) return None def mark_position ( self , lineno : int ): # FrameSummary is immutable, so we have to initialize a new one with updated # line number. self . debug_call_stack [ - 1 ] = traceback . FrameSummary ( self . debug_call_stack [ - 1 ] . filename , lineno , self . debug_call_stack [ - 1 ] . name ) self . at_position ( self . debug_call_stack [ - 1 ] . filename , self . debug_call_stack [ - 1 ] . lineno ) def into_staging ( self , func , extra_locals : Dict [ str , Any ] = None , src : str = None , verbose = False ): assert inspect . isfunction ( func ) if extra_locals is None : extra_locals = {} if src is None : lines , lineno = ins . getsourcelines ( func ) src = '' . join ( lines ) file = ins . getfile ( func ) else : lineno = 1 file = f '<staging: { func . __name__ } >' # Inject overload to extra_locals. extra_locals [ '__staging_overload__' ] = self # To transform a function, except essential AST transformation, we have to pass # the globals and locals (actually captured outer local variables) to the # transformed function properly. # Note that: # 1. We have to pass both globals and locals to `exec`. # 2. We cannot insert locals to the globals `dict`, otherwise it will pollute # the globals `dict`. # 3. We cannot copy the globals `dict` before passing it to exec, otherwise the # staged function cannot write to globals and get later updates in the global. # Thus, we have to pass the globals and locals to the transformed function # separately. if func . __closure__ : assert len ( func . __code__ . co_freevars ) == len ( func . __closure__ ) func_locals = { name : cell for name , cell in zip ( func . __code__ . co_freevars , func . __closure__ ) } else : func_locals = {} # Translate `#! ` comments to metadata calls. src = process_annotating_comments ( src ) # Wrap the code if it has a indentation. if src [ 0 ] == ' ' or src [ 0 ] == ' \\t ' : src = 'if True: \\n ' + src tree = ast . parse ( src ) assert len ( tree . body ) == 1 and isinstance ( tree . body [ 0 ], ast . If ) # Replace with the real body to eliminate the faked if. tree . body = tree . body [ 0 ] . body # Modify lineno to match with the location. lineno -= 1 else : tree = ast . parse ( src ) # Replace the annotations with __staging_annotations__ assert isinstance ( tree , ast . Module ) and isinstance ( tree . body [ - 1 ], ast . FunctionDef ) tree . body [ - 1 ] . args = ReplaceAnnotations ( func . __annotations__ . keys ()) . visit ( tree . body [ 0 ] . args ) tree = Transformer ( file , lineno ) . visit ( tree ) # Instead of passing the `func_local` directly to `exec`, we instead wrap the # staging function. This is to workaround an issue of CPython. (See # https://github.com/python/cpython/issues/86084). # The sketch is: # ``` # def __freetensor_staging_wrapper__(__freetensor_extra_locals__, # __freetensor_local_cells__): # some_extra_local = __freetensor_extra_locals__['some_extra_local'] # some_captured = None # # def original_func(): # nonlocal some_captured # some_captured = __freetensor_local_cells__.some_captured # try: # ... # original function body # finally: # __freetensor_local_cells__.some_captured = some_captured # # return original_func # ``` # Note that `__freetensor_local_cells__` is a `LocalsDictWrapper` object. # It in-turn accesses cell.cell_contents to get/set the value of the local # variable. # The `LocalsDictWrapper` is a helper class to reduce code generation complexity. WRAPPER_NAME = '__freetensor_staging_wrapper__' assert isinstance ( tree , ast . Module ) and isinstance ( tree . body [ - 1 ], ast . FunctionDef ) # Modify function body. if len ( func_locals ) > 0 : tree . body [ - 1 ] . body = ([ # Declare them as nonlocals to assign to outer scope. ast . Nonlocal ( list ( func_locals . keys ())), ] + [ # Fetch latest values of the closure variables. ast . Assign ([ ast . Name ( name , ast . Store ())], ast . Attribute ( ast . Name ( '__freetensor_local_cells__' , ast . Load ()), name , ast . Load ())) for name in func_locals . keys () ] + [ # Use a try-finally to ensure closure write back. ast . Try ( body = tree . body [ - 1 ] . body , handlers = [], orelse = [], finalbody = [ ast . Assign ([ ast . Attribute ( ast . Name ( '__freetensor_local_cells__' , ast . Load ()), name , ast . Store ()) ], ast . Name ( name , ast . Load ())) for name in func_locals . keys () ]) ]) tree . body = [ ast . FunctionDef ( name = WRAPPER_NAME , args = ast . arguments ( posonlyargs = [], args = [ ast . arg ( '__freetensor_extra_locals__' , None ), ast . arg ( '__freetensor_local_cells__' , None ), ast . arg ( '__staging_annotations__' , None ), ], vararg = None , kwonlyargs = [], kw_defaults = [], kwarg = None , defaults = []), body = [ # Captured closure variables are not fetched here, only declared. ast . Assign ([ ast . Name ( name , ast . Store ())], ast . Constant ( None )) for name in func_locals . keys () ] + [ # Extra locals are fetched here. ast . Assign ([ ast . Name ( name , ast . Store ())], ast . Subscript ( ast . Name ( '__freetensor_extra_locals__' , ast . Load ()), ast_index ( ast . Constant ( name )), ast . Load ())) for name in extra_locals . keys () ] + tree . body + [ ast . Return ( value = ast . Name ( id = func . __name__ , ctx = ast . Load ()))], decorator_list = [], returns = None ), ] tree = ast . fix_missing_locations ( tree ) if verbose : import astor source = astor . to_source ( tree ) if config . pretty_print (): from pygments import highlight from pygments.lexers import PythonLexer from pygments.formatters import TerminalFormatter print ( highlight ( source , PythonLexer (), TerminalFormatter ( bg = 'dark' , linenos = True )), file = sys . stderr ) else : print ( source ) tree = source # make debug info match dumped source # Create an empty locals dict to avoid polluting the original globals. empty_locals = {} exec ( compile ( tree , f '<staging: { func . __name__ } >' , 'exec' ), func . __globals__ , empty_locals ) f_wrapper = empty_locals [ WRAPPER_NAME ] # Pass the closure to the wrapper and retrieve the staging function with # correct captured variables. f_staging = f_wrapper ( extra_locals , LocalsDictWrapper ( func_locals ), func . __annotations__ ) return f_staging allow_shortcut_scope ( allow ) \u00b6 Opens a scope that allows shortcut control flows in a statically deterministic context. Need to be closed by with statement. Source code in python/freetensor/core/staging.py 184 185 186 187 def allow_shortcut_scope ( self , allow : bool ): '''Opens a scope that allows shortcut control flows in a statically deterministic context. Need to be closed by `with` statement.''' return AllowShortcutScope ( self , allow ) assert_stmt ( test ) \u00b6 Assert staging tool. Source code in python/freetensor/core/staging.py 288 289 290 291 292 293 def assert_stmt ( self , test ): '''Assert staging tool.''' if isinstance ( test , StagedPredicate ): test . assert_stmt () else : assert test assign_stmt ( name , value ) \u00b6 Customized assign wrapper. If value is instance of StagedAssignable , it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. Source code in python/freetensor/core/staging.py 233 234 235 236 237 238 239 240 241 242 def assign_stmt ( self , name : str , value ): '''Customized assign wrapper. If `value` is instance of `StagedAssignable`, it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. ''' if isinstance ( value , StagedAssignable ): return value . assign ( name ) else : return value at_position ( filename , lineno ) \u00b6 Code position handler. Defaults to a no-op. Can be overridden by subclasses. Parameters: Name Type Description Default filename str Name of the file containing code for the next statement. required lineno int Line number of the next statement. required Source code in python/freetensor/core/staging.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def at_position ( self , filename : str , lineno : int ) -> None : ''' Code position handler. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- filename : str Name of the file containing code for the next statement. lineno : int Line number of the next statement. ''' pass break_stmt () \u00b6 Break staging tool. Only allow break in static control flow. Source code in python/freetensor/core/staging.py 308 309 310 311 312 313 314 def break_stmt ( self ): '''Break staging tool. Only allow break in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Break is only allowed in statically deterministic control flow.' ) raise BreakException () continue_stmt () \u00b6 Continue staging tool. Only allow continue in static control flow. Source code in python/freetensor/core/staging.py 316 317 318 319 320 321 322 def continue_stmt ( self ): '''Continue staging tool. Only allow continue in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Continue is only allowed in statically deterministic control flow.' ) raise ContinueException () custom_attr ( obj , attr ) \u00b6 Customized attribute accessor. The framework first looks for a Python native attribute. If not found, it looks for this overloaded custom attribute resolver. The default implementation provides no custom attribute. Can be overridden by subclasses. Parameters: Name Type Description Default obj Any Object to access attribute. required attr str Attribute name. required Returns: Name Type Description Any Any The attribute value. Throws \u00b6 AttributeError : If the attribute is not found. Source code in python/freetensor/core/staging.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def custom_attr ( self , obj : Any , attr : str ) -> Any : ''' Customized attribute accessor. The framework first looks for a Python native attribute. If not found, it looks for this overloaded custom attribute resolver. The default implementation provides no custom attribute. Can be overridden by subclasses. Parameters ---------- obj : Any Object to access attribute. attr : str Attribute name. Returns ------- Any : The attribute value. Throws ------ AttributeError : If the attribute is not found. ''' return None foreach ( names , iter , body ) \u00b6 Customized foreach wrapper. If value is instance of StagedIterable , its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. Source code in python/freetensor/core/staging.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def foreach ( self , names , iter , body : Callable [[ Any ], None ]) -> None : '''Customized foreach wrapper. If `value` is instance of `StagedIterable`, its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. ''' if isinstance ( iter , StagedIterable ): iter . foreach ( names , body ) else : for iter_var in iter : try : body ( iter_var ) except BreakException : break except ContinueException : continue functiondef_wrapper ( filename , func ) \u00b6 Function definition wrapper. This wrapper performs extra initialization and cleanup for function definition. Source code in python/freetensor/core/staging.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def functiondef_wrapper ( self , filename , func ): '''Function definition wrapper. This wrapper performs extra initialization and cleanup for function definition. ''' def wrapped ( * args , ** kwargs ): # Push debug call stack with some random line number. # It will be updated by `mark_position` calls in the function. self . debug_call_stack . append ( traceback . FrameSummary ( filename , 1 , func . __name__ )) # The called function can now return from itself, despite what the outer # control flow is. with self . allow_shortcut_scope ( True ): try : func ( * args , ** kwargs ) except ReturnException as e : result = e . value else : # No return_stmt was called, naturally returns None result = None # Pop debug call stack. self . debug_call_stack . pop () return result return wrapped if_then_else_expr ( predicate , then_expr , else_expr ) \u00b6 If-then-else expression staging tool. Source code in python/freetensor/core/staging.py 257 258 259 260 261 262 263 264 265 def if_then_else_expr ( self , predicate , then_expr , else_expr ): '''If-then-else expression staging tool.''' if isinstance ( predicate , StagedPredicate ): return predicate . if_then_else_expr ( then_expr , else_expr ) else : if predicate : return then_expr () else : return else_expr () if_then_else_stmt ( predicate , then_body , else_body = None ) \u00b6 If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. Source code in python/freetensor/core/staging.py 244 245 246 247 248 249 250 251 252 253 254 255 def if_then_else_stmt ( self , predicate , then_body , else_body = None ): '''If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. ''' if isinstance ( predicate , StagedPredicate ): predicate . if_then_else_stmt ( then_body , else_body ) else : if predicate : then_body () elif else_body : else_body () load_attr ( obj , attr ) \u00b6 Load attribute staging tool. Allows customization of reading attributes. Source code in python/freetensor/core/staging.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 def load_attr ( self , obj , attr : str ): '''Load attribute staging tool. Allows customization of reading attributes.''' try : return getattr ( obj , attr ) except AttributeError : try : # Have to use AttributeError again, since a custom attribute might have # a None value result = self . custom_attr ( obj , attr ) successful = True except AttributeError : successful = False if successful : return result else : raise metadata ( content ) \u00b6 Metadata handler. A metadata line is a comment starting with #! and followed by a metadata, represented as a string parameter. Defaults to a no-op. Can be overridden by subclasses. Parameters: Name Type Description Default content str The metadata content. required Source code in python/freetensor/core/staging.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def metadata ( self , content ) -> None : ''' Metadata handler. A metadata line is a comment starting with `#! ` and followed by a metadata, represented as a string parameter. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- content : str The metadata content. ''' pass return_stmt ( value , funcname ) \u00b6 Return staging tool. Only allow return in static control flow. Source code in python/freetensor/core/staging.py 295 296 297 298 299 300 301 302 303 304 305 306 def return_stmt ( self , value , funcname ): '''Return staging tool. Only allow return in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Return is only allowed in statically deterministic control flow.' ) if isinstance ( value , StagedUnpackAssignable ): # We don't know how many items are there, so no unpacking value = value . assign ( funcname ) if isinstance ( value , StagedAssignable ): value = value . assign ( funcname ) raise ReturnException ( value ) unpack_assign_stmt ( names , values ) \u00b6 Customized assign wrapper for one or more targets. If values is instance of StagedUnpackAssignable , it's regarded as a customized assign behavior and gets executed with all the assigned targets' names. Otherwise, it calls assign_stmt with each sub-assignments. Please note that names can be nested tuples like (\"a\", (\"b\", \"c\")) . Please also note that names can also be a single string like \"a\" even if values is a tuple. There is no unpacking in this case Source code in python/freetensor/core/staging.py 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 def unpack_assign_stmt ( self , names , values ): '''Customized assign wrapper for one or more targets. If `values` is instance of `StagedUnpackAssignable`, it's regarded as a customized assign behavior and gets executed with all the assigned targets' names. Otherwise, it calls `assign_stmt` with each sub-assignments. Please note that `names` can be nested tuples like `(\"a\", (\"b\", \"c\"))`. Please also note that `names` can also be a single string like \"a\" even if `values` is a tuple. There is no unpacking in this case ''' if isinstance ( values , StagedUnpackAssignable ): return values . assign ( names ) elif isinstance ( names , str ): return self . assign_stmt ( names , values ) else : assert isinstance ( names , Sequence ) values = tuple ( values ) if len ( names ) != len ( values ): raise self . error ( \"Number of return values does not match when unpacking\" ) returns = [] for name , value in zip ( names , values ): returns . append ( self . unpack_assign_stmt ( name , value )) return tuple ( returns ) while_stmt ( fpred , body ) \u00b6 While statement staging tool. Source code in python/freetensor/core/staging.py 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 def while_stmt ( self , fpred , body ): '''While statement staging tool.''' first_pred = fpred () if isinstance ( first_pred , StagedPredicate ): first_pred . while_stmt ( body ) else : if first_pred : try : body () except BreakException : return except ContinueException : pass while fpred (): try : body () except BreakException : break except ContinueException : continue TransformError \u00b6 Bases: Exception Error occurred during AST transforming from python function to staging function that generates IR tree. Source code in python/freetensor/core/staging.py 23 24 25 26 27 28 29 30 class TransformError ( Exception ): '''Error occurred during AST transforming from python function to staging function that generates IR tree.''' def __init__ ( self , message : str , filename : str , base_lineno : int , error_node : ast . AST ) -> None : super () . __init__ ( f 'At { filename } : { base_lineno + error_node . lineno } : \\n { message } .' ) Transformer dataclass \u00b6 Bases: ast . NodeTransformer Source code in python/freetensor/core/staging.py 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 @dataclass class Transformer ( ast . NodeTransformer ): filename : str base_lineno : int curr_func : str = None nonlocals : List [ List [ str ]] = None def visit ( self , node : ast . AST ): new_node = super () . visit ( node ) if isinstance ( node , ast . stmt ) and not isinstance ( node , ast . FunctionDef ): if not isinstance ( new_node , list ): new_node = [ new_node ] return [ ast . Expr ( call_helper ( StagingOverload . mark_position , ast . Constant ( self . base_lineno + node . lineno - 1 ))) ] + new_node return new_node def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = unpack_assign_stmt('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = unpack_assign_stmt('lhs', rhs)` `a, (b, c) = (x, (y, z))` -> `a, (b, c) = unpack_assign_stmt(('a', ('b', 'c')), (x, (y, z)))` `a = b = c` -> `a = unpack_assign_stmt('a', c); b = unpack_assign_stmt('b', c)` If `unpack_assign_stmt` is not overloaded, `assign_stmt` will be called for each item ''' node : ast . Assign = self . generic_visit ( old_node ) class UnoverloadableExcept ( BaseException ): pass def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) elif isinstance ( target , ast . Attribute ): return ast . Constant ( target . attr ) elif isinstance ( target , ast . Tuple ): # Unpacking: (a, b) = c l = [] for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) else : raise UnoverloadableExcept () def do_visit_assign ( targets ): try : names = recursive_get_names ( targets ) return ast . Assign ([ targets ], call_helper ( StagingOverload . unpack_assign_stmt , names , node . value )) except UnoverloadableExcept : return ast . Assign ([ targets ], node . value ) # If there are more than one item in `node.targets`, it means multiple # assignments like `a = b = c`. For unpacking like `(a, b) = c`, it # is represented as one tuple as a target item new_nodes = [] for target in node . targets : new_nodes . append ( do_visit_assign ( target )) return new_nodes def handleType_AnnAssign ( self , node : ast . AnnAssign ) -> Any : x = node . target assert isinstance ( x , ast . Name ) assert node . value is None x_str = ast . Constant ( x . id ) Ty = node . annotation intermediate = f 'freetensor__annotate__ { x . id } ' intermediate_store = ast . Name ( intermediate , ast . Store ()) intermediate_load = ast . Name ( intermediate , ast . Load ()) node = [ ast . Assign ([ intermediate_store ], call_helper ( StagingOverload . annotate_stmt , x_str , Ty )), ast . If ( intermediate_load , [ ast . Assign ([ x ], intermediate_load )], []) ] return node def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # While opening a fake function, For loops initiates an iter name as # well. Need to remove it from the outer nonlocals list to implement # shadowing. Only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) def recursive_remove_id ( target ): if isinstance ( target , ast . Name ): if target . id in nonlocals : nonlocals . remove ( target . id ) else : assert isinstance ( target , ast . Tuple ) for t in target . elts : recursive_remove_id ( t ) recursive_remove_id ( old_node . target ) nonlocals = list ( nonlocals ) def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) else : l = [] assert isinstance ( target , ast . Tuple ) for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) target_names = recursive_get_names ( old_node . target ) node : ast . For = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ '__item__' ], [ ast . Assign ([ node . target ], ast . Name ( '__item__' , ast . Load ())) ] + node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . foreach , target_names , node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return node def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . while_stmt , ast . Lambda ( _EMPTY_ARGS , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return node def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( StagingOverload . if_then_else_stmt , test , then_body , else_body ))) return new_node def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( StagingOverload . if_then_else_expr , node . test , ast . Lambda ( _EMPTY_ARGS , node . body ), ast . Lambda ( _EMPTY_ARGS , node . orelse )) return node def visit_FunctionDef ( self , old_node : ast . FunctionDef ) -> Any : prev_func = self . curr_func self . curr_func = old_node . name # nested functions follow original Python (shitty) scoping, # thus backup the nonlocals stack and prepare a clean one. prev_nonlocals = self . nonlocals self . nonlocals = None with NonlocalTransformingScope ( self ): # mark arguments as nonlocal for name in old_node . args . args + old_node . args . kwonlyargs : self . nonlocals [ - 1 ] . append ( name . arg ) if old_node . args . vararg : self . nonlocals [ - 1 ] . append ( old_node . args . vararg . arg ) if old_node . args . kwarg : self . nonlocals [ - 1 ] . append ( old_node . args . kwarg . arg ) # Transform the function body node : ast . FunctionDef = self . generic_visit ( old_node ) # Cleanup the decorators node . decorator_list = [ call_helper ( StagingOverload . functiondef_decorator , ast . Constant ( self . filename )) ] annotations_dict_name = f '__staging_annotations__ { node . name } __' # Handle the type annotations node . body = [ stmt for arg in node . args . posonlyargs + node . args . args if arg . annotation for stmt in self . handleType_AnnAssign ( ast . AnnAssign ( ast . Name ( arg . arg , ast . Store ()), ast . Subscript ( ast . Name ( annotations_dict_name , ast . Load ()), ast . Constant ( arg . arg ), ast . Load ()), None , 1 )) ] + node . body annotations_dict = {} # Cleanup annotations; we don't need them any more for arg in [ node . args . vararg , node . args . kwarg ] + node . args . posonlyargs + node . args . args + node . args . kwonlyargs : if arg is not None and arg . annotation is not None : annotations_dict [ arg . arg ] = arg . annotation arg . annotation = None # Write the annotations_dict node = [ ast . Assign ( [ ast . Name ( annotations_dict_name , ast . Store ())], ast . Dict ([ ast . Constant ( k ) for k in annotations_dict . keys ()], list ( annotations_dict . values ()))), node ] self . curr_func = prev_func self . nonlocals = prev_nonlocals return node def visit_Assert ( self , old_node : ast . Assert ) -> Any : node : ast . Assert = self . generic_visit ( old_node ) node = ast . Expr ( call_helper ( StagingOverload . assert_stmt , node . test )) return node def visit_BoolOp ( self , old_node : ast . BoolOp ) -> Any : node : ast . BoolOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . And ): libfunc = StagingOverload . and_expr elif isinstance ( node . op , ast . Or ): libfunc = StagingOverload . or_expr else : return node node = call_helper ( libfunc , * [ ast . Lambda ( _EMPTY_ARGS , v ) for v in node . values ]) return node def visit_UnaryOp ( self , old_node : ast . UnaryOp ) -> Any : node : ast . UnaryOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . Not ): node = call_helper ( StagingOverload . not_expr , node . operand ) return node def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( node ) def visit_Attribute ( self , old_node : ast . Attribute ) -> Any : node : ast . Attribute = self . generic_visit ( old_node ) if isinstance ( node . ctx , ast . Load ): if not ( isinstance ( node . value , ast . Name ) and node . value . id == '__staging_overload__' ): node = call_helper ( StagingOverload . load_attr , node . value , ast . Constant ( node . attr )) return node def visit_Return ( self , old_node : ast . Return ) -> Any : node : ast . Return = self . generic_visit ( old_node ) assert self . curr_func is not None node = ast . Expr ( call_helper ( StagingOverload . return_stmt , node . value , ast . Constant ( self . curr_func ))) return node def visit_Lambda ( self , old_node : ast . Lambda ) -> Any : with NonlocalTransformingScope ( self ): node : ast . Lambda = self . generic_visit ( old_node ) return node def visit_comprehension ( self , old_node : ast . comprehension ) -> Any : with NonlocalTransformingScope ( self ): node : ast . comprehension = self . generic_visit ( old_node ) return node def visit_Name ( self , node : ast . Name ) -> Any : if isinstance ( node . ctx , ast . Store ): self . nonlocals [ - 1 ] . append ( node . id ) return self . generic_visit ( node ) def visit_AsyncFunctionDef ( self , node : ast . AsyncFunctionDef ) -> Any : raise TransformError ( 'Async functions not supported.' , self . filename , self . base_lineno , node ) def visit_ClassDef ( self , node : ast . ClassDef ) -> Any : raise TransformError ( 'Class definitions not supported.' , self . filename , self . base_lineno , node ) def visit_Yield ( self , node : ast . Yield ) -> Any : raise NotImplementedError () def visit_YieldFrom ( self , node : ast . YieldFrom ) -> Any : raise NotImplementedError () def visit_Break ( self , node : ast . Break ) -> Any : return ast . Expr ( call_helper ( StagingOverload . break_stmt )) def visit_Continue ( self , node : ast . Continue ) -> Any : return ast . Expr ( call_helper ( StagingOverload . continue_stmt )) def visit_With ( self , node : ast . With ) -> Any : def recursive_get_names ( target ): if isinstance ( target , ast . Name ): self . nonlocals [ - 1 ] . append ( target . id ) elif isinstance ( target , ast . Tuple ) or isinstance ( target , ast . List ): for t in target . elts : recursive_get_names ( t ) else : assert False for item in node . items : if item . optional_vars is not None : recursive_get_names ( item . optional_vars ) return self . generic_visit ( node ) visit_AnnAssign ( old_node ) \u00b6 Rule: x: Ty -> freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x : pure annotation Source code in python/freetensor/core/staging.py 803 804 805 806 807 808 809 810 811 812 813 814 def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node visit_Assign ( old_node ) \u00b6 Rule: lhs = rhs -> lhs = unpack_assign_stmt('lhs', rhs) x.lhs = rhs -> x.lhs = unpack_assign_stmt('lhs', rhs) a, (b, c) = (x, (y, z)) -> a, (b, c) = unpack_assign_stmt(('a', ('b', 'c')), (x, (y, z))) a = b = c -> a = unpack_assign_stmt('a', c); b = unpack_assign_stmt('b', c) If unpack_assign_stmt is not overloaded, assign_stmt will be called for each item Source code in python/freetensor/core/staging.py 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = unpack_assign_stmt('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = unpack_assign_stmt('lhs', rhs)` `a, (b, c) = (x, (y, z))` -> `a, (b, c) = unpack_assign_stmt(('a', ('b', 'c')), (x, (y, z)))` `a = b = c` -> `a = unpack_assign_stmt('a', c); b = unpack_assign_stmt('b', c)` If `unpack_assign_stmt` is not overloaded, `assign_stmt` will be called for each item ''' node : ast . Assign = self . generic_visit ( old_node ) class UnoverloadableExcept ( BaseException ): pass def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) elif isinstance ( target , ast . Attribute ): return ast . Constant ( target . attr ) elif isinstance ( target , ast . Tuple ): # Unpacking: (a, b) = c l = [] for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) else : raise UnoverloadableExcept () def do_visit_assign ( targets ): try : names = recursive_get_names ( targets ) return ast . Assign ([ targets ], call_helper ( StagingOverload . unpack_assign_stmt , names , node . value )) except UnoverloadableExcept : return ast . Assign ([ targets ], node . value ) # If there are more than one item in `node.targets`, it means multiple # assignments like `a = b = c`. For unpacking like `(a, b) = c`, it # is represented as one tuple as a target item new_nodes = [] for target in node . targets : new_nodes . append ( do_visit_assign ( target )) return new_nodes visit_Compare ( old_node ) \u00b6 Expand multiple comparison into and expression. Source code in python/freetensor/core/staging.py 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( node ) visit_For ( old_node ) \u00b6 Rule: for x in iter: body -> def for_body(x): body foreach('x', iter, for_body) Source code in python/freetensor/core/staging.py 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # While opening a fake function, For loops initiates an iter name as # well. Need to remove it from the outer nonlocals list to implement # shadowing. Only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) def recursive_remove_id ( target ): if isinstance ( target , ast . Name ): if target . id in nonlocals : nonlocals . remove ( target . id ) else : assert isinstance ( target , ast . Tuple ) for t in target . elts : recursive_remove_id ( t ) recursive_remove_id ( old_node . target ) nonlocals = list ( nonlocals ) def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) else : l = [] assert isinstance ( target , ast . Tuple ) for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) target_names = recursive_get_names ( old_node . target ) node : ast . For = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ '__item__' ], [ ast . Assign ([ node . target ], ast . Name ( '__item__' , ast . Load ())) ] + node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . foreach , target_names , node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return node visit_If ( old_node ) \u00b6 Rule: if pred: body else: orelse -> def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) Source code in python/freetensor/core/staging.py 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( StagingOverload . if_then_else_stmt , test , then_body , else_body ))) return new_node visit_IfExp ( old_node ) \u00b6 Rule: body if test else orelse -> if_then_else_expr(test, body, orelse) Source code in python/freetensor/core/staging.py 939 940 941 942 943 944 945 def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( StagingOverload . if_then_else_expr , node . test , ast . Lambda ( _EMPTY_ARGS , node . body ), ast . Lambda ( _EMPTY_ARGS , node . orelse )) return node visit_While ( old_node ) \u00b6 Rule: while pred: body -> def while_body(): body while_stmt(lambda: pred, while_body) Source code in python/freetensor/core/staging.py 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . while_stmt , ast . Lambda ( _EMPTY_ARGS , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return node call_helper ( callee , * args , ** kwargs ) \u00b6 Call helper that generates a python AST Call node with given callee (overload member) and arguments AST node. Source code in python/freetensor/core/staging.py 665 666 667 668 669 670 671 def call_helper ( callee , * args : ast . expr , ** kwargs : ast . expr ): '''Call helper that generates a python AST Call node with given callee (overload member) and arguments AST node.''' return ast . Call ( ast . Attribute ( ast . Name ( '__staging_overload__' , ast . Load ()), callee . __name__ , ast . Load ()), list ( args ), [ ast . keyword ( k , w ) for k , w in kwargs . items ()]) function_helper ( name , args , body , nonlocals ) \u00b6 Function helper that generates a python AST FunctionDef node with given name, arguments name, and body. Source code in python/freetensor/core/staging.py 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 def function_helper ( name : str , args : Sequence [ str ], body : List [ ast . stmt ], nonlocals : List [ str ]): '''Function helper that generates a python AST FunctionDef node with given name, arguments name, and body.''' nonlocal_body = ([ ast . Nonlocal ( nonlocals )] if len ( nonlocals ) > 0 else []) + body return ast . FunctionDef ( name = name , args = ast . arguments ( args = [], vararg = None , kwarg = None , posonlyargs = [ ast . arg ( a , None ) for a in args ], defaults = [], kwonlyargs = [], kw_defaults = []), body = nonlocal_body , returns = None , decorator_list = []) stmt \u00b6 Facility to build AST statements Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module. Classes and functions in this module are all in BigCamel naming style, to distinguish from expressions in expr.py Assert \u00b6 Scope used to create an Assert node This scope is internally used by transformer and tests E.g.: with Assert(i > 0): ... # Assertion body Source code in python/freetensor/core/stmt.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 class Assert : ''' Scope used to create an Assert node This scope is internally used by `transformer` and tests E.g.: ``` with Assert(i > 0): ... # Assertion body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () top . append_stmt ( ffi . makeAssert ( self . cond , body , top . get_metadata ())) Else \u00b6 Scope used to create an else branch of an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # True branch with Else(): ... # Else branch Source code in python/freetensor/core/stmt.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 class Else : ''' Scope used to create an else branch of an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # True branch with Else(): ... # Else branch ``` ''' def __init__ ( self ): pass def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_else_stmt ( body ) For \u00b6 Scope used to create a For node This scope is internally used by transformer and tests E.g.: with For('i', 0, n) as i: ... # Loop body Source code in python/freetensor/core/stmt.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 class For : ''' Scope used to create a For node This scope is internally used by `transformer` and tests E.g.: ``` with For('i', 0, n) as i: ... # Loop body ``` ''' def __init__ ( self , iter_var : str , begin , end , step = 1 , label : Optional [ str ] = None , no_deps : Optional [ Sequence [ str ]] = None , prefer_libs : Optional [ bool ] = None ): self . iter_var = iter_var self . begin = begin self . end = end self . step = step self . label = label self . no_deps = no_deps self . prefer_libs = prefer_libs self . borrowed_vardefs = set () for x in [ begin , end , step ]: for name in ffi . all_reads ( ffi . Expr ( x )): self . borrowed_vardefs . add ( open_vardefs [ name ]) def __enter__ ( self ): for item in self . borrowed_vardefs : item . lend_out () ctx_stack . push () return ffi . makeVar ( self . iter_var ) def __exit__ ( self , exc_type , exc_value , traceback ): for item in self . borrowed_vardefs : item . reclaim () if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () top . append_for_stmt ( self . iter_var , self . begin , self . end , self . step , body , metadata = ffi . SourceMetadata ([ self . label ]) if self . label is not None else None , no_deps = self . no_deps , prefer_libs = self . prefer_libs ) If \u00b6 Scope used to create an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # Branch body Source code in python/freetensor/core/stmt.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 class If : ''' Scope used to create an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # Branch body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_then_stmt ( self . cond , body ) Invoke \u00b6 Inlined invocation of another AST Invoke is used as a scope ( with Invoke(...) as returned_vars ), so that variables returned by the callee can be used in the socpe Invoke can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use inline in transformer instead, which supports generic types Source code in python/freetensor/core/stmt.py 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 class Invoke : ''' Inlined invocation of another AST `Invoke` is used as a scope (`with Invoke(...) as returned_vars`), so that variables returned by the callee can be used in the socpe `Invoke` can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use `inline` in `transformer` instead, which supports generic types ''' def __init__ ( self , ret_names : Sequence [ str ], func : ffi . Func , args : Sequence = [], kvs : Mapping = {}): self . args = args self . kvs = kvs self . func , returns = ffi . strip_returns ( func ) self . vardefs = [] # Outer to inner assert len ( ret_names ) == len ( returns ) for name , ret in zip ( ret_names , returns ): self . vardefs . append ( _VarDef ( name , ret . tensor . shape , ret . tensor . dtype , \"cache\" , ret . mtype )) def __enter__ ( self ): varrefs = [] ret_names = [] for vardef in self . vardefs : varref = vardef . __enter__ () varrefs . append ( varref ) ret_names . append ( varref . name ) ctx_stack . top () . append_stmt ( ffi . inlined_invoke ( ctx_stack . top () . get_metadata (), self . func , self . args , self . kvs , ret_names )) return varrefs [ 0 ] if len ( varrefs ) == 1 else tuple ( varrefs ) def __exit__ ( self , exc_type , exc_value , traceback ): for vardef in reversed ( self . vardefs ): vardef . __exit__ ( exc_type , exc_value , traceback ) NamedScope \u00b6 Scope used to create an StmtSeq node with an explicit labels E.g.: with NamedScope(): ... # body This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes Source code in python/freetensor/core/stmt.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 class NamedScope : ''' Scope used to create an StmtSeq node with an explicit labels E.g.: ``` with NamedScope(): ... # body ``` This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes ''' def __init__ ( self , * labels : str ): self . labels = labels def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception finished_scope = ctx_stack . pop () metadata = ctx_stack . top () . get_metadata ( self . labels ) body = finished_scope . make_stmt ( metadata ) ctx_stack . top () . append_stmt ( body ) UserGradStaged \u00b6 Internal staged implementation of UserGrad Source code in python/freetensor/core/stmt.py 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 class UserGradStaged : ''' Internal staged implementation of `UserGrad` ''' def __init__ ( self , * args : Sequence [ VarRef ], ** kvs ): self . ori_vars = args self . body = None self . grad_defs = [] if 'stmt_range' in kvs : stmt_range = kvs [ 'stmt_range' ] if isinstance ( stmt_range , StmtRange ): self . ori_stmts = stmt_range . make () else : raise TypeError ( \"`stmt_range` should be a `StmtRange` for `UserGrad`\" ) del kvs [ 'stmt_range' ] else : self . ori_stmts = { ctx_stack . get_last_stmt_id ()} for key in kvs : raise TypeError ( f \"Unrecognized parameter ` { key } ` of `UserGrad`\" ) def __enter__ ( self ): # Make `VarDef` scopes for the gradients grad_vars = [] for ori_var in self . ori_vars : grad_def = VarDef ( ori_var . name + \".grad\" , ori_var . full_shape , ori_var . dtype , \"cache\" , ori_var . mtype ) grad_vars . append ( grad_def . __enter__ ()) self . grad_defs . append ( grad_def ) # Make a context, which is used for popping out the body we need ctx_stack . push () return grad_vars def __exit__ ( self , exc_type , exc_value , traceback ): # Pop out the body we need self . body = ctx_stack . pop () . make_stmt () # Although we are discarding the gradient `VarDef` scopes, we still need to close # them, to restore ctx_stack. After that, we pop out the `VarDef` statement for grad_def in reversed ( self . grad_defs ): grad_def . __exit__ ( exc_type , exc_value , traceback ) if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception ctx_stack . top () . stmt_seq . pop () # Record the body to context ctx_stack . user_grads . append ( ffi . StmtSetToUserGrad ( self . ori_stmts , self . body )) Any () \u00b6 Create an Any node (only for testing) Any nodes matches any statement nodes in ast.match Source code in python/freetensor/core/stmt.py 412 413 414 415 416 417 418 def Any (): ''' Create an Any node (only for testing) Any nodes matches any statement nodes in `ast.match` ''' ctx_stack . top () . append_stmt ( ffi . makeAny ()) Eval ( expr ) \u00b6 Create an Eval node This scope is internally used by transformer and tests Source code in python/freetensor/core/stmt.py 402 403 404 405 406 407 408 409 def Eval ( expr ): ''' Create an Eval node This scope is internally used by `transformer` and tests ''' top = ctx_stack . top () top . append_stmt ( ffi . makeEval ( expr , top . get_metadata ())) MarkLabel ( label ) \u00b6 Mark the ID of the following statement This scope is internally used by transformer and tests Source code in python/freetensor/core/stmt.py 308 309 310 311 312 313 314 def MarkLabel ( label : str ): \"\"\" Mark the ID of the following statement This scope is internally used by `transformer` and tests \"\"\" ctx_stack . top () . add_label ( label ) MarkVersion ( tape_name , var ) \u00b6 Create an MarkVersion node (only for custom gradient) This node is only used for custom gradient. See UserGrad . Source code in python/freetensor/core/stmt.py 421 422 423 424 425 426 427 428 429 def MarkVersion ( tape_name : str , var : VarRef ): ''' Create an MarkVersion node (only for custom gradient) This node is only used for custom gradient. See `UserGrad`. ''' top = ctx_stack . top () top . append_stmt ( ffi . makeMarkVersion ( tape_name , var . name , top . get_metadata ())) VarDef ( * args , ** kvs ) \u00b6 A factory function that creates a VarDef or a series of nested VarDef s This scope is internally used by transformer and tests Source code in python/freetensor/core/stmt.py 148 149 150 151 152 153 154 155 156 157 158 def VarDef ( * args , ** kvs ): ''' A factory function that creates a VarDef or a series of nested `VarDef`s This scope is internally used by `transformer` and tests ''' if len ( args ) == 1 : return _VarsDef ( args [ 0 ]) else : return _VarDef ( * args , ** kvs ) libop \u00b6 constant \u00b6 zeros ( shape , dtype , mtype = None ) \u00b6 Create a zero tensor Parameters: Name Type Description Default shape Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape required dtype str or DataType Data type of the variable required mtype str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used None Returns: Name Type Description VarRef The zero tensor Source code in python/freetensor/libop/constant.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @core . inline def zeros ( shape , dtype , mtype = None ): ''' Create a zero tensor Parameters ---------- shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Returns ------- VarRef : The zero tensor ''' y = core . empty ( shape , dtype , mtype ) #! label: recur zeros_ ( y ) return y zeros_ ( y ) \u00b6 Fill zeros to a tensor Parameters: Name Type Description Default y VarRef The tensor to fill required Source code in python/freetensor/libop/constant.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @core . inline def zeros_ ( y ): ''' Fill zeros to a tensor Parameters ---------- y : VarRef The tensor to fill ''' if core . ndim ( y ) == 0 : y [()] = core . zero_value ( y . dtype ) else : #! label: L_elem for i in range ( core . shape ( y , 0 )): #! label: recur zeros_ ( y [ i ]) element_wise \u00b6 binary_op ( op , a , b ) \u00b6 (Broadcasted) any element-wise operation on two tensors and return the result Parameters: Name Type Description Default op Callable The operation applied to each item required a VarRef Left-hand-side operand required b VarRef Right-hand-side operand required Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/element_wise.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @core . inline def binary_op ( op , a , b ): ''' (Broadcasted) any element-wise operation on two tensors and return the result Parameters ---------- op : Callable The operation applied to each item a : VarRef Left-hand-side operand b : VarRef Right-hand-side operand Returns ------- VarRef The result tensor ''' #! label: out # NOTE: We only inference base data type, to avoid confusion in case the result # tensor is further assigned by users with other sign data types out = core . empty ( broadcast_shape ( a , b ), core . dtype ( op ( core . cast ( core . any (), core . dtype ( a )), core . cast ( core . any (), core . dtype ( b )))) . base , core . same_mtype ( core . mtype ( a ), core . mtype ( b ))) #! label: recur binary_op_ ( op , a , b , out ) return out binary_op_ ( op , a , b , out ) \u00b6 (Broadcasted) any element-wise operation on two tensors. The result is written to another tensor Parameters: Name Type Description Default op Callable The operation applied to each item required a VarRef Left-hand-side operand required b VarRef Right-hand-side operand required out VarRef The result tensor required Source code in python/freetensor/libop/element_wise.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @core . inline def binary_op_ ( op , a , b , out ): ''' (Broadcasted) any element-wise operation on two tensors. The result is written to another tensor Parameters ---------- op : Callable The operation applied to each item a : VarRef Left-hand-side operand b : VarRef Right-hand-side operand out : VarRef The result tensor ''' if core . ndim ( out ) == 0 : out [()] = op ( a , b ) else : #! label: L_elem for i in range ( out . shape ( 0 )): if core . ndim ( a ) < core . ndim ( out ): assert b . shape ( 0 ) == out . shape ( 0 ) #! label: recur binary_op_ ( op , a , b [ i ], out [ i ]) elif core . ndim ( b ) < core . ndim ( out ): assert a . shape ( 0 ) == out . shape ( 0 ) #! label: recur binary_op_ ( op , a [ i ], b , out [ i ]) else : assert a . shape ( 0 ) == out . shape ( 0 ) or a . shape ( 0 ) == 1 assert b . shape ( 0 ) == out . shape ( 0 ) or b . shape ( 0 ) == 1 #! label: recur binary_op_ ( op , a [ i % a . shape ( 0 )], b [ i % b . shape ( 0 )], out [ i ]) unary_op ( op , x ) \u00b6 Any element-wise operation on a tensor and return the result Parameters: Name Type Description Default op Callable The operation applied to each item required x VarRef The input tensor required Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/element_wise.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 @core . inline def unary_op ( op , x ): ''' Any element-wise operation on a tensor and return the result Parameters ---------- op : Callable The operation applied to each item x : VarRef The input tensor Returns ------- VarRef The result tensor ''' #! label: y # NOTE: We only inference base data type, to avoid confusion in case the result # tensor is further assigned by users with other sign data types y = core . empty ( copy_shape ( x ), core . dtype ( op ( core . cast ( core . any (), core . dtype ( x )))) . base , core . mtype ( x )) #! label: recur unary_op_ ( op , x , y ) return y unary_op_ ( op , x , y ) \u00b6 Any element-wise operation on a tensor. The result is written to another tensor Parameters: Name Type Description Default op Callable The operation applied to each item required x VarRef The input tensor required out VarRef The result tensor required Source code in python/freetensor/libop/element_wise.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 @core . inline def unary_op_ ( op , x , y ): ''' Any element-wise operation on a tensor. The result is written to another tensor Parameters ---------- op : Callable The operation applied to each item x : VarRef The input tensor out : VarRef The result tensor ''' if core . ndim ( x ) == 0 : y [()] = op ( x ) else : assert x . shape ( 0 ) == y . shape ( 0 ) #! label: L_elem for i in range ( x . shape ( 0 )): #! label: recur unary_op_ ( op , x [ i ], y [ i ]) pooling \u00b6 global_avg_pool ( X ) \u00b6 Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 @core . inline def global_avg_pool ( X ): ''' Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 )], X . dtype , X . mtype ) #! label: recur global_avg_pool_ ( X , Y ) return Y global_avg_pool_ ( X , Y ) \u00b6 Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @core . inline def global_avg_pool_ ( X , Y ): ''' Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) #! label: L_n for n in range ( X . shape ( 0 )): #! label: L_c for c in range ( X . shape ( 1 )): #! label: init Y [ n , c ] = 0 #! label: L_h for h in range ( X . shape ( 2 )): #! label: L_w for w in range ( X . shape ( 3 )): #! label: compute Y [ n , c ] += X [ n , c , h , w ] #! label: flush Y [ n , c ] /= X . shape ( 2 ) * X . shape ( 3 ) max_pool ( X , auto_pad = 'NOTSET' , dilations = None , kernel_shape = None , pads = None , strides = None ) \u00b6 Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @core . inline def max_pool ( X , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 ), calc_out_size ( X . shape ( 2 ), dilations [ 0 ], kernel_shape [ 0 ], pads [ 0 ], pads [ 2 ], strides [ 0 ]), calc_out_size ( X . shape ( 3 ), dilations [ 1 ], kernel_shape [ 1 ], pads [ 1 ], pads [ 3 ], strides [ 1 ]) ], X . dtype , X . mtype ) #! label: recur max_pool_ ( X , Y , auto_pad , dilations , kernel_shape , pads , strides ) return Y max_pool_ ( X , Y , auto_pad = 'NOTSET' , dilations = None , kernel_shape = None , pads = None , strides = None ) \u00b6 Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @core . inline def max_pool_ ( X , Y , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" # yapf: disable #! label: L_n for n in range ( X . shape ( 0 )): #! label: L_c for c in range ( X . shape ( 1 )): #! label: L_h for h in range ( Y . shape ( 2 )): #! label: L_w for w in range ( Y . shape ( 3 )): #! label: init Y [ n , c , h , w ] = core . min_value ( X . dtype ) #! label: L_kh for kh in range ( kernel_shape [ 0 ]): #! label: L_kw for kw in range ( kernel_shape [ 1 ]): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! label: compute Y [ n , c , h , w ] = core . max ( Y [ n , c , h , w ], X [ n , c , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ]]) reduction \u00b6 reduce_max ( x , axes , keepdims = True ) \u00b6 Maximum of a tensor through one or more dimensions and return the result Parameters: Name Type Description Default x VarRef The input tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/reduction.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 @core . inline def reduce_max ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! label: impl y = _general_reduce ( core . max , core . min_value ( core . dtype ( x )), x , axes , keepdims ) return y reduce_max_ ( x , y , axes , keepdims = True ) \u00b6 Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters: Name Type Description Default x VarRef The input tensor required y VarRef The result tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Source code in python/freetensor/libop/reduction.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @core . inline def reduce_max_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! label: impl _general_reduce_ ( core . max , core . min_value ( core . dtype ( x )), x , y , axes , keepdims ) reduce_min ( x , axes , keepdims = True ) \u00b6 Minimum of a tensor through one or more dimensions and return the result Parameters: Name Type Description Default x VarRef The input tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/reduction.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 @core . inline def reduce_min ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! label: impl y = _general_reduce ( core . min , core . max_value ( core . dtype ( x )), x , axes , keepdims ) return y reduce_min_ ( x , y , axes , keepdims = True ) \u00b6 Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters: Name Type Description Default x VarRef The input tensor required y VarRef The result tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Source code in python/freetensor/libop/reduction.py 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 @core . inline def reduce_min_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! label: impl _general_reduce_ ( core . min , core . max_value ( core . dtype ( x )), x , y , axes , keepdims )","title":"Python API"},{"location":"api/#freetensor.core","text":"","title":"core"},{"location":"api/#freetensor.core.autograd","text":"","title":"autograd"},{"location":"api/#freetensor.core.autograd.ArgRetDict","text":"Look an object using either a function argument or return value's name or its position Source code in python/freetensor/core/autograd.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ArgRetDict : ''' Look an object using either a function argument or return value's name or its position ''' def __init__ ( self , func , d ): self . func = func self . d = d def __getitem__ ( self , key ): if type ( key ) is Return : key = key . get_name ( self . func ) return self . d [ key ] def __contains__ ( self , key ): # Python's auto fallback from __getitem__ to __contains__ only works for # integer index if type ( key ) is Return : key = key . get_name ( self . func ) return key in self . d def __str__ ( self ): return str ( self . d )","title":"ArgRetDict"},{"location":"api/#freetensor.core.autograd.Return","text":"Alias of a return value of a function Return(n) represents the n-th return value (counted from 0) Return() can be used if there is only one return value Source code in python/freetensor/core/autograd.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Return : ''' Alias of a return value of a function `Return(n)` represents the n-th return value (counted from 0) `Return()` can be used if there is only one return value ''' def __init__ ( self , n : Optional [ int ] = None ): self . n = n def get_name ( self , func ): assert len ( func . returns ) > 0 , f \" { func . name } has no return value\" if self . n is not None : return func . returns [ self . n ] . name else : assert len ( func . returns ) == 1 , f \" { func . name } has more than one return value, and you need to specify the number of a return value\" return func . returns [ 0 ] . name def __str__ ( self ): return f \"Return( { self . n } )\"","title":"Return"},{"location":"api/#freetensor.core.autograd.grad","text":"Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad is an out-of-place version. The resulting gradient are returned from the backward function. Parameters: Name Type Description Default func AST The original function required requires Sequence [ str ] Name of input variables that need gradients required provides Sequence [ Union [ str , Return ]] Name of output variables whose gradients are known. A return value of a function can be specified with a Return object required tapes Union [ Sequence , GradTapeMode ] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history GradTapeMode.NoReuseOnly tape_in_closure bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True True invert bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults True user_grads Optional [ Sequence [ ffi . StmtSetToUserGrad ]] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating func by yourself (not getting it from the Python frontend). See UserGrad for details None verbose Optional [ int ] Verbosity level None Returns: Type Description tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in python/freetensor/core/autograd.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def grad ( func : ffi . Func , requires : Sequence [ str ], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , tape_in_closure : bool = True , invert : bool = True , user_grads : Optional [ Sequence [ ffi . StmtSetToUserGrad ]] = None , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad` is an out-of-place version. The resulting gradient are returned from the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history tape_in_closure : bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True invert: bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults user_grads: List[ffi.StmtSetToUserGrad] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating `func` by yourself (not getting it from the Python frontend). See `UserGrad` for details verbose: int Verbosity level Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad , func , requires , provides , tapes , tape_in_closure , invert , user_grads , verbose = verbose )","title":"grad()"},{"location":"api/#freetensor.core.autograd.grad_","text":"Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. grad_ is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters: Name Type Description Default func AST The original function required requires Sequence [ str ] Name of input variables that need gradients required provides Sequence [ Union [ str , Return ]] Name of output variables whose gradients are known. A return value of a function can be specified with a Return object required tapes Union [ Sequence , GradTapeMode ] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history GradTapeMode.NoReuseOnly tape_in_closure bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True True invert bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults to true. True user_grads Optional [ Sequence [ ffi . StmtSetToUserGrad ]] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating func by yourself (not getting it from the Python frontend). See UserGrad for details None verbose Optional [ int ] Verbosity level None Returns: Type Description tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) Source code in python/freetensor/core/autograd.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def grad_ ( func : ffi . Func , requires : Sequence [ str ], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , tape_in_closure : bool = True , invert : bool = True , user_grads : Optional [ Sequence [ ffi . StmtSetToUserGrad ]] = None , verbose : Optional [ int ] = None ): ''' Reverse mode automatic differentiation It returns a forward function and a backward function. The forward has the same interface of the original function, but it will store some intermediate tensors (the tape) to be reused by the backward function in some global states. The backward function computes the gradients. `grad_` is an inplace version. The resulting gradient are mutable arguments of the backward function. Parameters ---------- func : AST The original function requires : Sequence[str] Name of input variables that need gradients provides : Sequence[Union[str, Return]] Name of output variables whose gradients are known. A return value of a function can be specified with a `Return` object tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history tape_in_closure : bool True to pass taped tensors from the forward function to the backward function in implicit I/O parameters, i.e. in closure. False to pass these tensors as explicit I/O parameters. Default to True invert: bool If set to true, it can reduce the amount of recomputation or taping required. However, this may result in a loss of precision for floating-point numbers. Defaults to true. user_grads: List[ffi.StmtSetToUserGrad] For custom gradient. You do not have to explicitly set this parameter unless you are manipulating `func` by yourself (not getting it from the Python frontend). See `UserGrad` for details verbose: int Verbosity level Returns ------- tuple ( 0. Forward AST. 1. Backward AST. 2. Mapping from names in requries to its gradient name. 3. Mapping from names in provides to its gradient name. ) ''' return _grad_func ( ffi . grad_ , func , requires , provides , tapes , tape_in_closure , invert , user_grads , verbose = verbose )","title":"grad_()"},{"location":"api/#freetensor.core.autograd.grad_body","text":"grad or grad_ on a function body (for internal tests only) Source code in python/freetensor/core/autograd.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def grad_body ( stmt : ffi . Stmt , requires : Sequence [ Union [ str , Return ]], provides : Sequence [ Union [ str , Return ]], tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , invert : bool = True , user_grads : Sequence [ ffi . StmtSetToUserGrad ] = []): ''' `grad` or `grad_` on a function body (for internal tests only) ''' req = set ( requires ) prov = set ( provides ) if type ( tapes ) is not GradTapeMode : tapes = { find_stmt ( stmt , t ) . id for t in tapes } return ffi . grad_body ( stmt , req , prov , tapes , invert , user_grads )","title":"grad_body()"},{"location":"api/#freetensor.core.codegen","text":"","title":"codegen"},{"location":"api/#freetensor.core.codegen.codegen","text":"Generate native code Parameters: Name Type Description Default ast AST The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator None target Target ( Optional ) The target architecture. If omitted, use the default one in config None Source code in python/freetensor/core/codegen.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def codegen ( ast = None , target : Optional [ ffi . Target ] = None , verbose : Optional [ bool ] = None ) -> NativeCode : ''' Generate native code Parameters ---------- ast : AST The AST to be lowered. It must includes function signature to determine parameters and return values. If not specified, a partial function is returned, which can be used as a decorator target : Target (Optional) The target architecture. If omitted, use the default one in config ''' if ast is not None : if target is None : target = config . default_target () raw_code = ffi . code_gen ( ast , target ) if verbose : print ( debug . with_line_no ( raw_code ), file = sys . stderr ) return NativeCode ( ast , raw_code , target ) else : f = codegen if target is not None : f = functools . partial ( f , target = target ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f","title":"codegen()"},{"location":"api/#freetensor.core.config","text":"Global configurations","title":"config"},{"location":"api/#freetensor.core.context","text":"Facility to pick statements to build an AST Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module.","title":"context"},{"location":"api/#freetensor.core.context.ContextStack","text":"Source code in python/freetensor/core/context.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class ContextStack : def __init__ ( self ): self . reset () def reset ( self ): self . stack = [ Context ( self )] self . user_grads = [] # [fn(ffi.Stmt)], invoked for every `append_stmt` self . append_stmt_callbacks = [] def top ( self ) -> Context : return self . stack [ - 1 ] def push ( self ): self . stack . append ( Context ( self , self . top () . caller_metadata )) def pop ( self ): return self . stack . pop () def get_stack ( self ) -> List [ Context ]: return self . stack def set_stack ( self , stack : List [ Context ]): self . stack = stack def get_last_stmt_id ( self ): ''' Can be used inside the staged code, to get the ID of the immediately preceding statement ''' for ctx in reversed ( self . stack ): if len ( ctx . stmt_seq ) > 0 : return ctx . stmt_seq [ - 1 ] . id raise ft . InvalidProgram ( \"There is no statement yet\" ) def push_append_stmt_callback ( self , callback : Callable [[ ffi . Stmt ], None ]): ''' Add a callback to be called with all next statements to be appended. For `If` statement, it can be called twice, one without \"else\" branch, and then maybe one more with \"else\" branch ''' self . append_stmt_callbacks . append ( callback ) def pop_append_stmt_callback ( self ): self . append_stmt_callbacks . pop ()","title":"ContextStack"},{"location":"api/#freetensor.core.context.ContextStack.get_last_stmt_id","text":"Can be used inside the staged code, to get the ID of the immediately preceding statement Source code in python/freetensor/core/context.py 147 148 149 150 151 152 153 154 def get_last_stmt_id ( self ): ''' Can be used inside the staged code, to get the ID of the immediately preceding statement ''' for ctx in reversed ( self . stack ): if len ( ctx . stmt_seq ) > 0 : return ctx . stmt_seq [ - 1 ] . id raise ft . InvalidProgram ( \"There is no statement yet\" )","title":"get_last_stmt_id()"},{"location":"api/#freetensor.core.context.ContextStack.push_append_stmt_callback","text":"Add a callback to be called with all next statements to be appended. For If statement, it can be called twice, one without \"else\" branch, and then maybe one more with \"else\" branch Source code in python/freetensor/core/context.py 156 157 158 159 160 161 def push_append_stmt_callback ( self , callback : Callable [[ ffi . Stmt ], None ]): ''' Add a callback to be called with all next statements to be appended. For `If` statement, it can be called twice, one without \"else\" branch, and then maybe one more with \"else\" branch ''' self . append_stmt_callbacks . append ( callback )","title":"push_append_stmt_callback()"},{"location":"api/#freetensor.core.context.StmtRange","text":"Record a set of statement in a program, can be used for custom gradient Usage: with StmtRange() as rng: # Some statements StmtRange can be used interleaved with AST scopes. In these cases, you can directly call __enter__ and __exit__ . E.g., rng = StmtRange() rng.__enter__() # Some statements with VarDef(...) # Some scopes # Some other statements rng.__exit__(None, None, None) Source code in python/freetensor/core/context.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 class StmtRange : ''' Record a set of statement in a program, can be used for custom gradient Usage: ``` with StmtRange() as rng: # Some statements ``` `StmtRange` can be used interleaved with AST scopes. In these cases, you can directly call `__enter__` and `__exit__`. E.g., ``` rng = StmtRange() rng.__enter__() # Some statements with VarDef(...) # Some scopes # Some other statements rng.__exit__(None, None, None) ``` ''' def __init__ ( self ): self . ids = set () self . entered = False self . exited = False def __enter__ ( self ): def callback ( stmt ): self . ids . add ( stmt . id ) ctx_stack . push_append_stmt_callback ( callback ) self . entered = True return self def __exit__ ( self , exc_type , exc_value , traceback ): ctx_stack . pop_append_stmt_callback () self . exited = True def make ( self ): if not self . entered : raise ffi . InvalidProgram ( \"StmtRange is not properly entered\" ) if not self . exited : raise ffi . InvalidProgram ( \"StmtRange is not properly exited\" ) return self . ids","title":"StmtRange"},{"location":"api/#freetensor.core.context.pop_ast","text":"Get AST and reset context Internally used by transformer and tests Source code in python/freetensor/core/context.py 170 171 172 173 174 175 176 177 178 179 180 181 182 def pop_ast ( verbose : bool = False ): \"\"\" Get AST and reset context Internally used by `transformer` and tests \"\"\" ret = ctx_stack . pop () . make_stmt () ctx_stack . reset () if verbose : print ( \"The popped AST is:\" , file = sys . stderr ) print ( ret , file = sys . stderr ) print ( file = sys . stderr ) return ret","title":"pop_ast()"},{"location":"api/#freetensor.core.context.pop_ast_and_user_grads","text":"Get AST and reset context. Return an extra list for custom gradients Set UserGrad for details Source code in python/freetensor/core/context.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 def pop_ast_and_user_grads ( verbose : bool = False ): \"\"\" Get AST and reset context. Return an extra list for custom gradients Set `UserGrad` for details \"\"\" ast = ctx_stack . pop () . make_stmt () user_grads = ctx_stack . user_grads ctx_stack . reset () if verbose : print ( \"The popped AST is:\" , file = sys . stderr ) print ( ret , file = sys . stderr ) print ( file = sys . stderr ) return ast , user_grads","title":"pop_ast_and_user_grads()"},{"location":"api/#freetensor.core.driver","text":"","title":"driver"},{"location":"api/#freetensor.core.driver.Device","text":"Bases: ffi . Device A computing device can be constructed from 1. (TargetType, DeviceNumber) 2. (TargetType, getDeviceByName): cuda uses best matches criteria. 3. (TargetType, FullName, nth): get nth(from 0) device named Fullname . E.g. Device(TargetType::GPU, 0) means the 0-th GPU (device) Device(TargetType::GPU, \"V100\") means a GPU which best matches \"V100\" Device(TargetType::GPU, \"NVIDIA GeForce RTX 3060 Laptop GPU\", 0) A Device can be used as a \"with\" scope, then all the Array s and Driver s will use it by default. In this style, it also sets the default Target. E.g: with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default Source code in python/freetensor/core/driver.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 class Device ( ffi . Device ): ''' A computing device can be constructed from 1. (TargetType, DeviceNumber) 2. (TargetType, getDeviceByName): cuda uses best matches criteria. 3. (TargetType, FullName, nth): get nth(from 0) device named `Fullname`. E.g. Device(TargetType::GPU, 0) means the 0-th GPU (device) Device(TargetType::GPU, \"V100\") means a GPU which best matches \"V100\" Device(TargetType::GPU, \"NVIDIA GeForce RTX 3060 Laptop GPU\", 0) A Device can be used as a \"with\" scope, then all the `Array`s and `Driver`s will use it by default. In this style, it also sets the default Target. E.g: ``` with Device(...): ast = lower(ast) # Use the Target of the Device above by default a = Array(...) # Use the Device above by default ``` ''' def __enter__ ( self ): _old_target_device_stack . append ( ( config . default_target (), config . default_device ())) config . set_default_target ( self . target ()) config . set_default_device ( self ) return self def __exit__ ( self , exc_type , exc_value , traceback ): old_target , old_device = _old_target_device_stack . pop () config . set_default_target ( old_target ) config . set_default_device ( old_device )","title":"Device"},{"location":"api/#freetensor.core.driver.Driver","text":"Bases: ffi . Driver Source code in python/freetensor/core/driver.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 class Driver ( ffi . Driver ): def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' self . src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , self . src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , self . src , device , host_device , verbose ) self . func = func # When we pass numpy or pytorch tensors to `set_args`, they are # converted to `Array` objects by reference. In `Array`'s FFI, we # keep these tensors alive whenever the `Array`'s PYTHON objects # alive. We need to also keep the `Array`'s PYTHON objects here. # Please note that we cannot hold the reference count in `Driver`'s # C++ implementation, where we can only hold the `Array`'s C++ # objects alive. self . args_ref_cnt_holder = [] def native_code ( self ): ''' Get native code compiled by backend compiler ''' return self . src def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' # No need to hold reference of the last run any more self . args_ref_cnt_holder = [] args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ], dont_drop_borrow = not isinstance ( args [ i ], Array )) for key in kws : kws [ key ] = array ( kws [ key ], dont_drop_borrow = not isinstance ( kws [ key ], Array )) for arg in args : self . args_ref_cnt_holder . append ( arg ) for key in kws : self . args_ref_cnt_holder . append ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws ) def collect_returns ( self , always_return_pack : bool = False ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, or if `always_return_pack` is set, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 and not always_return_pack : return None elif len ( values ) == 1 and not always_return_pack : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values ) def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns ()","title":"Driver"},{"location":"api/#freetensor.core.driver.Driver.__call__","text":"Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call self.set_args first, then self.time , and finally self.collect_returns Source code in python/freetensor/core/driver.py 330 331 332 333 334 335 336 337 338 339 340 341 342 343 def __call__ ( self , * args , ** kws ): ''' Set argument, execute the binary code, and collect the returns If there is only one return value, it is returned directly. Otherwise, the return values are packed in a ReturnValuesPack This function will introduce some overhaed handling arguments and return values. For an accurate execution time measurement, plase call `self.set_args` first, then `self.time`, and finally `self.collect_returns` ''' self . set_args ( * args , ** kws ) self . run () return self . collect_returns ()","title":"__call__()"},{"location":"api/#freetensor.core.driver.Driver.__init__","text":"Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using build_binary Parameters: Name Type Description Default func ffi . Func AST of the function, where the function signature is needed to determine the parameters and return values required src str Native code generated from codegen required device Device ( Optional ) The device to run the program. If omitted, use the default device in config None verbose bool ( Optional ) True to print extra infomation None Source code in python/freetensor/core/driver.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def __init__ ( self , func : ffi . Func , src : str , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory This class is for internal use. Please consider using `build_binary` Parameters ---------- func : ffi.Func AST of the function, where the function signature is needed to determine the parameters and return values src : str Native code generated from codegen device : Device (Optional) The device to run the program. If omitted, use the default device in config verbose : bool (Optional) True to print extra infomation ''' self . src = str ( src ) if device is None : device = config . default_device () if verbose is None : verbose = False if host_device is None : super ( Driver , self ) . __init__ ( func , self . src , device , verbose ) else : super ( Driver , self ) . __init__ ( func , self . src , device , host_device , verbose ) self . func = func # When we pass numpy or pytorch tensors to `set_args`, they are # converted to `Array` objects by reference. In `Array`'s FFI, we # keep these tensors alive whenever the `Array`'s PYTHON objects # alive. We need to also keep the `Array`'s PYTHON objects here. # Please note that we cannot hold the reference count in `Driver`'s # C++ implementation, where we can only hold the `Array`'s C++ # objects alive. self . args_ref_cnt_holder = []","title":"__init__()"},{"location":"api/#freetensor.core.driver.Driver.collect_returns","text":"Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, or if always_return_pack is set, the return values are packed in a ReturnValuesPack Source code in python/freetensor/core/driver.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 def collect_returns ( self , always_return_pack : bool = False ): ''' Collect return values from an invocation Return values must be collect. Otherwise there will be memory leaks If there is only one return value, it is returned directly. Otherwise, or if `always_return_pack` is set, the return values are packed in a ReturnValuesPack ''' values = super ( Driver , self ) . collect_returns () if len ( values ) == 0 and not always_return_pack : return None elif len ( values ) == 1 and not always_return_pack : return values [ 0 ] else : return ReturnValuesPack ( map ( lambda r : r . name , filter ( lambda r : not r . is_in_closure or r . return_closure , self . func . returns )), values )","title":"collect_returns()"},{"location":"api/#freetensor.core.driver.Driver.native_code","text":"Get native code compiled by backend compiler Source code in python/freetensor/core/driver.py 282 283 284 def native_code ( self ): ''' Get native code compiled by backend compiler ''' return self . src","title":"native_code()"},{"location":"api/#freetensor.core.driver.Driver.set_args","text":"Set argument for an invocation Source code in python/freetensor/core/driver.py 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 def set_args ( self , * args , ** kws ): ''' Set argument for an invocation ''' # No need to hold reference of the last run any more self . args_ref_cnt_holder = [] args = list ( args ) kws = dict ( kws ) for i in range ( len ( args )): args [ i ] = array ( args [ i ], dont_drop_borrow = not isinstance ( args [ i ], Array )) for key in kws : kws [ key ] = array ( kws [ key ], dont_drop_borrow = not isinstance ( kws [ key ], Array )) for arg in args : self . args_ref_cnt_holder . append ( arg ) for key in kws : self . args_ref_cnt_holder . append ( kws [ key ]) super ( Driver , self ) . set_args ( args , kws )","title":"set_args()"},{"location":"api/#freetensor.core.driver.ReturnValuesPack","text":"Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: x, y, z = pack , or in a named manner: pack['x'] Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values Source code in python/freetensor/core/driver.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 class ReturnValuesPack : ''' Hold return values from a Driver invocation Return values can be retrieved in an anonymous manner: `x, y, z = pack`, or in a named manner: `pack['x']` Please note that a ReturnValuesPack is different from a OrderedDict, as OrderedDict unpacks to keys rather than values ''' def __init__ ( self , keys : Sequence [ str ], values : Sequence [ Array ]): keys = list ( keys ) values = list ( values ) assert len ( keys ) == len ( values ) self . keys = keys self . values = values def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key ) def __contains__ ( self , key ): ''' Test if a return value exists ''' for k , v in zip ( self . keys , self . values ): if k == key : return True return False","title":"ReturnValuesPack"},{"location":"api/#freetensor.core.driver.ReturnValuesPack.__contains__","text":"Test if a return value exists Source code in python/freetensor/core/driver.py 227 228 229 230 231 232 def __contains__ ( self , key ): ''' Test if a return value exists ''' for k , v in zip ( self . keys , self . values ): if k == key : return True return False","title":"__contains__()"},{"location":"api/#freetensor.core.driver.ReturnValuesPack.__getitem__","text":"Get a return value with a name. Tuple is supported for multiple values Source code in python/freetensor/core/driver.py 215 216 217 218 219 220 221 222 223 224 225 def __getitem__ ( self , key ) -> Array : ''' Get a return value with a name. Tuple is supported for multiple values ''' if type ( key ) is tuple or type ( key ) is list : ret = [] for k in key : ret . append ( self [ k ]) return ret for k , v in zip ( self . keys , self . values ): if k == key : return v raise ffi . DriverError ( \"No such return value named \" + key )","title":"__getitem__()"},{"location":"api/#freetensor.core.driver.ReturnValuesPack.__iter__","text":"Get all return values in the order declared in Func Source code in python/freetensor/core/driver.py 211 212 213 def __iter__ ( self ): ''' Get all return values in the order declared in Func ''' yield from self . values","title":"__iter__()"},{"location":"api/#freetensor.core.driver.array","text":"Factory function for Array This function is preferred over directly calling Array 's constructor, because it accepts more data format. If data is another FreeTensor Array , the original object will be returned, with dont_drop_borrow and moved set to new values. If dtype is set and different from the original data type, the Array will be copied first to convert the data type. If data is Numpy Array or PyTorch Tensor , it will be converted to FreeTensor Array . Memory copy will be avoided in most cases, but it is inevitable if the data is strided. If dtype is set and different from the original data type, the Array or Tensor will be copied first to convert the data type. Otherwise, the data will be treated as an n-dimensional array-like object, and will be parsed according the rules in NumPy. The data type is also set accordingly, unless dtype is set. Parameters: Name Type Description Default data FreeTensor Array, Numpy Array, PyTorch Tensor, or other array-like objects Data to be copied to or borrowed by the new Array object required dtype ft.DataType or str If data is not in dtype , convert it to dtype first before constructing the Array None dont_drop_borrow bool If true, report an error if we have to drop a borrwed data. This flag is set to true when the Array is cunstructed IMPLICITLY (not by this function) from a user object by borrowing from it, where users may expect they are acutually manipulating the their user object, instead of this Array False moved bool If true, it means we do not care about data in this Array any more after the program runs. Variables with \"input-mutable\" access type may modify the Array False Source code in python/freetensor/core/driver.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def array ( data , dtype = None , dont_drop_borrow : bool = False , moved : bool = False ): ''' Factory function for Array This function is preferred over directly calling `Array`'s constructor, because it accepts more data format. - If `data` is another FreeTensor `Array`, the original object will be returned, with `dont_drop_borrow` and `moved` set to new values. If `dtype` is set and different from the original data type, the `Array` will be copied first to convert the data type. - If `data` is Numpy `Array` or PyTorch `Tensor`, it will be converted to FreeTensor `Array`. Memory copy will be avoided in most cases, but it is inevitable if the data is strided. If `dtype` is set and different from the original data type, the `Array` or `Tensor` will be copied first to convert the data type. - Otherwise, the data will be treated as an n-dimensional array-like object, and will be parsed according the rules in NumPy. The data type is also set accordingly, unless `dtype` is set. Parameters ---------- data : FreeTensor Array, Numpy Array, PyTorch Tensor, or other array-like objects Data to be copied to or borrowed by the new Array object dtype : ft.DataType or str If `data` is not in `dtype`, convert it to `dtype` first before constructing the `Array` dont_drop_borrow : bool If true, report an error if we have to drop a borrwed data. This flag is set to true when the Array is cunstructed IMPLICITLY (not by this function) from a user object by borrowing from it, where users may expect they are acutually manipulating the their user object, instead of this Array moved : bool If true, it means we do not care about data in this Array any more after the program runs. Variables with \"input-mutable\" access type may modify the Array ''' if dtype is not None : dtype = DataType ( dtype ) if type ( data ) is Array : if dtype is not None and dtype != data . dtype : # Must be contiguous data = Array ( data . numpy () . astype ( to_numpy_dtype ( dtype ))) data . set_dont_drop_borrow ( dont_drop_borrow ) data . set_moved ( moved ) return data # For NumPy, Although Pybind11's `array_t` type provides a flag `forcecast` to # cast from a strided array to a contiguous one. But it always casts to a specific # type, e.g. float64. I have no idea how to support multiple types. Therfore, # we have to call NumPy's `.copy(order='C')` to make a new NumPy array. This # function can only be called from Python side (not from PyBind11's `py::array` # type). if type ( data ) is np . ndarray : if dtype is not None and to_numpy_dtype ( dtype ) != data . dtype : data = data . astype ( to_numpy_dtype ( dtype ), order = 'C' ) elif not data . flags [ 'C_CONTIGUOUS' ]: data = data . copy ( order = 'C' ) return Array ( data , dont_drop_borrow , moved ) if data . __class__ . __module__ == 'torch' : import torch if type ( data ) is torch . Tensor : if not config . with_pytorch (): raise ffi . InvalidIO ( \"FreeTensor should be built with WITH_PYTORCH to accept a PyTorch tensor\" ) if dtype is not None and to_torch_dtype ( dtype ) != data . dtype : data = data . to ( to_torch_dtype ( dtype ), memory_format = torch . contiguous_format ) elif not data . is_contiguous (): data = data . contiguous () return Array ( data , dont_drop_borrow , moved ) return array ( np . array ( data , dtype = None if dtype is None else to_numpy_dtype ( dtype )), dtype = dtype , dont_drop_borrow = dont_drop_borrow , moved = moved )","title":"array()"},{"location":"api/#freetensor.core.driver.build_binary","text":"Compile a program using a backend compiler and load it into memory Parameters: Name Type Description Default code NativeCode Native code generated by codegen . If not specified, a partial function is returned, which can be used as a decorator None device Device ( Optional ) The device to run the program. If omitted, use the default device in config None Source code in python/freetensor/core/driver.py 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 def build_binary ( code : Optional [ NativeCode ] = None , device : Optional [ Device ] = None , host_device : Optional [ Device ] = None , verbose : Optional [ bool ] = None ): ''' Compile a program using a backend compiler and load it into memory Parameters ---------- code : NativeCode Native code generated by `codegen`. If not specified, a partial function is returned, which can be used as a decorator device : Device (Optional) The device to run the program. If omitted, use the default device in config ''' if code is not None : if device is None : device = config . default_device () if device . target () != code . target : raise ffi . DriverError ( f \"Codegen target ( { code . target } ) is inconsistent with device target ( { device . target () } )\" ) return Driver ( code . func , code . code , device , host_device , verbose ) else : f = build_binary if device is not None : f = functools . partial ( f , device = device ) if host_device is not None : f = functools . partial ( f , host_device = host_device ) if verbose is not None : f = functools . partial ( f , verbose = verbose ) return f","title":"build_binary()"},{"location":"api/#freetensor.core.driver.move","text":"Alias for array(data, dont_drop_borrow=False, moved=True) Source code in python/freetensor/core/driver.py 102 103 104 105 def move ( data ): ''' Alias for array(data, dont_drop_borrow=False, moved=True) ''' return array ( data , dont_drop_borrow = False , moved = True )","title":"move()"},{"location":"api/#freetensor.core.expr","text":"Facility to build AST expressions Classes and functions in this module are not only used internally for constructing AST nodes, and also exposed to users via multi-stage programming","title":"expr"},{"location":"api/#freetensor.core.expr.AlreadyMadeReduceTo","text":"A single-value type that marks a ReduceTo node is already made, and there is no need to make another Store node In standard Python data model, functions like iadd returns the modified self, and setitem does a self-assignment. We do the augmenting assignment directly in iadd and return AlreadyMadeReduceTo, so we do not have to Store it again Source code in python/freetensor/core/expr.py 29 30 31 32 33 34 35 36 37 38 class AlreadyMadeReduceTo : \"\"\" A single-value type that marks a ReduceTo node is already made, and there is no need to make another Store node In standard Python data model, functions like __iadd__ returns the modified self, and __setitem__ does a self-assignment. We do the augmenting assignment directly in __iadd__ and return AlreadyMadeReduceTo, so we do not have to Store it again \"\"\" pass","title":"AlreadyMadeReduceTo"},{"location":"api/#freetensor.core.expr.VarRef","text":"Bases: ffi . FrontendVar Variable of FreeTensor All variables in FreeTensor DSL (declared via Var , created by empty or var , returned by libop , etc.), and their slices, are VarRef objects. Operations on VarRef objects generates AST nodes Source code in python/freetensor/core/expr.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 class VarRef ( ffi . FrontendVar ): ''' Variable of FreeTensor All variables in FreeTensor DSL (declared via `Var`, created by `empty` or `var`, returned by `libop`, etc.), and their slices, are `VarRef` objects. Operations on `VarRef` objects generates AST nodes ''' def __init__ ( self , name : str , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = [], is_load_at_version : bool = False ): super ( VarRef , self ) . __init__ ( name , full_shape , dtype , mtype , indices , is_load_at_version ) from .stmt import find_borrowed_vardefs self . borrowed_vardefs = find_borrowed_vardefs ( indices ) for item in self . borrowed_vardefs : item . lend_out () def __del__ ( self ): for item in self . borrowed_vardefs : item . reclaim () def __getitem__ ( self , key ): return self . __class__ ( self . name , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) def __setitem__ ( self , key , value ): var = self . __class__ ( self . name , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) if var . ndim > 0 : if value is AlreadyMadeReduceTo : return from .. import libop libop . assign ( var , value ) return if value is AlreadyMadeReduceTo : return top = ctx_stack . top () top . append_stmt ( var . as_store ( top . get_metadata (), value )) def as_store ( self , metadata , value ): if ( not isinstance ( value , ffi . AnyExpr ) and ffi . up_cast ( dtype ( value ), self . dtype ) . base != self . dtype . base ): # Add explicit cast node, to avoid confusion after propagation value = cast ( value , self . dtype ) return super ( VarRef , self ) . as_store ( metadata , value ) def as_reduce_to ( self , reduce_op , metadata , value , atomic = False ): if ( not isinstance ( value , ffi . AnyExpr ) and ffi . up_cast ( dtype ( value ), self . dtype ) . base != self . dtype . base ): # Add explicit cast node, to avoid confusion after propagation value = cast ( value , self . dtype ) return super ( VarRef , self ) . as_reduce_to ( reduce_op , metadata , value , atomic ) def select ( self , idx , dim ): assert isinstance ( dim , int ) assert dim >= 0 and dim < self . ndim indices = [ slice ( None , None ) if d != dim else idx for d in range ( self . ndim ) ] return self [ indices ] def shape ( self , dim = None ): ''' Return lengths of all dimensions or the length of one dimension `.shape()` -> list of lengths of all dimensions `.shape(dim)` -> length of dimension `dim`, where `dim` can be `int` or `Expr` All lengths can be `Expr` (if the length is dynamically decided) or `int` (if statically decided) ''' intOrExpr = lambda x : x . val if isinstance ( x , ffi . IntConst ) else x if dim is None : return [ intOrExpr ( d ) for d in super ( VarRef , self ) . shape ()] else : return intOrExpr ( super ( VarRef , self ) . shape ( dim )) def _parse_key ( self , key ): if key is None or key is ... : key = () if not isinstance ( key , collections . abc . Sequence ): key = ( key ,) ffiIdx = [] for idx , length in zip ( key , self . shape ()): if isinstance ( idx , slice ): start = idx . start if idx . start is not None else 0 stop = idx . stop if idx . stop is not None else length assert idx . step is None or idx . step == 1 ffiIdx . append ( ffi . FrontendVarIdx ( start , stop )) elif isinstance ( idx , VarRef ): if len ( idx . full_shape ) == len ( idx . indices ): ffiIdx . append ( ffi . FrontendVarIdx ( idx . as_load ())) else : assert len ( key ) == 1 , f \"Shape of an index of { self . name } should be 1-D, instead of { idx . name } \" assert type ( idx . full_shape [ 0 ] ) is ffi . IntConst , \"Dynamic number of dimensions is not supported\" ndim = idx . full_shape [ 0 ] . val ffiIdx += [ ffi . FrontendVarIdx ( idx [ i ] . as_load ()) for i in range ( ndim ) ] else : ffiIdx . append ( ffi . FrontendVarIdx ( idx )) return ffiIdx def __add__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( self , other ) return self . as_load () + other def __radd__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . add ( other , self ) return other + self . as_load () def __iadd__ ( self , other ): if self . ndim > 0 : from .. import libop libop . add_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Add , top . get_metadata (), other )) return AlreadyMadeReduceTo def __sub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( self , other ) return self . as_load () - other def __rsub__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . sub ( other , self ) return other - self . as_load () def __isub__ ( self , other ): if self . ndim > 0 : from .. import libop libop . sub_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Add , top . get_metadata (), - other )) return AlreadyMadeReduceTo def __mul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( self , other ) return self . as_load () * other def __rmul__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mul ( other , self ) return other * self . as_load () def __imul__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mul_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Mul , top . get_metadata (), other )) return AlreadyMadeReduceTo def __truediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( self , other ) return self . as_load () / other def __rtruediv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . truediv ( other , self ) return other / self . as_load () def __itruediv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . truediv_to ( self , other ) return AlreadyMadeReduceTo top = ctx_stack . top () top . append_stmt ( self . as_reduce_to ( ffi . ReduceOp . Mul , top . get_metadata (), 1. / other )) return AlreadyMadeReduceTo def __floordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( self , other ) return self . as_load () // other def __rfloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . floordiv ( other , self ) return other // self . as_load () def __ifloordiv__ ( self , other ): if self . ndim > 0 : from .. import libop libop . floordiv_to ( self , other ) return AlreadyMadeReduceTo return NotImplemented # Fallback to x = x // y def __mod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( self , other ) return self . as_load () % other def __rmod__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . mod ( other , self ) return other % self . as_load () def __imod__ ( self , other ): if self . ndim > 0 : from .. import libop libop . mod_to ( self , other ) return AlreadyMadeReduceTo return NotImplemented # Fallback to x = x % y def __lt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . lt ( self , other ) return self . as_load () < other def __le__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . le ( self , other ) return self . as_load () <= other def __gt__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . gt ( self , other ) return self . as_load () > other def __ge__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ge ( self , other ) return self . as_load () >= other def __eq__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . eq ( self , other ) return self . as_load () == other def __ne__ ( self , other ): if self . ndim > 0 : from .. import libop return libop . ne ( self , other ) return self . as_load () != other def __neg__ ( self ): if self . ndim > 0 : from .. import libop return libop . neg ( self ) return 0 - self . as_load () def __matmul__ ( self , other ): from .. import libop return libop . matmul ( self , other ) def __rmatmul__ ( self , other ): from .. import libop return libop . matmul ( other , self )","title":"VarRef"},{"location":"api/#freetensor.core.expr.VarRef.shape","text":"Return lengths of all dimensions or the length of one dimension .shape() -> list of lengths of all dimensions .shape(dim) -> length of dimension dim , where dim can be int or Expr All lengths can be Expr (if the length is dynamically decided) or int (if statically decided) Source code in python/freetensor/core/expr.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def shape ( self , dim = None ): ''' Return lengths of all dimensions or the length of one dimension `.shape()` -> list of lengths of all dimensions `.shape(dim)` -> length of dimension `dim`, where `dim` can be `int` or `Expr` All lengths can be `Expr` (if the length is dynamically decided) or `int` (if statically decided) ''' intOrExpr = lambda x : x . val if isinstance ( x , ffi . IntConst ) else x if dim is None : return [ intOrExpr ( d ) for d in super ( VarRef , self ) . shape ()] else : return intOrExpr ( super ( VarRef , self ) . shape ( dim ))","title":"shape()"},{"location":"api/#freetensor.core.expr.VarRefFromVarDef","text":"Bases: VarRef VarRef with extra checks Source code in python/freetensor/core/expr.py 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 class VarRefFromVarDef ( VarRef ): ''' VarRef with extra checks ''' def __init__ ( self , name : str , vardef , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = []): super ( VarRefFromVarDef , self ) . __init__ ( name , full_shape , dtype , mtype , indices ) self . vardef = vardef def __getitem__ ( self , key ): return VarRefFromVarDef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) def __setitem__ ( self , key , value ): var = VarRefFromVarDef ( self . name , self . vardef , self . full_shape , self . dtype , self . mtype , self . chain_indices ( self . _parse_key ( key ))) if var . ndim > 0 : if value is AlreadyMadeReduceTo : return from .. import libop libop . assign ( var , value ) return if not is_writable ( var . vardef . atype ): raise ffi . InvalidProgram ( f \"Cannot modify an \\\" { var . vardef . atype } \\\" tensor ` { self . name } `\" ) if var . vardef . borrower_cnt > 0 : raise ffi . InvalidProgram ( \"Cannot modify tensor `\" + self . name + \"` becuase it has been borrowed in another tensor's shape, \" \"a tensor slice, or a range of a loop\" ) if value is AlreadyMadeReduceTo : # Following the checks above return top = ctx_stack . top () top . append_stmt ( var . as_store ( top . get_metadata (), value ))","title":"VarRefFromVarDef"},{"location":"api/#freetensor.core.expr.VarVersionRef","text":"Bases: VarRef Special VarRef used for custom gradient, generated from mark_version Source code in python/freetensor/core/expr.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 class VarVersionRef ( VarRef ): ''' Special VarRef used for custom gradient, generated from `mark_version` ''' def __init__ ( self , name : str , full_shape : Sequence , dtype : ffi . DataType , mtype : ffi . MemType , indices : Sequence = []): for dim in full_shape : if not isinstance ( dim , int ) and not isinstance ( dim , ffi . IntConst ): raise ffi . InvalidAutoGrad ( \"`mark_version` on dynamic-shaped variables is not supported\" \" yet\" ) super ( VarVersionRef , self ) . __init__ ( name , full_shape , dtype , mtype , indices , True )","title":"VarVersionRef"},{"location":"api/#freetensor.core.expr.abs","text":"Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The absolute value Source code in python/freetensor/core/expr.py 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 def abs ( expr ): ''' Absolute value For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.abs Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The absolute value ''' if _istensor ( expr ): from .. import libop return libop . abs ( expr ) if isinstance ( expr , Number ): return builtins . abs ( expr ) return ffi . makeAbs ( expr )","title":"abs()"},{"location":"api/#freetensor.core.expr.add","text":"lhs + rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The sum Source code in python/freetensor/core/expr.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 def add ( lhs , rhs ): ''' `lhs + rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.add Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The sum ''' return lhs + rhs","title":"add()"},{"location":"api/#freetensor.core.expr.any","text":"Create an AnyExpr node (only for testing and type inference) Any nodes matches any expression nodes in ast.match Source code in python/freetensor/core/expr.py 1203 1204 1205 1206 1207 1208 1209 def any (): ''' Create an AnyExpr node (only for testing and type inference) Any nodes matches any expression nodes in `ast.match` ''' return ffi . makeAnyExpr ()","title":"any()"},{"location":"api/#freetensor.core.expr.cast","text":"Cast to another type Parameters: Name Type Description Default expr VarRef or Number The operand required dtype DataTypr or str The target data type required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 def cast ( expr , dtype ): ''' Cast to another type Parameters ---------- expr : VarRef or Number The operand dtype : DataTypr or str The target data type Returns ------- VarRef or Number The result ''' return ffi . makeCast ( expr , ffi . DataType ( dtype ))","title":"cast()"},{"location":"api/#freetensor.core.expr.ceil","text":"Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 def ceil ( expr ): ''' Round a float up to an interger (towards +inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceil Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . ceil ( expr ) return ffi . makeCeil ( expr )","title":"ceil()"},{"location":"api/#freetensor.core.expr.ceildiv","text":"Ceiling integer division of lhs dividing by rhs The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 def ceildiv ( lhs , rhs ): ''' Ceiling integer division of `lhs` dividing by `rhs` The result rounds towards positive infinity For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ceildiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . ceildiv ( lhs , rhs ) if type ( lhs ) is int and type ( rhs ) is int : return lhs // rhs + ( lhs % rhs > 0 ) return ffi . makeCeilDiv ( lhs , rhs )","title":"ceildiv()"},{"location":"api/#freetensor.core.expr.dtype","text":"Get element data type of a variable Source code in python/freetensor/core/expr.py 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 def dtype ( var ): ''' Get element data type of a variable ''' if isinstance ( var , VarRef ): return var . dtype elif isinstance ( var , ffi . Expr ): return var . dtype else : # TODO: Config default type if isinstance ( var , bool ): # NOTE: before int, because bool in Python is a sub-class of int return ffi . DataType ( \"bool\" ) elif isinstance ( var , float ): return ffi . DataType ( \"float32\" ) elif isinstance ( var , int ): return ffi . DataType ( \"int32\" ) else : raise Exception ( 'Unknown scalar type: ' + str ( type ( var )))","title":"dtype()"},{"location":"api/#freetensor.core.expr.eq","text":"lhs == rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 def eq ( lhs , rhs ): ''' `lhs == rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.eq Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs == rhs","title":"eq()"},{"location":"api/#freetensor.core.expr.exp","text":"Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The exponent Source code in python/freetensor/core/expr.py 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 def exp ( expr ): ''' Natural exponent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.exp Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The exponent ''' if _istensor ( expr ): from .. import libop return libop . exp ( expr ) if isinstance ( expr , Number ): return math . exp ( expr ) return ffi . makeExp ( expr )","title":"exp()"},{"location":"api/#freetensor.core.expr.floor","text":"Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 def floor ( expr ): ''' Round a float down to an interger (towards -inf) For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floor Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . floor ( expr ) return ffi . makeFloor ( expr )","title":"floor()"},{"location":"api/#freetensor.core.expr.floordiv","text":"Floored integer division of lhs dividing by rhs The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over round_towards_0_div , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 def floordiv ( lhs , rhs ): ''' Floored integer division of `lhs` dividing by `rhs` The result rounds towards negative infinity (following Python convention, instead of C) This function is recommended over `round_towards_0_div`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.floordiv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs // rhs","title":"floordiv()"},{"location":"api/#freetensor.core.expr.ge","text":"lhs >= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 def ge ( lhs , rhs ): ''' `lhs >= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ge Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs >= rhs","title":"ge()"},{"location":"api/#freetensor.core.expr.gt","text":"lhs > rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 def gt ( lhs , rhs ): ''' `lhs > rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.gt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs > rhs","title":"gt()"},{"location":"api/#freetensor.core.expr.if_then_else","text":"Similar to then_case if cond else else_case NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use if_then_else to guard an out-of-bound array indexing Parameters: Name Type Description Default cond VarRef of Number Condition required lhs VarRef or Number Then-case experssion required rhs VarRef or Number Else-case expression required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 def if_then_else ( cond , then_case , else_case ): ''' Similar to `then_case if cond else else_case` NOTE: there is NO guarantee that only one branch will be executed. In some cases, both branches will be executed and the result of one of them will be picked. Therefore, please do NOT use `if_then_else` to guard an out-of-bound array indexing Parameters ---------- cond : VarRef of Number Condition lhs : VarRef or Number Then-case experssion rhs : VarRef or Number Else-case expression Returns ------- VarRef or Number The result ''' if type ( cond ) is bool : return then_case if cond else else_case return ffi . makeIfExpr ( cond , then_case , else_case )","title":"if_then_else()"},{"location":"api/#freetensor.core.expr.intrinsic","text":"Invoke whatever target code Parameters: Name Type Description Default fmt str What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) required The Parameters to fmt required ret_type DataType or str (Keyword argument only) The return type. Void for no return type. Defaults to Void required has_side_effect (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false required Source code in python/freetensor/core/expr.py 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 def intrinsic ( fmt , * params , ** kws ): \"\"\" Invoke whatever target code Parameters ---------- fmt : str What to run. \"%\" is filled by parameters one by one. E.g. sinf(%) The following variadic arguments : Expr Parameters to `fmt` ret_type : DataType or str (Keyword argument only) The return type. Void for no return type. Defaults to Void has_side_effect: bool (Keyword argument only) True to indicate the intrinsic modifes something other than the return value. Defaults to false \"\"\" ret_type = ffi . DataType ( \"void\" ) has_side_effect = False if \"ret_type\" in kws : ret_type = ffi . DataType ( kws [ \"ret_type\" ]) del kws [ \"ret_type\" ] if \"has_side_effect\" in kws : has_side_effect = kws [ \"has_side_effect\" ] del kws [ \"has_side_effect\" ] assert len ( kws ) == 0 , \"Unrecognized keyword arguments: %s \" % kws return ffi . makeIntrinsic ( fmt , params , ret_type , has_side_effect )","title":"intrinsic()"},{"location":"api/#freetensor.core.expr.l_and","text":"Logical and of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The logical and Source code in python/freetensor/core/expr.py 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 def l_and ( lhs , rhs ): ''' Logical and of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_and Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical and ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_and ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs and rhs else : return ffi . makeLAnd ( lhs , rhs )","title":"l_and()"},{"location":"api/#freetensor.core.expr.l_not","text":"Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The logical not Source code in python/freetensor/core/expr.py 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 def l_not ( expr ): ''' Logical not For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_not Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The logical not ''' if _istensor ( expr ): from .. import libop return libop . l_not ( expr ) if type ( expr ) is bool : return not expr else : return ffi . makeLNot ( expr )","title":"l_not()"},{"location":"api/#freetensor.core.expr.l_or","text":"Logical or of lhs and rhs NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The logical or Source code in python/freetensor/core/expr.py 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 def l_or ( lhs , rhs ): ''' Logical or of `lhs` and `rhs` NOTE: Short-circuit evaluation is NOT supported For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.l_or Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The logical or ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . l_or ( lhs , rhs ) if type ( lhs ) is bool and type ( rhs ) is bool : return lhs or rhs else : return ffi . makeLOr ( lhs , rhs )","title":"l_or()"},{"location":"api/#freetensor.core.expr.le","text":"lhs <= rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 def le ( lhs , rhs ): ''' `lhs <= rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.le Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs <= rhs","title":"le()"},{"location":"api/#freetensor.core.expr.ln","text":"Natural logarithm For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ln Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The exponent Source code in python/freetensor/core/expr.py 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 def ln ( expr ): ''' Natural logarithm For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ln Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The exponent ''' if _istensor ( expr ): from .. import libop return libop . ln ( expr ) if isinstance ( expr , Number ): return math . log ( expr ) # Defaults to ln without the base return ffi . makeLn ( expr )","title":"ln()"},{"location":"api/#freetensor.core.expr.load_at_version","text":"Create an LoadAtVersion node (only for custom gradient) This node is only used for custom gradient. See UserGradForPrevStmt . Source code in python/freetensor/core/expr.py 1212 1213 1214 1215 1216 1217 1218 def load_at_version ( tape_name : str , dtype , * indices ): ''' Create an LoadAtVersion node (only for custom gradient) This node is only used for custom gradient. See `UserGradForPrevStmt`. ''' return ffi . makeLoadAtVersion ( tape_name , indices , ffi . DataType ( dtype ))","title":"load_at_version()"},{"location":"api/#freetensor.core.expr.lt","text":"lhs < rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 def lt ( lhs , rhs ): ''' `lhs < rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.lt Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs < rhs","title":"lt()"},{"location":"api/#freetensor.core.expr.max","text":"Maximum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The maximum Source code in python/freetensor/core/expr.py 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 def max ( lhs , rhs ): ''' Maximum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.max Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The maximum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . max ( lhs , rhs ) if isinstance ( lhs , Number ) and isinstance ( rhs , Number ): return builtins . max ( lhs , rhs ) return ffi . makeMax ( lhs , rhs )","title":"max()"},{"location":"api/#freetensor.core.expr.min","text":"Minimum of lhs and rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The minimum Source code in python/freetensor/core/expr.py 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 def min ( lhs , rhs ): ''' Minimum of `lhs` and `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.min Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The minimum ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . min ( lhs , rhs ) if isinstance ( lhs , Number ) and isinstance ( rhs , Number ): return builtins . min ( lhs , rhs ) return ffi . makeMin ( lhs , rhs )","title":"min()"},{"location":"api/#freetensor.core.expr.mod","text":"lhs modulus rhs The result is always non-negative (following Python convention, instead of C). This function is recommended over remainder , as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The modulo Source code in python/freetensor/core/expr.py 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 def mod ( lhs , rhs ): ''' `lhs` modulus `rhs` The result is always non-negative (following Python convention, instead of C). This function is recommended over `remainder`, as it enjoys more optimizations For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mod Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The modulo ''' return lhs % rhs","title":"mod()"},{"location":"api/#freetensor.core.expr.mtype","text":"Get memory type of a variable Source code in python/freetensor/core/expr.py 1260 1261 1262 1263 1264 1265 def mtype ( var ): ''' Get memory type of a variable ''' if isinstance ( var , VarRef ): return var . mtype else : return 'byvalue'","title":"mtype()"},{"location":"api/#freetensor.core.expr.mul","text":"lhs * rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The product Source code in python/freetensor/core/expr.py 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 def mul ( lhs , rhs ): ''' `lhs * rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.mul Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The product ''' return lhs * rhs","title":"mul()"},{"location":"api/#freetensor.core.expr.ndim","text":"Get the number of dimensions of a variable Source code in python/freetensor/core/expr.py 1221 1222 1223 1224 1225 1226 def ndim ( var ): ''' Get the number of dimensions of a variable ''' if isinstance ( var , VarRef ): return var . ndim else : return 0","title":"ndim()"},{"location":"api/#freetensor.core.expr.ne","text":"lhs != rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The comparison Source code in python/freetensor/core/expr.py 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 def ne ( lhs , rhs ): ''' `lhs != rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.ne Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The comparison ''' return lhs != rhs","title":"ne()"},{"location":"api/#freetensor.core.expr.remainder","text":"Remainder of lhs dividing rhs The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use lhs % rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The remainder Source code in python/freetensor/core/expr.py 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 def remainder ( lhs , rhs ): ''' Remainder of `lhs` dividing `rhs` The result can be positive or negative (following C convention, instead of Python). End users are encouraged to use `lhs % rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.remainder Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The remainder ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . remainder ( lhs , rhs ) return ffi . makeRemainder ( lhs , rhs )","title":"remainder()"},{"location":"api/#freetensor.core.expr.round_towards_0_div","text":"C-style integer division of lhs dividing by rhs The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use lhs // rhs instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 def round_towards_0_div ( lhs , rhs ): ''' C-style integer division of `lhs` dividing by `rhs` The result rounds towards 0 (following C convention, instead of Python) End users are encouraged to use `lhs // rhs` instead, which follows Python convetion, and enjoys better optimization in FreeTensor For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.round_towards_0_div Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' if _istensor ( lhs ) or _istensor ( rhs ): from .. import libop return libop . round_towards_0_div ( lhs , rhs ) return ffi . makeRoundTowards0Div ( lhs , rhs )","title":"round_towards_0_div()"},{"location":"api/#freetensor.core.expr.shape","text":"shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable Source code in python/freetensor/core/expr.py 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 def shape ( var , i = None ): ''' shape(var, i): Get size of specified dimension of a variable shape(var): Get sizes of all dimensions of a variable ''' if isinstance ( var , VarRef ): return var . shape ( i ) else : if i is None : return () else : raise Exception ( f 'Getting size of dimension { i } of scalar { var } ' )","title":"shape()"},{"location":"api/#freetensor.core.expr.sigmoid","text":"Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 def sigmoid ( expr ): ''' Sigmoid For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sigmoid Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . sigmoid ( expr ) return ffi . makeSigmoid ( expr )","title":"sigmoid()"},{"location":"api/#freetensor.core.expr.sqrt","text":"Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The square root Source code in python/freetensor/core/expr.py 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 def sqrt ( expr ): ''' Square root For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sqrt Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square root ''' if _istensor ( expr ): from .. import libop return libop . sqrt ( expr ) if isinstance ( expr , Number ): return math . sqrt ( expr ) return ffi . makeSqrt ( expr )","title":"sqrt()"},{"location":"api/#freetensor.core.expr.square","text":"Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The square Source code in python/freetensor/core/expr.py 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 def square ( expr ): ''' Square For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.square Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The square ''' if _istensor ( expr ): from .. import libop return libop . square ( expr ) if isinstance ( expr , Number ): return expr * expr return ffi . makeSquare ( expr )","title":"square()"},{"location":"api/#freetensor.core.expr.sub","text":"lhs - rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The difference Source code in python/freetensor/core/expr.py 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 def sub ( lhs , rhs ): ''' `lhs - rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.sub Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The difference ''' return lhs - rhs","title":"sub()"},{"location":"api/#freetensor.core.expr.tanh","text":"Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters: Name Type Description Default expr VarRef or Number The operand required Returns: Type Description VarRef or Number The result Source code in python/freetensor/core/expr.py 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 def tanh ( expr ): ''' Hyperbolic tangent For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.tanh Parameters ---------- expr : VarRef or Number The operand Returns ------- VarRef or Number The result ''' if _istensor ( expr ): from .. import libop return libop . tanh ( expr ) if isinstance ( expr , Number ): return math . tanh ( expr ) return ffi . makeTanh ( expr )","title":"tanh()"},{"location":"api/#freetensor.core.expr.truediv","text":"Floating point division of lhs dividing by rhs For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters: Name Type Description Default lhs VarRef or Number The left-hand-side operand required rhs VarRef or Number The right-hand-side operand required Returns: Type Description VarRef or Number The quotient Source code in python/freetensor/core/expr.py 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 def truediv ( lhs , rhs ): ''' Floating point division of `lhs` dividing by `rhs` For scalar operands, it emit an expression node in AST. For non-scalar operands, it calls libop.truediv Parameters ---------- lhs : VarRef or Number The left-hand-side operand rhs : VarRef or Number The right-hand-side operand Returns ------- VarRef or Number The quotient ''' return lhs / rhs","title":"truediv()"},{"location":"api/#freetensor.core.frontend","text":"A frontend transforming user Python functions to ASTs via staging.","title":"frontend"},{"location":"api/#freetensor.core.frontend.FreeTensorOverload","text":"Bases: StagingOverload Helper class managing context in IR staging. Source code in python/freetensor/core/frontend.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 class FreeTensorOverload ( StagingOverload ): '''Helper class managing context in IR staging.''' def __init__ ( self ): super () . __init__ () self . lifetime_stack : List [ LifetimeScope ] = [] self . closure : Dict [ str , Any ] = {} self . name_dict : Dict [ str , int ] = {} def register_vardef ( self , name , shape , dtype , atype , mtype = None , capture = None ): fullname = self . fullname ( name ) if capture : self . closure [ fullname ] = capture return self . lifetime_stack [ - 1 ] . register_inner_scope ( _VarDef ( fullname , shape , dtype , atype , mtype )) def register_inlined_invoke ( self , ret_names : Sequence [ str ], func : ffi . Func , args , kvs ): ret_names = [ self . fullname ( name ) for name in ret_names ] return self . lifetime_stack [ - 1 ] . register_inner_scope ( Invoke ( ret_names , func , args , kvs )) def register_assert ( self , pred ): self . lifetime_stack [ - 1 ] . register_inner_scope ( Assert ( pred )) def fullname ( self , name : str ) -> str : '''Get distinct name.''' if name in self . name_dict : self . name_dict [ name ] += 1 return f ' { name } _ { self . name_dict [ name ] } ' else : self . name_dict [ name ] = 0 return name def in_staging ( self ,): return len ( self . lifetime_stack ) > 0 def custom_attr ( self , obj : Any , attr : str ) -> Any : if attr == \"ndim\" : return ndim ( obj ) if attr == \"shape\" : return lambda i = None : shape ( obj , i ) if attr == \"dtype\" : return dtype ( obj ) if attr == \"mtype\" : return mtype ( obj ) raise AttributeError () def functiondef_wrapper ( self , filename : str , func ): basic_wrapped = super () . functiondef_wrapper ( filename , func ) def wrapped ( * args , __freetensor_transform_outermost__ = False , ** kwargs ): if __freetensor_transform_outermost__ : call_metadata = None else : call_metadata = ctx_stack . top () . get_metadata () ctx_stack . top () . clear_metadata () prev = ctx_stack . top () . caller_metadata ctx_stack . top () . set_caller_metadata ( call_metadata ) result = basic_wrapped ( * args , ** kwargs ) ctx_stack . top () . set_caller_metadata ( prev ) return result return wrapped def metadata ( self , entry : str ) -> None : parts = entry . split () if len ( parts ) == 0 : return key = parts [ 0 ] val = None if len ( parts ) > 1 : val = parts [ 1 ] if key == 'label:' : if val is not None : ctx_stack . top () . add_label ( val ) return elif key == 'no_deps:' : if val is not None : back = inspect . currentframe () . f_back if val in back . f_locals : var = back . f_locals [ val ] elif val in back . f_globals : var = back . f_globals [ val ] else : raise self . error ( f 'Variable { val } not found for annotating comment ( { key } : { val } )' ) if not isinstance ( var , VarRef ): raise self . error ( f 'Variable { val } = { var } is not a VarRef, which is required by annotating comment ( { key } : { val } )' ) ctx_stack . top () . add_next_no_deps ( var . name ) return elif key == 'prefer_libs' : ctx_stack . top () . set_next_prefer_libs () return raise ffi . InvalidProgram ( '''Invalid metadata. Possible metadata are: `label: <label_name>`: to label the following statement, `no_deps: <variable_name>`: to mark a variable to have no dependence along the following loop, `prefer_libs`: to indicate the following statement should preferably be executed using external libraries. ''' ) def at_position ( self , filename : str , lineno : int ) -> None : ctx_stack . top () . set_next_location ( filename , lineno )","title":"FreeTensorOverload"},{"location":"api/#freetensor.core.frontend.FreeTensorOverload.fullname","text":"Get distinct name. Source code in python/freetensor/core/frontend.py 99 100 101 102 103 104 105 106 def fullname ( self , name : str ) -> str : '''Get distinct name.''' if name in self . name_dict : self . name_dict [ name ] += 1 return f ' { name } _ { self . name_dict [ name ] } ' else : self . name_dict [ name ] = 0 return name","title":"fullname()"},{"location":"api/#freetensor.core.frontend.LifetimeScope","text":"This scope is used to register multiple scopes inside a single lifetime scope. The inner scopes might be used to register variables, etc. They will be exited in reverse order of their registration. Source code in python/freetensor/core/frontend.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class LifetimeScope : '''This scope is used to register multiple scopes inside a single lifetime scope. The inner scopes might be used to register variables, etc. They will be exited in reverse order of their registration. ''' def __init__ ( self ): self . inner_scopes = [] def __enter__ ( self ): lang_overload . lifetime_stack . append ( self ) def __exit__ ( self , exc_type , exc_val , exc_tb ): for scope in reversed ( self . inner_scopes ): scope . __exit__ ( exc_type , exc_val , exc_tb ) popped = lang_overload . lifetime_stack . pop () if popped != self : raise lang_overload . error ( 'LifetimeScope enter/exit not match, must be FILO' ) def register_inner_scope ( self , scope ): self . inner_scopes . append ( scope ) return scope . __enter__ ()","title":"LifetimeScope"},{"location":"api/#freetensor.core.frontend.UserGrad","text":"Bases: UserGradStaged Define a custom gradient Follow the following steps to define custom gradient: Add some mark_version statements in the program. mark_version('y0', y) marks the specific versions of variable y at the program position of the statement and at all iterations as 'y0' . Add a UserGrad scope. 2.1. UserGrad optionally receives parameter stmt_range , recorded by the StmtRange helper class, which means the gradient is for the code specified in the range. Ignoring the parameter means setting gradient for the previous statement of the scope. 2.2. Other parameters of UserGrad sets the mapping from original variables to gradient variables. with UserGradForPrevStmt(x, y) as (dx, dy) provides VarRef dx and dy as gradient variables to be used inside the scope. In order to use the value from the forward pass in the backward pass, do not access the forward variables directly in the scope. Instead, use load_at_version expressions. load_at_version(y0, i, j) loads from y[i, j] at the specific version marked by y0 = mark_version(y) , saved from the same iteration in the forward pass . (If directly writing staged code, it is MarkVersion('y0', y) ). In other words, after AD, the position of mark_version and the dynamic loop iterator together makes up the actual version number for the tape. Build the AST with pop_ast_and_user_grads instead of pop_ast . An extra list will be returned together with the AST, which you need to pass as grad 's user_grads argument. This list records the forward-to-backward relation of the nodes. If you are directly writing staged code, use UserGradStaged instead. Parameters: Name Type Description Default stmt_range The range in the original program that we are setting custom gradient for required args Sequence [ VarRef ] (Positional variadic) Mapping from original variables to gradient variables () Source code in python/freetensor/core/frontend.py 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 class UserGrad ( UserGradStaged ): ''' Define a custom gradient Follow the following steps to define custom gradient: 1. Add some `mark_version` statements in the program. `mark_version('y0', y)` marks the specific versions of variable `y` **at the program position of the statement** and **at all iterations** as `'y0'`. 2. Add a `UserGrad` scope. 2.1. `UserGrad` optionally receives parameter `stmt_range`, recorded by the `StmtRange` helper class, which means the gradient is for the code specified in the range. Ignoring the parameter means setting gradient for the previous statement of the scope. 2.2. Other parameters of `UserGrad` sets the mapping from original variables to gradient variables. `with UserGradForPrevStmt(x, y) as (dx, dy)` provides `VarRef` `dx` and `dy` as gradient variables to be used inside the scope. 3. In order to use the value from the forward pass in the backward pass, do not access the forward variables directly in the scope. Instead, use `load_at_version` expressions. `load_at_version(y0, i, j)` loads from `y[i, j]` **at the specific version marked by `y0 = mark_version(y)`**, saved from **the same iteration in the forward pass**. (If directly writing staged code, it is `MarkVersion('y0', y)`). In other words, after AD, the position of `mark_version` and the dynamic loop iterator together makes up the actual version number for the tape. 4. Build the AST with `pop_ast_and_user_grads` instead of `pop_ast`. An extra list will be returned together with the AST, which you need to pass as `grad`'s `user_grads` argument. This list records the forward-to-backward relation of the nodes. If you are directly writing staged code, use `UserGradStaged` instead. Parameters ---------- stmt_range: Optional[StmtRange] The range in the original program that we are setting custom gradient for args: Sequence[VarRef] (Positional variadic) Mapping from original variables to gradient variables ''' def __init__ ( self , * args : Sequence [ VarRef ], ** kvs ): super ( UserGrad , self ) . __init__ ( * args , ** kvs ) self . lifetime_scope = LifetimeScope () def __enter__ ( self ): ret = super ( UserGrad , self ) . __enter__ () self . lifetime_scope . __enter__ () return ret def __exit__ ( self , exc_type , exc_value , traceback ): self . lifetime_scope . __exit__ ( exc_type , exc_value , traceback ) return super ( UserGrad , self ) . __exit__ ( exc_type , exc_value , traceback )","title":"UserGrad"},{"location":"api/#freetensor.core.frontend.Var","text":"Bases: StagedTypeAnnotation Source code in python/freetensor/core/frontend.py 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 class Var ( StagedTypeAnnotation ): def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype def annotate ( self , name : str ) -> VarRef : return lang_overload . register_vardef ( name , self . shape , self . dtype , self . atype , self . mtype )","title":"Var"},{"location":"api/#freetensor.core.frontend.Var.__init__","text":"Declare a variable Parameters: Name Type Description Default name str Name of the variable required shape Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape required dtype str or DataType Data type of the variable required atype str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" 'input' mtype str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used None Source code in python/freetensor/core/frontend.py 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def __init__ ( self , shape , dtype , atype = \"input\" , mtype = None ): ''' Declare a variable Parameters ---------- name : str Name of the variable shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable atype : str or AccessType Access type of the variable. It specifies whether (and how) the variable is an I/O variable of the function it belongs to. Defaults to \"input\" mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used ''' self . shape , self . dtype , self . atype , self . mtype = shape , dtype , atype , mtype","title":"__init__()"},{"location":"api/#freetensor.core.frontend.VarCreator","text":"Bases: StagedAssignable Source code in python/freetensor/core/frontend.py 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 @dataclass class VarCreator ( StagedAssignable ): shape : Union [ Sequence , VarRef ] dtype : str mtype : str assigned : bool = False def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' if not self . assigned : self . assigned = True return lang_overload . register_vardef ( name , self . shape , self . dtype , 'cache' , self . mtype ) else : raise lang_overload . error ( \"Create new tensors in an `a = b = c`-like multi-assignment \" \"is not supported\" )","title":"VarCreator"},{"location":"api/#freetensor.core.frontend.VarCreator.assign","text":"Customized assign behavior. Creates a VarDef with its full name. Source code in python/freetensor/core/frontend.py 244 245 246 247 248 249 250 251 252 253 def assign ( self , name : str ) -> VarRef : '''Customized assign behavior. Creates a VarDef with its full name.''' if not self . assigned : self . assigned = True return lang_overload . register_vardef ( name , self . shape , self . dtype , 'cache' , self . mtype ) else : raise lang_overload . error ( \"Create new tensors in an `a = b = c`-like multi-assignment \" \"is not supported\" )","title":"assign()"},{"location":"api/#freetensor.core.frontend.VersionMarker","text":"Bases: StagedAssignable Source code in python/freetensor/core/frontend.py 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 @dataclass class VersionMarker ( StagedAssignable ): var : VarRef assigned : bool = False def assign ( self , tape_name : str ) -> VarRef : '''Customized assign behavior. Creates a MarkVersion with its full name.''' if not self . assigned : self . assigned = True full_tape_name = lang_overload . fullname ( tape_name ) MarkVersion ( full_tape_name , self . var ) return VarVersionRef ( full_tape_name , self . var . full_shape , self . var . dtype , self . var . mtype , self . var . indices ) else : raise lang_overload . error ( \"Marking version in an `a = b = c`-like multi-assignment is not\" \" supported\" )","title":"VersionMarker"},{"location":"api/#freetensor.core.frontend.VersionMarker.assign","text":"Customized assign behavior. Creates a MarkVersion with its full name. Source code in python/freetensor/core/frontend.py 393 394 395 396 397 398 399 400 401 402 403 404 405 def assign ( self , tape_name : str ) -> VarRef : '''Customized assign behavior. Creates a MarkVersion with its full name.''' if not self . assigned : self . assigned = True full_tape_name = lang_overload . fullname ( tape_name ) MarkVersion ( full_tape_name , self . var ) return VarVersionRef ( full_tape_name , self . var . full_shape , self . var . dtype , self . var . mtype , self . var . indices ) else : raise lang_overload . error ( \"Marking version in an `a = b = c`-like multi-assignment is not\" \" supported\" )","title":"assign()"},{"location":"api/#freetensor.core.frontend.dynamic_range","text":"Bases: StagedIterable Dynamic range that generates For loop in IR tree. Source code in python/freetensor/core/frontend.py 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 class dynamic_range ( StagedIterable ): '''Dynamic range that generates For loop in IR tree.''' def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step def foreach ( self , name , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' if not isinstance ( name , str ): raise lang_overload . error ( 'dynamic_range only supports exactly one target variable' ) # Early optimizations if isinstance ( self . start , Number ) and isinstance ( self . stop , Number ) and isinstance ( self . step , Number ): if not range ( self . start , self . stop , self . step ): return if len ( range ( self . start , self . stop , self . step )) == 1 : with LifetimeScope (): body ( self . start ) return with lang_overload . allow_shortcut_scope ( False ): with For ( lang_overload . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var )","title":"dynamic_range"},{"location":"api/#freetensor.core.frontend.dynamic_range.__init__","text":"Initialize a dynamic range. Arguments semantic identical to builtin range . Source code in python/freetensor/core/frontend.py 482 483 484 485 486 487 488 489 490 491 def __init__ ( self , start , stop = None , step = 1 ) -> None : '''Initialize a dynamic range. Arguments semantic identical to builtin `range`.''' if stop : self . start = start self . stop = stop else : self . start = 0 self . stop = start self . step = step","title":"__init__()"},{"location":"api/#freetensor.core.frontend.dynamic_range.foreach","text":"Customized foreach behavior. Creates a For loop. Source code in python/freetensor/core/frontend.py 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 def foreach ( self , name , body : Callable [[ Any ], None ]) -> None : '''Customized foreach behavior. Creates a For loop.''' if not isinstance ( name , str ): raise lang_overload . error ( 'dynamic_range only supports exactly one target variable' ) # Early optimizations if isinstance ( self . start , Number ) and isinstance ( self . stop , Number ) and isinstance ( self . step , Number ): if not range ( self . start , self . stop , self . step ): return if len ( range ( self . start , self . stop , self . step )) == 1 : with LifetimeScope (): body ( self . start ) return with lang_overload . allow_shortcut_scope ( False ): with For ( lang_overload . fullname ( name ), self . start , self . stop , self . step ) as iter_var : with LifetimeScope (): body ( iter_var )","title":"foreach()"},{"location":"api/#freetensor.core.frontend.push_for_backward","text":"Push the current value from the forward pass to be used at the backward pass This function is for custom gradients. See UserGrad for details on how to provide custom gradients. You may imagine there is a virtual stack for each variable. Each time you call x_handle = push_for_backward(x) in the forward pass, the value of x at the current iteration will be \"pushed\" to the virtual stack. You can access x_handle at the backward pass. Each time you access x_handle , you will \"pop\" the stack and get the value of x pushed at the same iteration . Since the \"stack\" is virtual, you do NOT need to \"pop\" the same count as \"push\"es: the version numbering is fully automatic. Besides, there may not be a real stack at runtime: it can be compiled to any data structure. This function will be staged to mark_version statement in the IR. Source code in python/freetensor/core/frontend.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def push_for_backward ( var : VarRef ): ''' Push the current value from the forward pass to be used at the backward pass This function is for custom gradients. See `UserGrad` for details on how to provide custom gradients. You may imagine there is a virtual stack for each variable. Each time you call `x_handle = push_for_backward(x)` in the forward pass, the value of `x` **at the current iteration** will be \"pushed\" to the virtual stack. You can access `x_handle` at the backward pass. Each time you access `x_handle`, you will \"pop\" the stack and get the value of `x` **pushed at the same iteration**. Since the \"stack\" is virtual, you do NOT need to \"pop\" the same count as \"push\"es: the version numbering is fully automatic. Besides, there may not be a real stack at runtime: it can be compiled to any data structure. This function will be staged to `mark_version` statement in the IR. ''' return VersionMarker ( var )","title":"push_for_backward()"},{"location":"api/#freetensor.core.func","text":"","title":"func"},{"location":"api/#freetensor.core.func.Func","text":"Bases: ffi . Func Source code in python/freetensor/core/func.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class Func ( ffi . Func ): def __init__ ( self , name : str , params : Sequence [ FuncParam ], returns : Sequence [ FuncRet ], body : ffi . Stmt , extra_closure = {}, user_grads = []): super () . __init__ ( name , params , returns , body , extra_closure ) self . user_grads = user_grads # Mimic a Python function self . __name__ = name def __call__ ( self , * args , ** kvs ): ''' Enable invoking a transformed AST in another function being transformed, via `inlined_invoke` ''' if lang_overload . in_staging (): if len ( self . returns ) == 1 : names = ( self . name ,) else : names = tuple ( f \" { self . name } . { i } \" for i in range ( len ( self . returns ))) return lang_overload . register_inlined_invoke ( names , self , args , kvs ) else : raise lang_overload . error ( 'Unexpected call on a transformed AST. A transformed AST can only ' 'be called in the following two ways: 1) called with actual data ' 'after `@optimize`, and 2) called from another function to be ' '`@transform`ed' )","title":"Func"},{"location":"api/#freetensor.core.func.Func.__call__","text":"Enable invoking a transformed AST in another function being transformed, via inlined_invoke Source code in python/freetensor/core/func.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __call__ ( self , * args , ** kvs ): ''' Enable invoking a transformed AST in another function being transformed, via `inlined_invoke` ''' if lang_overload . in_staging (): if len ( self . returns ) == 1 : names = ( self . name ,) else : names = tuple ( f \" { self . name } . { i } \" for i in range ( len ( self . returns ))) return lang_overload . register_inlined_invoke ( names , self , args , kvs ) else : raise lang_overload . error ( 'Unexpected call on a transformed AST. A transformed AST can only ' 'be called in the following two ways: 1) called with actual data ' 'after `@optimize`, and 2) called from another function to be ' '`@transform`ed' )","title":"__call__()"},{"location":"api/#freetensor.core.optimize","text":"","title":"optimize"},{"location":"api/#freetensor.core.optimize.optimize","text":"An one-click optimization from Python function to binary executable Usage: @optimize def f(...): ... It is equivalent to: @build_binary @codegen @lower @transform def f(...): ... Parameters: Name Type Description Default func Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator None schedule_callback Callable ( Optional ) Schedule(s) to apply None target Target ( Optional ) The target architecture. You don't have to set target if you set device None device Device ( Optional ) Where to run the program None default_dynamic_range bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True True verbose int ( Optional ) Verbosity level. Can be 0, 1 or 2 None Source code in python/freetensor/core/optimize.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def optimize ( func = None , schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , target : Optional [ Target ] = None , device : Optional [ Device ] = None , default_dynamic_range : bool = True , verbose : Optional [ int ] = None ): ''' An one-click optimization from Python function to binary executable Usage: ``` @optimize def f(...): ... ``` It is equivalent to: ``` @build_binary @codegen @lower @transform def f(...): ... ``` Parameters ---------- func : Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator schedule_callback : Callable (Optional) Schedule(s) to apply target : Target (Optional) The target architecture. You don't have to set target if you set device device : Device (Optional) Where to run the program default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int (Optional) Verbosity level. Can be 0, 1 or 2 ''' if func is not None : if target is None and device is not None : target = device . target () if not issubclass ( type ( func ), ffi . AST ): ast = transform ( func , default_dynamic_range = default_dynamic_range , verbose = verbose ) else : ast = func ast = schedule ( ast , schedule_callback , verbose = verbose ) ast = lower ( ast , target , verbose = verbose ) code = codegen ( ast , target , verbose = verbose ) exe = build_binary ( code , device , verbose = verbose ) return exe else : return functools . partial ( optimize , schedule_callback = schedule_callback , target = target , device = device , default_dynamic_range = default_dynamic_range , verbose = verbose )","title":"optimize()"},{"location":"api/#freetensor.core.optimize.optimize_to_pytorch","text":"Compile a FreeTensor function to a PyTorch call, whose gradient can be recognized by PyTorch The compiled function will be a typical PyTorch's \"function\" (rather than a PyTorch's \"module\"). Technically, this means it is a wrapper function around a PyTorch's Function 's apply method Schedules (if any) must be applied to the forward function and the backward function separated. For this reason, currently only first-order gradient is supported Parameters: Name Type Description Default func Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator None tapes Union [ Sequence , GradTapeMode ] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a GradTapeMode , then it will determine which intermediate variables to be stored by heuristics. Avail GradTapeMode s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history GradTapeMode.NoReuseOnly forward_schedule_callback Callable ( Optional ) Schedule(s) to apply to the forward function None backward_schedule_callback Callable ( Optional ) Schedule(s) to apply to the backward function None target Target ( Optional ) The target architecture. You don't have to set target if you set device None device Device ( Optional ) Where to run the program None default_dynamic_range bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True True verbose int ( Optional ) Verbosity level. Can be 0, 1 or 2 None Source code in python/freetensor/core/optimize.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def optimize_to_pytorch ( func = None , tapes : Union [ Sequence , GradTapeMode ] = GradTapeMode . NoReuseOnly , forward_schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , backward_schedule_callback : Optional [ Callable [[ Schedule ], None ]] = None , target : Optional [ Target ] = None , device : Optional [ Device ] = None , default_dynamic_range : bool = True , verbose : Optional [ int ] = None ): ''' Compile a FreeTensor function to a PyTorch call, whose gradient can be recognized by PyTorch The compiled function will be a typical PyTorch's \"function\" (rather than a PyTorch's \"module\"). Technically, this means it is a wrapper function around a PyTorch's `Function`'s `apply` method Schedules (if any) must be applied to the forward function and the backward function separated. For this reason, currently only first-order gradient is supported Parameters ---------- func : Python function or AST The user function to optimize. If not specified, a partial function will be returend, which can be used as a decorator tapes : Union[Sequence, GradTapeMode] Intermediate variables that need to be stored from the forward pass and reused in the backward pass. This parameter can be a sequence, which contains VarDef selectors of them. It can also be a `GradTapeMode`, then it will determine which intermediate variables to be stored by heuristics. Avail `GradTapeMode`s are: All: store all variables including local scalars; None: store nothing; NoReuseOnly: store variables that only hold one version of data, which means we do not have to store each version of them in their history forward_schedule_callback : Callable (Optional) Schedule(s) to apply to the forward function backward_schedule_callback : Callable (Optional) Schedule(s) to apply to the backward function target : Target (Optional) The target architecture. You don't have to set target if you set device device : Device (Optional) Where to run the program default_dynamic_range : bool If True, the built-in range is replaced with freetensor.dynamic_range. Defaults to True verbose : int (Optional) Verbosity level. Can be 0, 1 or 2 ''' if func is not None : import torch # Transform from Python source to AST if not issubclass ( type ( func ), ffi . AST ): ast = transform ( func , default_dynamic_range = default_dynamic_range , verbose = verbose ) else : ast = func # Compile lazily because we know `requires` and `provides` only when # executing. Re-compile when gradient requirements changes saved_requires = set () saved_provides = set () cur_requires = None cur_provides = None fwd_exe = None bwd_exe = None input_grad_map = None output_grad_map = None tape_rets = None def lazy_compile (): nonlocal saved_requires , saved_provides , cur_requires , cur_provides nonlocal fwd_exe , bwd_exe , input_grad_map , output_grad_map , tape_rets if saved_requires == cur_requires and saved_provides == cur_provides : return saved_requires = cur_requires saved_provides = cur_provides if len ( cur_requires ) != 0 : fwd_ast , bwd_ast , input_grad_map , output_grad_map = grad ( ast , requires = saved_requires , provides = saved_provides , tapes = tapes , # PyTorch requires explicitly marking saved states via # `save_for_backward()` tape_in_closure = False , verbose = verbose ) tape_rets = fwd_ast . returns [ len ( ast . returns ):] fwd_exe = optimize ( fwd_ast , forward_schedule_callback , target , device , default_dynamic_range , verbose ) bwd_exe = optimize ( bwd_ast , backward_schedule_callback , target , device , default_dynamic_range , verbose ) else : # No one needs grad. No need to do autograd fwd_ast = ast fwd_exe = optimize ( fwd_ast , forward_schedule_callback , target , device , default_dynamic_range , verbose ) bwd_exe = None input_grad_map = {} output_grad_map = {} tape_rets = [] # Generate a PyTorch Function class GeneratedPyTorchFunction ( torch . autograd . Function ): @staticmethod def forward ( ctx , * args , ** kvs ): nonlocal cur_requires , cur_provides # We only get to know provided gradients of output tensors when we # run `backward`, but we need to run autograd and compile the program # here in `forward`. We can only assume gradients are provided for # every output tensors, even if they are unrelated to the inputs. # Setting this option to True makes PyTorch generate zero gradient # for such outputs. (TODO: better solution?) ctx . set_materialize_grads ( True ) # Gather required gradients of the inputs cur_requires = set () for param , arg in zip ( ast . params , args ): if arg . requires_grad : cur_requires . add ( param . name ) for key , value in kvs . items (): if value . requires_grad : cur_requires . add ( key ) # For the reason above, we assume gradients are provided for every # output tensors cur_provides = set () for ret in ast . returns : cur_provides . add ( ret . name ) lazy_compile () fwd_exe . set_args ( * args , ** kvs ) fwd_exe . run () returns = fwd_exe . collect_returns ( always_return_pack = True ) returns = tuple ( item . torch () for item in returns ) # Save states for 1) all inputs and 2) all taped tensors (taped # outputs are also taped tensors). For taped tensors, we need to # make them output tensors, so PyTorch can recognize them. This is # an officially recommanded trick at # https://pytorch.org/tutorials/intermediate/custom_function_double_backward_tutorial.html#saving-intermediate-results # So, please be aware that only the first part in `returns` are real # return tensors saved_tensors = [] for arg in args : # 1) saved_tensors . append ( arg ) for ret in returns : # 2) and maybe other junks saved_tensors . append ( ret ) ctx . save_for_backward ( * saved_tensors ) return returns [ 0 ] if len ( returns ) == 1 else returns @staticmethod @torch . autograd . function . once_differentiable def backward ( ctx , * args , ** kvs ): saved_tensors = ctx . saved_tensors internal_kvs = {} for ret , arg in zip ( ast . returns , args ): internal_kvs [ output_grad_map [ ret . name ]] = arg for key , value in kvs : internal_kvs [ output_grad_map [ key ]] = value for param , saved in zip ( ast . params , saved_tensors ): # NOTE: Now we only support \"input\" parameters for PyTorch # interface (no \"inout\" or \"output\"), so we can forward all # parameters. If we support \"inout\" or \"output\" in the future, # we need to filter only \"input\" parameters here internal_kvs [ param . name ] = saved for tape_ret , saved in zip ( tape_rets , saved_tensors [ len ( ast . params ) + len ( ast . returns ):]): internal_kvs [ tape_ret . name ] = saved bwd_exe . set_args ( ** internal_kvs ) bwd_exe . run () input_grads = bwd_exe . collect_returns ( always_return_pack = True ) # PyTorch requires returning gradient of inputs in their original # order. If no gradient is required for an input, set it to None returns = tuple ( input_grads [ input_grad_map [ param . name ]] . torch ( ) if param . name in input_grad_map else None for param in ast . params ) return returns [ 0 ] if len ( returns ) == 1 else returns # Wrap around the PyTorch `Function`, to be a real Python \"function\", and # remove our extra tape outputs def generatedPyTorchFunction ( * args , ** kvs ): returns = GeneratedPyTorchFunction . apply ( * args , ** kvs ) returns_tuple = returns if isinstance ( returns , Sequence ) else ( returns ,) returns_tuple = returns_tuple [: len ( ast . returns )] return returns_tuple [ 0 ] if len ( returns_tuple ) == 1 else returns_tuple # If called inside a FreeTensor funcion, don't care about PyTorch, just # inline the transformed AST return staged_callable ( ast , generatedPyTorchFunction ) else : return functools . partial ( optimize_to_pytorch , tapes = tapes , forward_schedule_callback = forward_schedule_callback , backward_schedule_callback = backward_schedule_callback , target = target , device = device , default_dynamic_range = default_dynamic_range , verbose = verbose )","title":"optimize_to_pytorch()"},{"location":"api/#freetensor.core.passes","text":"","title":"passes"},{"location":"api/#freetensor.core.passes.lower","text":"Lower an AST using a series of passes Parameters: Name Type Description Default ast AST The AST to be lowered. Can be a Func or a Stmt . If not specified, a partial function of lower will be returned, which can be used as a decorator None target Target ( Optional ) Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config None skip_passes Sequence [ str ]( Optional ) Skip some pass for testing or debugging. Names in skip_passes are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes None verbose int ( Optional ) 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes None Source code in python/freetensor/core/passes.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def lower ( ast = None , target : Optional [ ffi . Target ] = None , skip_passes : Optional [ Sequence [ str ]] = None , verbose : Optional [ int ] = None ): ''' Lower an AST using a series of passes Parameters ---------- ast : AST The AST to be lowered. Can be a `Func` or a `Stmt`. If not specified, a partial function of `lower` will be returned, which can be used as a decorator target : Target (Optional) Lower the AST to a target with target-specific passes, then the AST can be used for codegen. If not set, use the default Target in Config skip_passes : Sequence[str] (Optional) Skip some pass for testing or debugging. Names in `skip_passes` are in underscore_style, as in Python. Please note that some passes will not be skipped even specified in these parameter, because they are indirectly called in some other passes verbose : int (Optional) 0 = print nothing. 1 = print the lowered AST. 2 = print AST after every single passes ''' if ast is not None : return ffi . lower ( ast , target , set () if skip_passes is None else set ( skip_passes ), 0 if verbose is None else verbose ) else : _lower = lower if target is not None : _lower = functools . partial ( _lower , target = target ) if skip_passes is not None : _lower = functools . partial ( _lower , skip_passes = skip_passes ) if verbose is not None : _lower = functools . partial ( _lower , verbose = verbose ) return _lower","title":"lower()"},{"location":"api/#freetensor.core.staging","text":"A staging framework to support the FreeTensor frontend.","title":"staging"},{"location":"api/#freetensor.core.staging.AllowShortcutScope","text":"Allow return scope. This is a context manager that allows return in statically deterministic control flow. Source code in python/freetensor/core/staging.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 @dataclass class AllowShortcutScope : '''Allow return scope. This is a context manager that allows return in statically deterministic control flow. ''' overload : StagingOverload should_allow : bool def __enter__ ( self ): self . prev = self . overload . is_shortcut_allowed self . overload . is_shortcut_allowed = self . should_allow def __exit__ ( self , exc_class , exc_value , traceback ): self . overload . is_shortcut_allowed = self . prev","title":"AllowShortcutScope"},{"location":"api/#freetensor.core.staging.BreakException","text":"Bases: Exception Exception to be raised by StagingOverload.break_stmt. Breaks from a for loop. Source code in python/freetensor/core/staging.py 68 69 70 71 class BreakException ( Exception ): '''Exception to be raised by StagingOverload.break_stmt. Breaks from a for loop.''' pass","title":"BreakException"},{"location":"api/#freetensor.core.staging.ContinueException","text":"Bases: Exception Exception to be raised by StagingOverload.continue_stmt. Continues a for loop. Source code in python/freetensor/core/staging.py 74 75 76 77 class ContinueException ( Exception ): '''Exception to be raised by StagingOverload.continue_stmt. Continues a for loop.''' pass","title":"ContinueException"},{"location":"api/#freetensor.core.staging.ReturnException","text":"Bases: Exception Exception to be raised by StagingOverload.return_stmt. Holds a return value that will be passed through to the function wrapper. Source code in python/freetensor/core/staging.py 60 61 62 63 64 65 class ReturnException ( Exception ): '''Exception to be raised by StagingOverload.return_stmt. Holds a return value that will be passed through to the function wrapper.''' def __init__ ( self , value : Any ) -> None : self . value = value","title":"ReturnException"},{"location":"api/#freetensor.core.staging.StagingError","text":"Bases: Exception Error occurred during staging function execution (i.e. IR tree generation). Source code in python/freetensor/core/staging.py 33 34 35 36 37 38 39 40 class StagingError ( Exception ): '''Error occurred during staging function execution (i.e. IR tree generation).''' def __init__ ( self , overload : StagingOverload , message : str ) -> None : # TODO: add output of StagingContext.call_stack super () . __init__ ( f ' { message } : \\n { \"\" . join ( traceback . format_list ( overload . debug_call_stack )) } ' . lstrip ())","title":"StagingError"},{"location":"api/#freetensor.core.staging.StagingOverload","text":"Source code in python/freetensor/core/staging.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 class StagingOverload : def __init__ ( self ) -> None : self . is_shortcut_allowed : bool = True self . debug_call_stack : List [ traceback . FrameSummary ] = [] def custom_attr ( self , obj : Any , attr : str ) -> Any : ''' Customized attribute accessor. The framework first looks for a Python native attribute. If not found, it looks for this overloaded custom attribute resolver. The default implementation provides no custom attribute. Can be overridden by subclasses. Parameters ---------- obj : Any Object to access attribute. attr : str Attribute name. Returns ------- Any : The attribute value. Throws ------ AttributeError : If the attribute is not found. ''' return None def metadata ( self , content ) -> None : ''' Metadata handler. A metadata line is a comment starting with `#! ` and followed by a metadata, represented as a string parameter. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- content : str The metadata content. ''' pass def at_position ( self , filename : str , lineno : int ) -> None : ''' Code position handler. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- filename : str Name of the file containing code for the next statement. lineno : int Line number of the next statement. ''' pass def error ( self , content : str ): return StagingError ( self , content ) def allow_shortcut_scope ( self , allow : bool ): '''Opens a scope that allows shortcut control flows in a statically deterministic context. Need to be closed by `with` statement.''' return AllowShortcutScope ( self , allow ) def foreach ( self , names , iter , body : Callable [[ Any ], None ]) -> None : '''Customized foreach wrapper. If `value` is instance of `StagedIterable`, its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. ''' if isinstance ( iter , StagedIterable ): iter . foreach ( names , body ) else : for iter_var in iter : try : body ( iter_var ) except BreakException : break except ContinueException : continue def unpack_assign_stmt ( self , names , values ): '''Customized assign wrapper for one or more targets. If `values` is instance of `StagedUnpackAssignable`, it's regarded as a customized assign behavior and gets executed with all the assigned targets' names. Otherwise, it calls `assign_stmt` with each sub-assignments. Please note that `names` can be nested tuples like `(\"a\", (\"b\", \"c\"))`. Please also note that `names` can also be a single string like \"a\" even if `values` is a tuple. There is no unpacking in this case ''' if isinstance ( values , StagedUnpackAssignable ): return values . assign ( names ) elif isinstance ( names , str ): return self . assign_stmt ( names , values ) else : assert isinstance ( names , Sequence ) values = tuple ( values ) if len ( names ) != len ( values ): raise self . error ( \"Number of return values does not match when unpacking\" ) returns = [] for name , value in zip ( names , values ): returns . append ( self . unpack_assign_stmt ( name , value )) return tuple ( returns ) def assign_stmt ( self , name : str , value ): '''Customized assign wrapper. If `value` is instance of `StagedAssignable`, it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. ''' if isinstance ( value , StagedAssignable ): return value . assign ( name ) else : return value def if_then_else_stmt ( self , predicate , then_body , else_body = None ): '''If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. ''' if isinstance ( predicate , StagedPredicate ): predicate . if_then_else_stmt ( then_body , else_body ) else : if predicate : then_body () elif else_body : else_body () def if_then_else_expr ( self , predicate , then_expr , else_expr ): '''If-then-else expression staging tool.''' if isinstance ( predicate , StagedPredicate ): return predicate . if_then_else_expr ( then_expr , else_expr ) else : if predicate : return then_expr () else : return else_expr () def while_stmt ( self , fpred , body ): '''While statement staging tool.''' first_pred = fpred () if isinstance ( first_pred , StagedPredicate ): first_pred . while_stmt ( body ) else : if first_pred : try : body () except BreakException : return except ContinueException : pass while fpred (): try : body () except BreakException : break except ContinueException : continue def assert_stmt ( self , test ): '''Assert staging tool.''' if isinstance ( test , StagedPredicate ): test . assert_stmt () else : assert test def return_stmt ( self , value , funcname ): '''Return staging tool. Only allow return in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Return is only allowed in statically deterministic control flow.' ) if isinstance ( value , StagedUnpackAssignable ): # We don't know how many items are there, so no unpacking value = value . assign ( funcname ) if isinstance ( value , StagedAssignable ): value = value . assign ( funcname ) raise ReturnException ( value ) def break_stmt ( self ): '''Break staging tool. Only allow break in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Break is only allowed in statically deterministic control flow.' ) raise BreakException () def continue_stmt ( self ): '''Continue staging tool. Only allow continue in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Continue is only allowed in statically deterministic control flow.' ) raise ContinueException () def load_attr ( self , obj , attr : str ): '''Load attribute staging tool. Allows customization of reading attributes.''' try : return getattr ( obj , attr ) except AttributeError : try : # Have to use AttributeError again, since a custom attribute might have # a None value result = self . custom_attr ( obj , attr ) successful = True except AttributeError : successful = False if successful : return result else : raise def and_expr ( self , * lazy_args ): def reducer ( a , fb ): if isinstance ( a , StagedPredicate ): return a . logical_and ( fb ) else : # This is not a simple logical and; it's equivalent to a if-then-else. # Thus, if a is True, fb() is returned, preserving the original value, # which might be a StagedPredicate. return a and fb () return functools . reduce ( reducer , lazy_args , True ) def or_expr ( self , * lazy_args ): def reducer ( a , fb ): if isinstance ( a , StagedPredicate ): return a . logical_or ( fb ) else : return a or fb () return functools . reduce ( reducer , lazy_args , False ) def not_expr ( self , arg ): if isinstance ( arg , StagedPredicate ): return arg . logical_not () else : return not arg def functiondef_decorator ( self , filename ): return functools . partial ( self . functiondef_wrapper , filename ) def functiondef_wrapper ( self , filename , func ): '''Function definition wrapper. This wrapper performs extra initialization and cleanup for function definition. ''' def wrapped ( * args , ** kwargs ): # Push debug call stack with some random line number. # It will be updated by `mark_position` calls in the function. self . debug_call_stack . append ( traceback . FrameSummary ( filename , 1 , func . __name__ )) # The called function can now return from itself, despite what the outer # control flow is. with self . allow_shortcut_scope ( True ): try : func ( * args , ** kwargs ) except ReturnException as e : result = e . value else : # No return_stmt was called, naturally returns None result = None # Pop debug call stack. self . debug_call_stack . pop () return result return wrapped def annotate_stmt ( self , name : str , ty ): if isinstance ( ty , StagedTypeAnnotation ): return ty . annotate ( name ) return None def mark_position ( self , lineno : int ): # FrameSummary is immutable, so we have to initialize a new one with updated # line number. self . debug_call_stack [ - 1 ] = traceback . FrameSummary ( self . debug_call_stack [ - 1 ] . filename , lineno , self . debug_call_stack [ - 1 ] . name ) self . at_position ( self . debug_call_stack [ - 1 ] . filename , self . debug_call_stack [ - 1 ] . lineno ) def into_staging ( self , func , extra_locals : Dict [ str , Any ] = None , src : str = None , verbose = False ): assert inspect . isfunction ( func ) if extra_locals is None : extra_locals = {} if src is None : lines , lineno = ins . getsourcelines ( func ) src = '' . join ( lines ) file = ins . getfile ( func ) else : lineno = 1 file = f '<staging: { func . __name__ } >' # Inject overload to extra_locals. extra_locals [ '__staging_overload__' ] = self # To transform a function, except essential AST transformation, we have to pass # the globals and locals (actually captured outer local variables) to the # transformed function properly. # Note that: # 1. We have to pass both globals and locals to `exec`. # 2. We cannot insert locals to the globals `dict`, otherwise it will pollute # the globals `dict`. # 3. We cannot copy the globals `dict` before passing it to exec, otherwise the # staged function cannot write to globals and get later updates in the global. # Thus, we have to pass the globals and locals to the transformed function # separately. if func . __closure__ : assert len ( func . __code__ . co_freevars ) == len ( func . __closure__ ) func_locals = { name : cell for name , cell in zip ( func . __code__ . co_freevars , func . __closure__ ) } else : func_locals = {} # Translate `#! ` comments to metadata calls. src = process_annotating_comments ( src ) # Wrap the code if it has a indentation. if src [ 0 ] == ' ' or src [ 0 ] == ' \\t ' : src = 'if True: \\n ' + src tree = ast . parse ( src ) assert len ( tree . body ) == 1 and isinstance ( tree . body [ 0 ], ast . If ) # Replace with the real body to eliminate the faked if. tree . body = tree . body [ 0 ] . body # Modify lineno to match with the location. lineno -= 1 else : tree = ast . parse ( src ) # Replace the annotations with __staging_annotations__ assert isinstance ( tree , ast . Module ) and isinstance ( tree . body [ - 1 ], ast . FunctionDef ) tree . body [ - 1 ] . args = ReplaceAnnotations ( func . __annotations__ . keys ()) . visit ( tree . body [ 0 ] . args ) tree = Transformer ( file , lineno ) . visit ( tree ) # Instead of passing the `func_local` directly to `exec`, we instead wrap the # staging function. This is to workaround an issue of CPython. (See # https://github.com/python/cpython/issues/86084). # The sketch is: # ``` # def __freetensor_staging_wrapper__(__freetensor_extra_locals__, # __freetensor_local_cells__): # some_extra_local = __freetensor_extra_locals__['some_extra_local'] # some_captured = None # # def original_func(): # nonlocal some_captured # some_captured = __freetensor_local_cells__.some_captured # try: # ... # original function body # finally: # __freetensor_local_cells__.some_captured = some_captured # # return original_func # ``` # Note that `__freetensor_local_cells__` is a `LocalsDictWrapper` object. # It in-turn accesses cell.cell_contents to get/set the value of the local # variable. # The `LocalsDictWrapper` is a helper class to reduce code generation complexity. WRAPPER_NAME = '__freetensor_staging_wrapper__' assert isinstance ( tree , ast . Module ) and isinstance ( tree . body [ - 1 ], ast . FunctionDef ) # Modify function body. if len ( func_locals ) > 0 : tree . body [ - 1 ] . body = ([ # Declare them as nonlocals to assign to outer scope. ast . Nonlocal ( list ( func_locals . keys ())), ] + [ # Fetch latest values of the closure variables. ast . Assign ([ ast . Name ( name , ast . Store ())], ast . Attribute ( ast . Name ( '__freetensor_local_cells__' , ast . Load ()), name , ast . Load ())) for name in func_locals . keys () ] + [ # Use a try-finally to ensure closure write back. ast . Try ( body = tree . body [ - 1 ] . body , handlers = [], orelse = [], finalbody = [ ast . Assign ([ ast . Attribute ( ast . Name ( '__freetensor_local_cells__' , ast . Load ()), name , ast . Store ()) ], ast . Name ( name , ast . Load ())) for name in func_locals . keys () ]) ]) tree . body = [ ast . FunctionDef ( name = WRAPPER_NAME , args = ast . arguments ( posonlyargs = [], args = [ ast . arg ( '__freetensor_extra_locals__' , None ), ast . arg ( '__freetensor_local_cells__' , None ), ast . arg ( '__staging_annotations__' , None ), ], vararg = None , kwonlyargs = [], kw_defaults = [], kwarg = None , defaults = []), body = [ # Captured closure variables are not fetched here, only declared. ast . Assign ([ ast . Name ( name , ast . Store ())], ast . Constant ( None )) for name in func_locals . keys () ] + [ # Extra locals are fetched here. ast . Assign ([ ast . Name ( name , ast . Store ())], ast . Subscript ( ast . Name ( '__freetensor_extra_locals__' , ast . Load ()), ast_index ( ast . Constant ( name )), ast . Load ())) for name in extra_locals . keys () ] + tree . body + [ ast . Return ( value = ast . Name ( id = func . __name__ , ctx = ast . Load ()))], decorator_list = [], returns = None ), ] tree = ast . fix_missing_locations ( tree ) if verbose : import astor source = astor . to_source ( tree ) if config . pretty_print (): from pygments import highlight from pygments.lexers import PythonLexer from pygments.formatters import TerminalFormatter print ( highlight ( source , PythonLexer (), TerminalFormatter ( bg = 'dark' , linenos = True )), file = sys . stderr ) else : print ( source ) tree = source # make debug info match dumped source # Create an empty locals dict to avoid polluting the original globals. empty_locals = {} exec ( compile ( tree , f '<staging: { func . __name__ } >' , 'exec' ), func . __globals__ , empty_locals ) f_wrapper = empty_locals [ WRAPPER_NAME ] # Pass the closure to the wrapper and retrieve the staging function with # correct captured variables. f_staging = f_wrapper ( extra_locals , LocalsDictWrapper ( func_locals ), func . __annotations__ ) return f_staging","title":"StagingOverload"},{"location":"api/#freetensor.core.staging.StagingOverload.allow_shortcut_scope","text":"Opens a scope that allows shortcut control flows in a statically deterministic context. Need to be closed by with statement. Source code in python/freetensor/core/staging.py 184 185 186 187 def allow_shortcut_scope ( self , allow : bool ): '''Opens a scope that allows shortcut control flows in a statically deterministic context. Need to be closed by `with` statement.''' return AllowShortcutScope ( self , allow )","title":"allow_shortcut_scope()"},{"location":"api/#freetensor.core.staging.StagingOverload.assert_stmt","text":"Assert staging tool. Source code in python/freetensor/core/staging.py 288 289 290 291 292 293 def assert_stmt ( self , test ): '''Assert staging tool.''' if isinstance ( test , StagedPredicate ): test . assert_stmt () else : assert test","title":"assert_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.assign_stmt","text":"Customized assign wrapper. If value is instance of StagedAssignable , it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. Source code in python/freetensor/core/staging.py 233 234 235 236 237 238 239 240 241 242 def assign_stmt ( self , name : str , value ): '''Customized assign wrapper. If `value` is instance of `StagedAssignable`, it's regarded as a customized assign behavior and gets executed with the assigned target variable name. This wrapper is used for initializing a variable. ''' if isinstance ( value , StagedAssignable ): return value . assign ( name ) else : return value","title":"assign_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.at_position","text":"Code position handler. Defaults to a no-op. Can be overridden by subclasses. Parameters: Name Type Description Default filename str Name of the file containing code for the next statement. required lineno int Line number of the next statement. required Source code in python/freetensor/core/staging.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def at_position ( self , filename : str , lineno : int ) -> None : ''' Code position handler. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- filename : str Name of the file containing code for the next statement. lineno : int Line number of the next statement. ''' pass","title":"at_position()"},{"location":"api/#freetensor.core.staging.StagingOverload.break_stmt","text":"Break staging tool. Only allow break in static control flow. Source code in python/freetensor/core/staging.py 308 309 310 311 312 313 314 def break_stmt ( self ): '''Break staging tool. Only allow break in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Break is only allowed in statically deterministic control flow.' ) raise BreakException ()","title":"break_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.continue_stmt","text":"Continue staging tool. Only allow continue in static control flow. Source code in python/freetensor/core/staging.py 316 317 318 319 320 321 322 def continue_stmt ( self ): '''Continue staging tool. Only allow continue in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Continue is only allowed in statically deterministic control flow.' ) raise ContinueException ()","title":"continue_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.custom_attr","text":"Customized attribute accessor. The framework first looks for a Python native attribute. If not found, it looks for this overloaded custom attribute resolver. The default implementation provides no custom attribute. Can be overridden by subclasses. Parameters: Name Type Description Default obj Any Object to access attribute. required attr str Attribute name. required Returns: Name Type Description Any Any The attribute value.","title":"custom_attr()"},{"location":"api/#freetensor.core.staging.StagingOverload.foreach","text":"Customized foreach wrapper. If value is instance of StagedIterable , its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. Source code in python/freetensor/core/staging.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def foreach ( self , names , iter , body : Callable [[ Any ], None ]) -> None : '''Customized foreach wrapper. If `value` is instance of `StagedIterable`, its regarded as a customized foreach behavior and used to generate code for the python for loop. Otherwise, we try to execute the loop as usual. ''' if isinstance ( iter , StagedIterable ): iter . foreach ( names , body ) else : for iter_var in iter : try : body ( iter_var ) except BreakException : break except ContinueException : continue","title":"foreach()"},{"location":"api/#freetensor.core.staging.StagingOverload.functiondef_wrapper","text":"Function definition wrapper. This wrapper performs extra initialization and cleanup for function definition. Source code in python/freetensor/core/staging.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def functiondef_wrapper ( self , filename , func ): '''Function definition wrapper. This wrapper performs extra initialization and cleanup for function definition. ''' def wrapped ( * args , ** kwargs ): # Push debug call stack with some random line number. # It will be updated by `mark_position` calls in the function. self . debug_call_stack . append ( traceback . FrameSummary ( filename , 1 , func . __name__ )) # The called function can now return from itself, despite what the outer # control flow is. with self . allow_shortcut_scope ( True ): try : func ( * args , ** kwargs ) except ReturnException as e : result = e . value else : # No return_stmt was called, naturally returns None result = None # Pop debug call stack. self . debug_call_stack . pop () return result return wrapped","title":"functiondef_wrapper()"},{"location":"api/#freetensor.core.staging.StagingOverload.if_then_else_expr","text":"If-then-else expression staging tool. Source code in python/freetensor/core/staging.py 257 258 259 260 261 262 263 264 265 def if_then_else_expr ( self , predicate , then_expr , else_expr ): '''If-then-else expression staging tool.''' if isinstance ( predicate , StagedPredicate ): return predicate . if_then_else_expr ( then_expr , else_expr ) else : if predicate : return then_expr () else : return else_expr ()","title":"if_then_else_expr()"},{"location":"api/#freetensor.core.staging.StagingOverload.if_then_else_stmt","text":"If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. Source code in python/freetensor/core/staging.py 244 245 246 247 248 249 250 251 252 253 254 255 def if_then_else_stmt ( self , predicate , then_body , else_body = None ): '''If-then-else statement staging tool. When predicate is deterministic in staging, only one branch is generated. Otherwise, a If node in IR is generated. ''' if isinstance ( predicate , StagedPredicate ): predicate . if_then_else_stmt ( then_body , else_body ) else : if predicate : then_body () elif else_body : else_body ()","title":"if_then_else_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.load_attr","text":"Load attribute staging tool. Allows customization of reading attributes. Source code in python/freetensor/core/staging.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 def load_attr ( self , obj , attr : str ): '''Load attribute staging tool. Allows customization of reading attributes.''' try : return getattr ( obj , attr ) except AttributeError : try : # Have to use AttributeError again, since a custom attribute might have # a None value result = self . custom_attr ( obj , attr ) successful = True except AttributeError : successful = False if successful : return result else : raise","title":"load_attr()"},{"location":"api/#freetensor.core.staging.StagingOverload.metadata","text":"Metadata handler. A metadata line is a comment starting with #! and followed by a metadata, represented as a string parameter. Defaults to a no-op. Can be overridden by subclasses. Parameters: Name Type Description Default content str The metadata content. required Source code in python/freetensor/core/staging.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def metadata ( self , content ) -> None : ''' Metadata handler. A metadata line is a comment starting with `#! ` and followed by a metadata, represented as a string parameter. Defaults to a no-op. Can be overridden by subclasses. Parameters ---------- content : str The metadata content. ''' pass","title":"metadata()"},{"location":"api/#freetensor.core.staging.StagingOverload.return_stmt","text":"Return staging tool. Only allow return in static control flow. Source code in python/freetensor/core/staging.py 295 296 297 298 299 300 301 302 303 304 305 306 def return_stmt ( self , value , funcname ): '''Return staging tool. Only allow return in static control flow.''' if not self . is_shortcut_allowed : raise self . error ( 'Return is only allowed in statically deterministic control flow.' ) if isinstance ( value , StagedUnpackAssignable ): # We don't know how many items are there, so no unpacking value = value . assign ( funcname ) if isinstance ( value , StagedAssignable ): value = value . assign ( funcname ) raise ReturnException ( value )","title":"return_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.unpack_assign_stmt","text":"Customized assign wrapper for one or more targets. If values is instance of StagedUnpackAssignable , it's regarded as a customized assign behavior and gets executed with all the assigned targets' names. Otherwise, it calls assign_stmt with each sub-assignments. Please note that names can be nested tuples like (\"a\", (\"b\", \"c\")) . Please also note that names can also be a single string like \"a\" even if values is a tuple. There is no unpacking in this case Source code in python/freetensor/core/staging.py 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 def unpack_assign_stmt ( self , names , values ): '''Customized assign wrapper for one or more targets. If `values` is instance of `StagedUnpackAssignable`, it's regarded as a customized assign behavior and gets executed with all the assigned targets' names. Otherwise, it calls `assign_stmt` with each sub-assignments. Please note that `names` can be nested tuples like `(\"a\", (\"b\", \"c\"))`. Please also note that `names` can also be a single string like \"a\" even if `values` is a tuple. There is no unpacking in this case ''' if isinstance ( values , StagedUnpackAssignable ): return values . assign ( names ) elif isinstance ( names , str ): return self . assign_stmt ( names , values ) else : assert isinstance ( names , Sequence ) values = tuple ( values ) if len ( names ) != len ( values ): raise self . error ( \"Number of return values does not match when unpacking\" ) returns = [] for name , value in zip ( names , values ): returns . append ( self . unpack_assign_stmt ( name , value )) return tuple ( returns )","title":"unpack_assign_stmt()"},{"location":"api/#freetensor.core.staging.StagingOverload.while_stmt","text":"While statement staging tool. Source code in python/freetensor/core/staging.py 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 def while_stmt ( self , fpred , body ): '''While statement staging tool.''' first_pred = fpred () if isinstance ( first_pred , StagedPredicate ): first_pred . while_stmt ( body ) else : if first_pred : try : body () except BreakException : return except ContinueException : pass while fpred (): try : body () except BreakException : break except ContinueException : continue","title":"while_stmt()"},{"location":"api/#freetensor.core.staging.TransformError","text":"Bases: Exception Error occurred during AST transforming from python function to staging function that generates IR tree. Source code in python/freetensor/core/staging.py 23 24 25 26 27 28 29 30 class TransformError ( Exception ): '''Error occurred during AST transforming from python function to staging function that generates IR tree.''' def __init__ ( self , message : str , filename : str , base_lineno : int , error_node : ast . AST ) -> None : super () . __init__ ( f 'At { filename } : { base_lineno + error_node . lineno } : \\n { message } .' )","title":"TransformError"},{"location":"api/#freetensor.core.staging.Transformer","text":"Bases: ast . NodeTransformer Source code in python/freetensor/core/staging.py 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 @dataclass class Transformer ( ast . NodeTransformer ): filename : str base_lineno : int curr_func : str = None nonlocals : List [ List [ str ]] = None def visit ( self , node : ast . AST ): new_node = super () . visit ( node ) if isinstance ( node , ast . stmt ) and not isinstance ( node , ast . FunctionDef ): if not isinstance ( new_node , list ): new_node = [ new_node ] return [ ast . Expr ( call_helper ( StagingOverload . mark_position , ast . Constant ( self . base_lineno + node . lineno - 1 ))) ] + new_node return new_node def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = unpack_assign_stmt('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = unpack_assign_stmt('lhs', rhs)` `a, (b, c) = (x, (y, z))` -> `a, (b, c) = unpack_assign_stmt(('a', ('b', 'c')), (x, (y, z)))` `a = b = c` -> `a = unpack_assign_stmt('a', c); b = unpack_assign_stmt('b', c)` If `unpack_assign_stmt` is not overloaded, `assign_stmt` will be called for each item ''' node : ast . Assign = self . generic_visit ( old_node ) class UnoverloadableExcept ( BaseException ): pass def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) elif isinstance ( target , ast . Attribute ): return ast . Constant ( target . attr ) elif isinstance ( target , ast . Tuple ): # Unpacking: (a, b) = c l = [] for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) else : raise UnoverloadableExcept () def do_visit_assign ( targets ): try : names = recursive_get_names ( targets ) return ast . Assign ([ targets ], call_helper ( StagingOverload . unpack_assign_stmt , names , node . value )) except UnoverloadableExcept : return ast . Assign ([ targets ], node . value ) # If there are more than one item in `node.targets`, it means multiple # assignments like `a = b = c`. For unpacking like `(a, b) = c`, it # is represented as one tuple as a target item new_nodes = [] for target in node . targets : new_nodes . append ( do_visit_assign ( target )) return new_nodes def handleType_AnnAssign ( self , node : ast . AnnAssign ) -> Any : x = node . target assert isinstance ( x , ast . Name ) assert node . value is None x_str = ast . Constant ( x . id ) Ty = node . annotation intermediate = f 'freetensor__annotate__ { x . id } ' intermediate_store = ast . Name ( intermediate , ast . Store ()) intermediate_load = ast . Name ( intermediate , ast . Load ()) node = [ ast . Assign ([ intermediate_store ], call_helper ( StagingOverload . annotate_stmt , x_str , Ty )), ast . If ( intermediate_load , [ ast . Assign ([ x ], intermediate_load )], []) ] return node def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # While opening a fake function, For loops initiates an iter name as # well. Need to remove it from the outer nonlocals list to implement # shadowing. Only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) def recursive_remove_id ( target ): if isinstance ( target , ast . Name ): if target . id in nonlocals : nonlocals . remove ( target . id ) else : assert isinstance ( target , ast . Tuple ) for t in target . elts : recursive_remove_id ( t ) recursive_remove_id ( old_node . target ) nonlocals = list ( nonlocals ) def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) else : l = [] assert isinstance ( target , ast . Tuple ) for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) target_names = recursive_get_names ( old_node . target ) node : ast . For = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ '__item__' ], [ ast . Assign ([ node . target ], ast . Name ( '__item__' , ast . Load ())) ] + node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . foreach , target_names , node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return node def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . while_stmt , ast . Lambda ( _EMPTY_ARGS , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return node def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( StagingOverload . if_then_else_stmt , test , then_body , else_body ))) return new_node def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( StagingOverload . if_then_else_expr , node . test , ast . Lambda ( _EMPTY_ARGS , node . body ), ast . Lambda ( _EMPTY_ARGS , node . orelse )) return node def visit_FunctionDef ( self , old_node : ast . FunctionDef ) -> Any : prev_func = self . curr_func self . curr_func = old_node . name # nested functions follow original Python (shitty) scoping, # thus backup the nonlocals stack and prepare a clean one. prev_nonlocals = self . nonlocals self . nonlocals = None with NonlocalTransformingScope ( self ): # mark arguments as nonlocal for name in old_node . args . args + old_node . args . kwonlyargs : self . nonlocals [ - 1 ] . append ( name . arg ) if old_node . args . vararg : self . nonlocals [ - 1 ] . append ( old_node . args . vararg . arg ) if old_node . args . kwarg : self . nonlocals [ - 1 ] . append ( old_node . args . kwarg . arg ) # Transform the function body node : ast . FunctionDef = self . generic_visit ( old_node ) # Cleanup the decorators node . decorator_list = [ call_helper ( StagingOverload . functiondef_decorator , ast . Constant ( self . filename )) ] annotations_dict_name = f '__staging_annotations__ { node . name } __' # Handle the type annotations node . body = [ stmt for arg in node . args . posonlyargs + node . args . args if arg . annotation for stmt in self . handleType_AnnAssign ( ast . AnnAssign ( ast . Name ( arg . arg , ast . Store ()), ast . Subscript ( ast . Name ( annotations_dict_name , ast . Load ()), ast . Constant ( arg . arg ), ast . Load ()), None , 1 )) ] + node . body annotations_dict = {} # Cleanup annotations; we don't need them any more for arg in [ node . args . vararg , node . args . kwarg ] + node . args . posonlyargs + node . args . args + node . args . kwonlyargs : if arg is not None and arg . annotation is not None : annotations_dict [ arg . arg ] = arg . annotation arg . annotation = None # Write the annotations_dict node = [ ast . Assign ( [ ast . Name ( annotations_dict_name , ast . Store ())], ast . Dict ([ ast . Constant ( k ) for k in annotations_dict . keys ()], list ( annotations_dict . values ()))), node ] self . curr_func = prev_func self . nonlocals = prev_nonlocals return node def visit_Assert ( self , old_node : ast . Assert ) -> Any : node : ast . Assert = self . generic_visit ( old_node ) node = ast . Expr ( call_helper ( StagingOverload . assert_stmt , node . test )) return node def visit_BoolOp ( self , old_node : ast . BoolOp ) -> Any : node : ast . BoolOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . And ): libfunc = StagingOverload . and_expr elif isinstance ( node . op , ast . Or ): libfunc = StagingOverload . or_expr else : return node node = call_helper ( libfunc , * [ ast . Lambda ( _EMPTY_ARGS , v ) for v in node . values ]) return node def visit_UnaryOp ( self , old_node : ast . UnaryOp ) -> Any : node : ast . UnaryOp = self . generic_visit ( old_node ) if isinstance ( node . op , ast . Not ): node = call_helper ( StagingOverload . not_expr , node . operand ) return node def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( node ) def visit_Attribute ( self , old_node : ast . Attribute ) -> Any : node : ast . Attribute = self . generic_visit ( old_node ) if isinstance ( node . ctx , ast . Load ): if not ( isinstance ( node . value , ast . Name ) and node . value . id == '__staging_overload__' ): node = call_helper ( StagingOverload . load_attr , node . value , ast . Constant ( node . attr )) return node def visit_Return ( self , old_node : ast . Return ) -> Any : node : ast . Return = self . generic_visit ( old_node ) assert self . curr_func is not None node = ast . Expr ( call_helper ( StagingOverload . return_stmt , node . value , ast . Constant ( self . curr_func ))) return node def visit_Lambda ( self , old_node : ast . Lambda ) -> Any : with NonlocalTransformingScope ( self ): node : ast . Lambda = self . generic_visit ( old_node ) return node def visit_comprehension ( self , old_node : ast . comprehension ) -> Any : with NonlocalTransformingScope ( self ): node : ast . comprehension = self . generic_visit ( old_node ) return node def visit_Name ( self , node : ast . Name ) -> Any : if isinstance ( node . ctx , ast . Store ): self . nonlocals [ - 1 ] . append ( node . id ) return self . generic_visit ( node ) def visit_AsyncFunctionDef ( self , node : ast . AsyncFunctionDef ) -> Any : raise TransformError ( 'Async functions not supported.' , self . filename , self . base_lineno , node ) def visit_ClassDef ( self , node : ast . ClassDef ) -> Any : raise TransformError ( 'Class definitions not supported.' , self . filename , self . base_lineno , node ) def visit_Yield ( self , node : ast . Yield ) -> Any : raise NotImplementedError () def visit_YieldFrom ( self , node : ast . YieldFrom ) -> Any : raise NotImplementedError () def visit_Break ( self , node : ast . Break ) -> Any : return ast . Expr ( call_helper ( StagingOverload . break_stmt )) def visit_Continue ( self , node : ast . Continue ) -> Any : return ast . Expr ( call_helper ( StagingOverload . continue_stmt )) def visit_With ( self , node : ast . With ) -> Any : def recursive_get_names ( target ): if isinstance ( target , ast . Name ): self . nonlocals [ - 1 ] . append ( target . id ) elif isinstance ( target , ast . Tuple ) or isinstance ( target , ast . List ): for t in target . elts : recursive_get_names ( t ) else : assert False for item in node . items : if item . optional_vars is not None : recursive_get_names ( item . optional_vars ) return self . generic_visit ( node )","title":"Transformer"},{"location":"api/#freetensor.core.staging.Transformer.visit_AnnAssign","text":"Rule: x: Ty -> freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x : pure annotation Source code in python/freetensor/core/staging.py 803 804 805 806 807 808 809 810 811 812 813 814 def visit_AnnAssign ( self , old_node : ast . AnnAssign ) -> Any : '''Rule: `x: Ty` -> ``` freetensor__annotate__x = annotate_stmt('x', Ty) if freetensor__annotate__x: x = freetensor__annotate__x ```: pure annotation ''' node : ast . AnnAssign = self . generic_visit ( old_node ) if isinstance ( node . target , ast . Name ) and node . value is None : node = self . handleType_AnnAssign ( node ) return node","title":"visit_AnnAssign()"},{"location":"api/#freetensor.core.staging.Transformer.visit_Assign","text":"Rule: lhs = rhs -> lhs = unpack_assign_stmt('lhs', rhs) x.lhs = rhs -> x.lhs = unpack_assign_stmt('lhs', rhs) a, (b, c) = (x, (y, z)) -> a, (b, c) = unpack_assign_stmt(('a', ('b', 'c')), (x, (y, z))) a = b = c -> a = unpack_assign_stmt('a', c); b = unpack_assign_stmt('b', c) If unpack_assign_stmt is not overloaded, assign_stmt will be called for each item Source code in python/freetensor/core/staging.py 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 def visit_Assign ( self , old_node : ast . Assign ) -> ast . Assign : '''Rule: `lhs = rhs` -> `lhs = unpack_assign_stmt('lhs', rhs)` `x.lhs = rhs` -> `x.lhs = unpack_assign_stmt('lhs', rhs)` `a, (b, c) = (x, (y, z))` -> `a, (b, c) = unpack_assign_stmt(('a', ('b', 'c')), (x, (y, z)))` `a = b = c` -> `a = unpack_assign_stmt('a', c); b = unpack_assign_stmt('b', c)` If `unpack_assign_stmt` is not overloaded, `assign_stmt` will be called for each item ''' node : ast . Assign = self . generic_visit ( old_node ) class UnoverloadableExcept ( BaseException ): pass def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) elif isinstance ( target , ast . Attribute ): return ast . Constant ( target . attr ) elif isinstance ( target , ast . Tuple ): # Unpacking: (a, b) = c l = [] for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) else : raise UnoverloadableExcept () def do_visit_assign ( targets ): try : names = recursive_get_names ( targets ) return ast . Assign ([ targets ], call_helper ( StagingOverload . unpack_assign_stmt , names , node . value )) except UnoverloadableExcept : return ast . Assign ([ targets ], node . value ) # If there are more than one item in `node.targets`, it means multiple # assignments like `a = b = c`. For unpacking like `(a, b) = c`, it # is represented as one tuple as a target item new_nodes = [] for target in node . targets : new_nodes . append ( do_visit_assign ( target )) return new_nodes","title":"visit_Assign()"},{"location":"api/#freetensor.core.staging.Transformer.visit_Compare","text":"Expand multiple comparison into and expression. Source code in python/freetensor/core/staging.py 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 def visit_Compare ( self , old_node : ast . Compare ) -> Any : '''Expand multiple comparison into `and` expression.''' if len ( old_node . comparators ) == 1 : return self . generic_visit ( old_node ) lhs = old_node . left node = ast . BoolOp ( ast . And (), []) for op , rhs in zip ( old_node . ops , old_node . comparators ): node . values . append ( ast . Compare ( lhs , [ op ], [ rhs ])) lhs = rhs return self . visit ( node )","title":"visit_Compare()"},{"location":"api/#freetensor.core.staging.Transformer.visit_For","text":"Rule: for x in iter: body -> def for_body(x): body foreach('x', iter, for_body) Source code in python/freetensor/core/staging.py 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 def visit_For ( self , old_node : ast . For ): '''Rule: ``` for x in iter: body ``` -> ``` def for_body(x): body foreach('x', iter, for_body) ```''' if len ( old_node . orelse ) == 0 : with NonlocalTransformingScope ( self ) as nonlocals : # While opening a fake function, For loops initiates an iter name as # well. Need to remove it from the outer nonlocals list to implement # shadowing. Only For loops behaves as such, so handle it specially here. nonlocals = set ( nonlocals ) def recursive_remove_id ( target ): if isinstance ( target , ast . Name ): if target . id in nonlocals : nonlocals . remove ( target . id ) else : assert isinstance ( target , ast . Tuple ) for t in target . elts : recursive_remove_id ( t ) recursive_remove_id ( old_node . target ) nonlocals = list ( nonlocals ) def recursive_get_names ( target ): if isinstance ( target , ast . Name ): return ast . Constant ( target . id ) else : l = [] assert isinstance ( target , ast . Tuple ) for t in target . elts : l . append ( recursive_get_names ( t )) return ast . Tuple ( l , ast . Load ()) target_names = recursive_get_names ( old_node . target ) node : ast . For = self . generic_visit ( old_node ) node = [ function_helper ( 'for_body' , [ '__item__' ], [ ast . Assign ([ node . target ], ast . Name ( '__item__' , ast . Load ())) ] + node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . foreach , target_names , node . iter , ast . Name ( 'for_body' , ast . Load ()))) ] else : node = self . generic_visit ( old_node ) return node","title":"visit_For()"},{"location":"api/#freetensor.core.staging.Transformer.visit_If","text":"Rule: if pred: body else: orelse -> def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) Source code in python/freetensor/core/staging.py 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 def visit_If ( self , old_node : ast . If ): '''Rule: ``` if pred: body else: orelse ``` -> ``` def then_body(): body def else_body(): orelse if_then_else_stmt(pred, then_body, else_body) ``` ''' test = self . visit ( old_node . test ) with NonlocalTransformingScope ( self ) as nonlocals : new_node = [ function_helper ( 'then_body' , [], [ z for x in old_node . body for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals ) ] then_body = ast . Name ( 'then_body' , ast . Load ()) if old_node . orelse : with NonlocalTransformingScope ( self ) as nonlocals : new_node . append ( function_helper ( 'else_body' , [], [ z for x in old_node . orelse for y in [ self . visit ( x )] for z in ( y if isinstance ( y , list ) else [ y ]) ], nonlocals )) else_body = ast . Name ( 'else_body' , ast . Load ()) else : else_body = ast . Constant ( None ) new_node . append ( ast . Expr ( call_helper ( StagingOverload . if_then_else_stmt , test , then_body , else_body ))) return new_node","title":"visit_If()"},{"location":"api/#freetensor.core.staging.Transformer.visit_IfExp","text":"Rule: body if test else orelse -> if_then_else_expr(test, body, orelse) Source code in python/freetensor/core/staging.py 939 940 941 942 943 944 945 def visit_IfExp ( self , old_node : ast . IfExp ): '''Rule: `body if test else orelse` -> `if_then_else_expr(test, body, orelse)`''' node = self . generic_visit ( old_node ) node = call_helper ( StagingOverload . if_then_else_expr , node . test , ast . Lambda ( _EMPTY_ARGS , node . body ), ast . Lambda ( _EMPTY_ARGS , node . orelse )) return node","title":"visit_IfExp()"},{"location":"api/#freetensor.core.staging.Transformer.visit_While","text":"Rule: while pred: body -> def while_body(): body while_stmt(lambda: pred, while_body) Source code in python/freetensor/core/staging.py 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 def visit_While ( self , old_node : ast . While ) -> Any : '''Rule: ``` while pred: body ``` -> ``` def while_body(): body while_stmt(lambda: pred, while_body) ```''' with NonlocalTransformingScope ( self ) as nonlocals : node : ast . While = self . generic_visit ( old_node ) node = [ function_helper ( 'while_body' , [], node . body , nonlocals ), ast . Expr ( call_helper ( StagingOverload . while_stmt , ast . Lambda ( _EMPTY_ARGS , node . test ), ast . Name ( 'while_body' , ast . Load ()))) ] return node","title":"visit_While()"},{"location":"api/#freetensor.core.staging.call_helper","text":"Call helper that generates a python AST Call node with given callee (overload member) and arguments AST node. Source code in python/freetensor/core/staging.py 665 666 667 668 669 670 671 def call_helper ( callee , * args : ast . expr , ** kwargs : ast . expr ): '''Call helper that generates a python AST Call node with given callee (overload member) and arguments AST node.''' return ast . Call ( ast . Attribute ( ast . Name ( '__staging_overload__' , ast . Load ()), callee . __name__ , ast . Load ()), list ( args ), [ ast . keyword ( k , w ) for k , w in kwargs . items ()])","title":"call_helper()"},{"location":"api/#freetensor.core.staging.function_helper","text":"Function helper that generates a python AST FunctionDef node with given name, arguments name, and body. Source code in python/freetensor/core/staging.py 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 def function_helper ( name : str , args : Sequence [ str ], body : List [ ast . stmt ], nonlocals : List [ str ]): '''Function helper that generates a python AST FunctionDef node with given name, arguments name, and body.''' nonlocal_body = ([ ast . Nonlocal ( nonlocals )] if len ( nonlocals ) > 0 else []) + body return ast . FunctionDef ( name = name , args = ast . arguments ( args = [], vararg = None , kwarg = None , posonlyargs = [ ast . arg ( a , None ) for a in args ], defaults = [], kwonlyargs = [], kw_defaults = []), body = nonlocal_body , returns = None , decorator_list = [])","title":"function_helper()"},{"location":"api/#freetensor.core.stmt","text":"Facility to build AST statements Classes and functions in this module are internally used by transformer to construct ASTs. They are also used by some internal tests. API of these classes and functions are subject to changes. End users are encouraged to use transformer , instead of this module. Classes and functions in this module are all in BigCamel naming style, to distinguish from expressions in expr.py","title":"stmt"},{"location":"api/#freetensor.core.stmt.Assert","text":"Scope used to create an Assert node This scope is internally used by transformer and tests E.g.: with Assert(i > 0): ... # Assertion body Source code in python/freetensor/core/stmt.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 class Assert : ''' Scope used to create an Assert node This scope is internally used by `transformer` and tests E.g.: ``` with Assert(i > 0): ... # Assertion body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () top . append_stmt ( ffi . makeAssert ( self . cond , body , top . get_metadata ()))","title":"Assert"},{"location":"api/#freetensor.core.stmt.Else","text":"Scope used to create an else branch of an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # True branch with Else(): ... # Else branch Source code in python/freetensor/core/stmt.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 class Else : ''' Scope used to create an else branch of an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # True branch with Else(): ... # Else branch ``` ''' def __init__ ( self ): pass def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_else_stmt ( body )","title":"Else"},{"location":"api/#freetensor.core.stmt.For","text":"Scope used to create a For node This scope is internally used by transformer and tests E.g.: with For('i', 0, n) as i: ... # Loop body Source code in python/freetensor/core/stmt.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 class For : ''' Scope used to create a For node This scope is internally used by `transformer` and tests E.g.: ``` with For('i', 0, n) as i: ... # Loop body ``` ''' def __init__ ( self , iter_var : str , begin , end , step = 1 , label : Optional [ str ] = None , no_deps : Optional [ Sequence [ str ]] = None , prefer_libs : Optional [ bool ] = None ): self . iter_var = iter_var self . begin = begin self . end = end self . step = step self . label = label self . no_deps = no_deps self . prefer_libs = prefer_libs self . borrowed_vardefs = set () for x in [ begin , end , step ]: for name in ffi . all_reads ( ffi . Expr ( x )): self . borrowed_vardefs . add ( open_vardefs [ name ]) def __enter__ ( self ): for item in self . borrowed_vardefs : item . lend_out () ctx_stack . push () return ffi . makeVar ( self . iter_var ) def __exit__ ( self , exc_type , exc_value , traceback ): for item in self . borrowed_vardefs : item . reclaim () if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () top = ctx_stack . top () top . append_for_stmt ( self . iter_var , self . begin , self . end , self . step , body , metadata = ffi . SourceMetadata ([ self . label ]) if self . label is not None else None , no_deps = self . no_deps , prefer_libs = self . prefer_libs )","title":"For"},{"location":"api/#freetensor.core.stmt.If","text":"Scope used to create an If node This scope is internally used by transformer and tests E.g.: with If(i > 0): ... # Branch body Source code in python/freetensor/core/stmt.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 class If : ''' Scope used to create an If node This scope is internally used by `transformer` and tests E.g.: ``` with If(i > 0): ... # Branch body ``` ''' def __init__ ( self , cond ): self . cond = cond def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception body = ctx_stack . pop () . make_stmt () ctx_stack . top () . append_if_then_stmt ( self . cond , body )","title":"If"},{"location":"api/#freetensor.core.stmt.Invoke","text":"Inlined invocation of another AST Invoke is used as a scope ( with Invoke(...) as returned_vars ), so that variables returned by the callee can be used in the socpe Invoke can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use inline in transformer instead, which supports generic types Source code in python/freetensor/core/stmt.py 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 class Invoke : ''' Inlined invocation of another AST `Invoke` is used as a scope (`with Invoke(...) as returned_vars`), so that variables returned by the callee can be used in the socpe `Invoke` can be used for invoking a gradient function, which has already been lowered as an AST. Please note that once a user function has been lowered as an AST, the dimensionalities of its tensors get fixed. Therefore, to invoke ordinary user functions, please use `inline` in `transformer` instead, which supports generic types ''' def __init__ ( self , ret_names : Sequence [ str ], func : ffi . Func , args : Sequence = [], kvs : Mapping = {}): self . args = args self . kvs = kvs self . func , returns = ffi . strip_returns ( func ) self . vardefs = [] # Outer to inner assert len ( ret_names ) == len ( returns ) for name , ret in zip ( ret_names , returns ): self . vardefs . append ( _VarDef ( name , ret . tensor . shape , ret . tensor . dtype , \"cache\" , ret . mtype )) def __enter__ ( self ): varrefs = [] ret_names = [] for vardef in self . vardefs : varref = vardef . __enter__ () varrefs . append ( varref ) ret_names . append ( varref . name ) ctx_stack . top () . append_stmt ( ffi . inlined_invoke ( ctx_stack . top () . get_metadata (), self . func , self . args , self . kvs , ret_names )) return varrefs [ 0 ] if len ( varrefs ) == 1 else tuple ( varrefs ) def __exit__ ( self , exc_type , exc_value , traceback ): for vardef in reversed ( self . vardefs ): vardef . __exit__ ( exc_type , exc_value , traceback )","title":"Invoke"},{"location":"api/#freetensor.core.stmt.NamedScope","text":"Scope used to create an StmtSeq node with an explicit labels E.g.: with NamedScope(): ... # body This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes Source code in python/freetensor/core/stmt.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 class NamedScope : ''' Scope used to create an StmtSeq node with an explicit labels E.g.: ``` with NamedScope(): ... # body ``` This scope is used for testing only. StmtSeq nodes can be deleted in many lowering passes ''' def __init__ ( self , * labels : str ): self . labels = labels def __enter__ ( self ): ctx_stack . push () def __exit__ ( self , exc_type , exc_value , traceback ): if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception finished_scope = ctx_stack . pop () metadata = ctx_stack . top () . get_metadata ( self . labels ) body = finished_scope . make_stmt ( metadata ) ctx_stack . top () . append_stmt ( body )","title":"NamedScope"},{"location":"api/#freetensor.core.stmt.UserGradStaged","text":"Internal staged implementation of UserGrad Source code in python/freetensor/core/stmt.py 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 class UserGradStaged : ''' Internal staged implementation of `UserGrad` ''' def __init__ ( self , * args : Sequence [ VarRef ], ** kvs ): self . ori_vars = args self . body = None self . grad_defs = [] if 'stmt_range' in kvs : stmt_range = kvs [ 'stmt_range' ] if isinstance ( stmt_range , StmtRange ): self . ori_stmts = stmt_range . make () else : raise TypeError ( \"`stmt_range` should be a `StmtRange` for `UserGrad`\" ) del kvs [ 'stmt_range' ] else : self . ori_stmts = { ctx_stack . get_last_stmt_id ()} for key in kvs : raise TypeError ( f \"Unrecognized parameter ` { key } ` of `UserGrad`\" ) def __enter__ ( self ): # Make `VarDef` scopes for the gradients grad_vars = [] for ori_var in self . ori_vars : grad_def = VarDef ( ori_var . name + \".grad\" , ori_var . full_shape , ori_var . dtype , \"cache\" , ori_var . mtype ) grad_vars . append ( grad_def . __enter__ ()) self . grad_defs . append ( grad_def ) # Make a context, which is used for popping out the body we need ctx_stack . push () return grad_vars def __exit__ ( self , exc_type , exc_value , traceback ): # Pop out the body we need self . body = ctx_stack . pop () . make_stmt () # Although we are discarding the gradient `VarDef` scopes, we still need to close # them, to restore ctx_stack. After that, we pop out the `VarDef` statement for grad_def in reversed ( self . grad_defs ): grad_def . __exit__ ( exc_type , exc_value , traceback ) if exc_value is not None : # Do not generate an AST node return False # Do not suppress the exception ctx_stack . top () . stmt_seq . pop () # Record the body to context ctx_stack . user_grads . append ( ffi . StmtSetToUserGrad ( self . ori_stmts , self . body ))","title":"UserGradStaged"},{"location":"api/#freetensor.core.stmt.Any","text":"Create an Any node (only for testing) Any nodes matches any statement nodes in ast.match Source code in python/freetensor/core/stmt.py 412 413 414 415 416 417 418 def Any (): ''' Create an Any node (only for testing) Any nodes matches any statement nodes in `ast.match` ''' ctx_stack . top () . append_stmt ( ffi . makeAny ())","title":"Any()"},{"location":"api/#freetensor.core.stmt.Eval","text":"Create an Eval node This scope is internally used by transformer and tests Source code in python/freetensor/core/stmt.py 402 403 404 405 406 407 408 409 def Eval ( expr ): ''' Create an Eval node This scope is internally used by `transformer` and tests ''' top = ctx_stack . top () top . append_stmt ( ffi . makeEval ( expr , top . get_metadata ()))","title":"Eval()"},{"location":"api/#freetensor.core.stmt.MarkLabel","text":"Mark the ID of the following statement This scope is internally used by transformer and tests Source code in python/freetensor/core/stmt.py 308 309 310 311 312 313 314 def MarkLabel ( label : str ): \"\"\" Mark the ID of the following statement This scope is internally used by `transformer` and tests \"\"\" ctx_stack . top () . add_label ( label )","title":"MarkLabel()"},{"location":"api/#freetensor.core.stmt.MarkVersion","text":"Create an MarkVersion node (only for custom gradient) This node is only used for custom gradient. See UserGrad . Source code in python/freetensor/core/stmt.py 421 422 423 424 425 426 427 428 429 def MarkVersion ( tape_name : str , var : VarRef ): ''' Create an MarkVersion node (only for custom gradient) This node is only used for custom gradient. See `UserGrad`. ''' top = ctx_stack . top () top . append_stmt ( ffi . makeMarkVersion ( tape_name , var . name , top . get_metadata ()))","title":"MarkVersion()"},{"location":"api/#freetensor.core.stmt.VarDef","text":"A factory function that creates a VarDef or a series of nested VarDef s This scope is internally used by transformer and tests Source code in python/freetensor/core/stmt.py 148 149 150 151 152 153 154 155 156 157 158 def VarDef ( * args , ** kvs ): ''' A factory function that creates a VarDef or a series of nested `VarDef`s This scope is internally used by `transformer` and tests ''' if len ( args ) == 1 : return _VarsDef ( args [ 0 ]) else : return _VarDef ( * args , ** kvs )","title":"VarDef()"},{"location":"api/#freetensor.libop","text":"","title":"libop"},{"location":"api/#freetensor.libop.constant","text":"","title":"constant"},{"location":"api/#freetensor.libop.constant.zeros","text":"Create a zero tensor Parameters: Name Type Description Default shape Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape required dtype str or DataType Data type of the variable required mtype str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used None Returns: Name Type Description VarRef The zero tensor Source code in python/freetensor/libop/constant.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @core . inline def zeros ( shape , dtype , mtype = None ): ''' Create a zero tensor Parameters ---------- shape : Sequence[Expr] or Var Shape of the variable. A variable can be created using a literal shape, or another fixed-length VarRef as a shape dtype : str or DataType Data type of the variable mtype : str or MemType (Optional) Memory type of the variable. If omitted, the main memory type of the default Target in config will be used Returns ------- VarRef : The zero tensor ''' y = core . empty ( shape , dtype , mtype ) #! label: recur zeros_ ( y ) return y","title":"zeros()"},{"location":"api/#freetensor.libop.constant.zeros_","text":"Fill zeros to a tensor Parameters: Name Type Description Default y VarRef The tensor to fill required Source code in python/freetensor/libop/constant.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @core . inline def zeros_ ( y ): ''' Fill zeros to a tensor Parameters ---------- y : VarRef The tensor to fill ''' if core . ndim ( y ) == 0 : y [()] = core . zero_value ( y . dtype ) else : #! label: L_elem for i in range ( core . shape ( y , 0 )): #! label: recur zeros_ ( y [ i ])","title":"zeros_()"},{"location":"api/#freetensor.libop.element_wise","text":"","title":"element_wise"},{"location":"api/#freetensor.libop.element_wise.binary_op","text":"(Broadcasted) any element-wise operation on two tensors and return the result Parameters: Name Type Description Default op Callable The operation applied to each item required a VarRef Left-hand-side operand required b VarRef Right-hand-side operand required Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/element_wise.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @core . inline def binary_op ( op , a , b ): ''' (Broadcasted) any element-wise operation on two tensors and return the result Parameters ---------- op : Callable The operation applied to each item a : VarRef Left-hand-side operand b : VarRef Right-hand-side operand Returns ------- VarRef The result tensor ''' #! label: out # NOTE: We only inference base data type, to avoid confusion in case the result # tensor is further assigned by users with other sign data types out = core . empty ( broadcast_shape ( a , b ), core . dtype ( op ( core . cast ( core . any (), core . dtype ( a )), core . cast ( core . any (), core . dtype ( b )))) . base , core . same_mtype ( core . mtype ( a ), core . mtype ( b ))) #! label: recur binary_op_ ( op , a , b , out ) return out","title":"binary_op()"},{"location":"api/#freetensor.libop.element_wise.binary_op_","text":"(Broadcasted) any element-wise operation on two tensors. The result is written to another tensor Parameters: Name Type Description Default op Callable The operation applied to each item required a VarRef Left-hand-side operand required b VarRef Right-hand-side operand required out VarRef The result tensor required Source code in python/freetensor/libop/element_wise.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @core . inline def binary_op_ ( op , a , b , out ): ''' (Broadcasted) any element-wise operation on two tensors. The result is written to another tensor Parameters ---------- op : Callable The operation applied to each item a : VarRef Left-hand-side operand b : VarRef Right-hand-side operand out : VarRef The result tensor ''' if core . ndim ( out ) == 0 : out [()] = op ( a , b ) else : #! label: L_elem for i in range ( out . shape ( 0 )): if core . ndim ( a ) < core . ndim ( out ): assert b . shape ( 0 ) == out . shape ( 0 ) #! label: recur binary_op_ ( op , a , b [ i ], out [ i ]) elif core . ndim ( b ) < core . ndim ( out ): assert a . shape ( 0 ) == out . shape ( 0 ) #! label: recur binary_op_ ( op , a [ i ], b , out [ i ]) else : assert a . shape ( 0 ) == out . shape ( 0 ) or a . shape ( 0 ) == 1 assert b . shape ( 0 ) == out . shape ( 0 ) or b . shape ( 0 ) == 1 #! label: recur binary_op_ ( op , a [ i % a . shape ( 0 )], b [ i % b . shape ( 0 )], out [ i ])","title":"binary_op_()"},{"location":"api/#freetensor.libop.element_wise.unary_op","text":"Any element-wise operation on a tensor and return the result Parameters: Name Type Description Default op Callable The operation applied to each item required x VarRef The input tensor required Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/element_wise.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 @core . inline def unary_op ( op , x ): ''' Any element-wise operation on a tensor and return the result Parameters ---------- op : Callable The operation applied to each item x : VarRef The input tensor Returns ------- VarRef The result tensor ''' #! label: y # NOTE: We only inference base data type, to avoid confusion in case the result # tensor is further assigned by users with other sign data types y = core . empty ( copy_shape ( x ), core . dtype ( op ( core . cast ( core . any (), core . dtype ( x )))) . base , core . mtype ( x )) #! label: recur unary_op_ ( op , x , y ) return y","title":"unary_op()"},{"location":"api/#freetensor.libop.element_wise.unary_op_","text":"Any element-wise operation on a tensor. The result is written to another tensor Parameters: Name Type Description Default op Callable The operation applied to each item required x VarRef The input tensor required out VarRef The result tensor required Source code in python/freetensor/libop/element_wise.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 @core . inline def unary_op_ ( op , x , y ): ''' Any element-wise operation on a tensor. The result is written to another tensor Parameters ---------- op : Callable The operation applied to each item x : VarRef The input tensor out : VarRef The result tensor ''' if core . ndim ( x ) == 0 : y [()] = op ( x ) else : assert x . shape ( 0 ) == y . shape ( 0 ) #! label: L_elem for i in range ( x . shape ( 0 )): #! label: recur unary_op_ ( op , x [ i ], y [ i ])","title":"unary_op_()"},{"location":"api/#freetensor.libop.pooling","text":"","title":"pooling"},{"location":"api/#freetensor.libop.pooling.global_avg_pool","text":"Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 @core . inline def global_avg_pool ( X ): ''' Global averaging pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 )], X . dtype , X . mtype ) #! label: recur global_avg_pool_ ( X , Y ) return Y","title":"global_avg_pool()"},{"location":"api/#freetensor.libop.pooling.global_avg_pool_","text":"Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @core . inline def global_avg_pool_ ( X , Y ): ''' Global averaging pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) #! label: L_n for n in range ( X . shape ( 0 )): #! label: L_c for c in range ( X . shape ( 1 )): #! label: init Y [ n , c ] = 0 #! label: L_h for h in range ( X . shape ( 2 )): #! label: L_w for w in range ( X . shape ( 3 )): #! label: compute Y [ n , c ] += X [ n , c , h , w ] #! label: flush Y [ n , c ] /= X . shape ( 2 ) * X . shape ( 3 )","title":"global_avg_pool_()"},{"location":"api/#freetensor.libop.pooling.max_pool","text":"Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @core . inline def max_pool ( X , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is returned Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" Y = core . empty ([ X . shape ( 0 ), X . shape ( 1 ), calc_out_size ( X . shape ( 2 ), dilations [ 0 ], kernel_shape [ 0 ], pads [ 0 ], pads [ 2 ], strides [ 0 ]), calc_out_size ( X . shape ( 3 ), dilations [ 1 ], kernel_shape [ 1 ], pads [ 1 ], pads [ 3 ], strides [ 1 ]) ], X . dtype , X . mtype ) #! label: recur max_pool_ ( X , Y , auto_pad , dilations , kernel_shape , pads , strides ) return Y","title":"max_pool()"},{"location":"api/#freetensor.libop.pooling.max_pool_","text":"Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported Source code in python/freetensor/libop/pooling.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @core . inline def max_pool_ ( X , Y , auto_pad : str = 'NOTSET' , dilations : Optional [ Sequence [ int ]] = None , kernel_shape : Sequence [ int ] = None , pads : Optional [ Sequence [ int ]] = None , strides : Optional [ Sequence [ int ]] = None ): ''' Maximum pooling. The result is written to another tensor Parameters follow ONNX convention. Currently only 2-D pooling is supported ''' n_spatial_dim = 2 # Currently only 2-D pooling is supported (TODO) # TODO: ceil_mode # TODO: return_indices if dilations is None : dilations = [ 1 ] * n_spatial_dim if strides is None : # NOTE: strides default to 1 in ONNX, while default to kernel_shape in PyTorch strides = [ 1 ] * n_spatial_dim if pads is None : if auto_pad == 'VALID' : pads = list ( zip ( * ([[ 0 , 0 ]] * n_spatial_dim ))) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_UPPER' : pads = list ( zip ( * [ calc_same_upper_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] elif auto_pad == 'SAME_LOWER' : pads = list ( zip ( * [ calc_same_lower_pad ( dil , kern , stride ) for dil , kern , stride in zip ( dilations , kernel_shape , strides ) ])) pads = pads [ 0 ] + pads [ 1 ] else : assert False , \"auto_pad should be set if pads is not specified\" # yapf: disable #! label: L_n for n in range ( X . shape ( 0 )): #! label: L_c for c in range ( X . shape ( 1 )): #! label: L_h for h in range ( Y . shape ( 2 )): #! label: L_w for w in range ( Y . shape ( 3 )): #! label: init Y [ n , c , h , w ] = core . min_value ( X . dtype ) #! label: L_kh for kh in range ( kernel_shape [ 0 ]): #! label: L_kw for kw in range ( kernel_shape [ 1 ]): # h_in = h * stride + kh * dilation - pad # w_in = w * stride + kw * dilation - pad if ( h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] >= 0 and h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ] < X . shape ( 2 ) and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] >= 0 and w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ] < X . shape ( 3 )): #! label: compute Y [ n , c , h , w ] = core . max ( Y [ n , c , h , w ], X [ n , c , h * strides [ 0 ] + kh * dilations [ 0 ] - pads [ 0 ], w * strides [ 1 ] + kw * dilations [ 1 ] - pads [ 1 ]])","title":"max_pool_()"},{"location":"api/#freetensor.libop.reduction","text":"","title":"reduction"},{"location":"api/#freetensor.libop.reduction.reduce_max","text":"Maximum of a tensor through one or more dimensions and return the result Parameters: Name Type Description Default x VarRef The input tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/reduction.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 @core . inline def reduce_max ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! label: impl y = _general_reduce ( core . max , core . min_value ( core . dtype ( x )), x , axes , keepdims ) return y","title":"reduce_max()"},{"location":"api/#freetensor.libop.reduction.reduce_max_","text":"Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters: Name Type Description Default x VarRef The input tensor required y VarRef The result tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Source code in python/freetensor/libop/reduction.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @core . inline def reduce_max_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Maximum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! label: impl _general_reduce_ ( core . max , core . min_value ( core . dtype ( x )), x , y , axes , keepdims )","title":"reduce_max_()"},{"location":"api/#freetensor.libop.reduction.reduce_min","text":"Minimum of a tensor through one or more dimensions and return the result Parameters: Name Type Description Default x VarRef The input tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Returns: Type Description VarRef The result tensor Source code in python/freetensor/libop/reduction.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 @core . inline def reduce_min ( x , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions and return the result Parameters ---------- x : VarRef The input tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True Returns ------- VarRef The result tensor ''' #! label: impl y = _general_reduce ( core . min , core . max_value ( core . dtype ( x )), x , axes , keepdims ) return y","title":"reduce_min()"},{"location":"api/#freetensor.libop.reduction.reduce_min_","text":"Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters: Name Type Description Default x VarRef The input tensor required y VarRef The result tensor required axes Sequence [ int ]( Optional ) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension required keepdims bool ( Optional ) Keep the reduced dimensions as singleton dimensions. Defaults to True True Source code in python/freetensor/libop/reduction.py 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 @core . inline def reduce_min_ ( x , y , axes : Sequence [ int ], keepdims : bool = True ): ''' Minimum of a tensor through one or more dimensions. The result is written to another tensor Parameters ---------- x : VarRef The input tensor y : VarRef The result tensor axes : Sequence[int] (Optional) Which dimensions to reduce through. Defaults to None, standing for all dimensions, i.e., reduce the tensor to a scalar. Negative axis means counting form the last dimension keepdims : bool (Optional) Keep the reduced dimensions as singleton dimensions. Defaults to True ''' #! label: impl _general_reduce_ ( core . min , core . max_value ( core . dtype ( x )), x , y , axes , keepdims )","title":"reduce_min_()"},{"location":"about/contrib/","text":"Contributing \u00b6 Pull Requests are welcome! Please configure (or install some plugins for) your editor, to support clang-format , yapf and editorconfig , for code formating. And please note that we use different naming styles in Python and C++ parts.","title":"Contributing"},{"location":"about/pub/","text":"Publication \u00b6 Shizhi Tang, Jidong Zhai, Haojie Wang, Lin Jiang, Liyan Zheng, Zhenhao Yuan, and Chen Zhang. 2022. FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs. In Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI \u201922), June 13-17, 2022, San Diego, CA, USA . ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3519939.3523448. ( Download ) @inproceedings{10.1145/3519939.3523448, author = {Tang, Shizhi and Zhai, Jidong and Wang, Haojie and Jiang, Lin and Zheng, Liyan and Yuan, Zhenhao and Zhang, Chen}, title = {FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs}, year = {2022}, isbn = {9781450392655}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3519939.3523448}, doi = {10.1145/3519939.3523448}, booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation}, pages = {872\u2013887}, numpages = {16}, keywords = {tensor computing, optimizing compilers, DSL}, location = {San Diego, CA, USA}, series = {PLDI 2022} } Evaluation code can be found in this repository . NOTE: API of FreeTensor has been changed since submission. To reproduce the exact result in the paper, please consider the Artifact Evaluation version of FreeTensor, published here .","title":"Publication"},{"location":"guide/","text":"Get Started \u00b6 Build and Run Your First Program with FreeTenor Optimize a Program with Schedules Optimize a Program with Hints Running on a GPU Automatic Differentiation","title":"Get Started"},{"location":"guide/ad/","text":"Automatic Differentiation \u00b6 Reverse-Mode AD Providing Your Custom Gradients Why or When do We Need Custom Gradients How to Write Custom Gradients in FreeTensor Additional Descriptions on push_for_backward Automatic Differentiation (AD) transforms a program to another program that computes the original one's derivative or gradient. FreeTensor supports Reverse-Mode AD, and there is a plan to support Forward-Mode AD in the future. Reverse-Mode AD \u00b6 Suppose there is a program x -> y -> z -> w that computes an output w from intermediate variables z and y , and an input variable x . Reverse-Mode AD generates a gradient program dw/dw=1 -> dw/dz -> dw/dy -> dw/dx that computes dw/dx by Chain Rule. y , z and w may be saved in a \"tape\" when evaluation the original program, to be reused in the gradient one. If FreeTensor is built with WITH_PYTORCH=ON , you can skip this section and turn to the @optimize_to_pytorch integration , which integrates seamlessly with PyTorch's autograd mechanism, but will incur some runtime overhead. Here is an example of Reverse-Mode AD in FreeTensor: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy()) You need to call ft.grad (or the inplace version ft.grad_ ) to generate a forward function and a backward function. Please note that the forward function fwd is not the same as the original function test , because fwd may save some intermediate tensors to a global tape , and fwd must be executed before the backward one bwd . After that, you call ft.optimize to optimize and compile the program just as in previous examples, but for both fwd and bwd this time. Finally, you execute fwd and bwd . The parameters and return values of bwd are the gradients of a , b and y , which have their own names. To set and get these parameters and return values, you look up for them in two dictionaries input_grads and output_grads returned from ft.grad (in type ft.ArgRetDict . input_grads and output_grads accept either a name of a parameter, or a special ft.Return to specify a return value. When invoking bwd , parameters can be set via keyword arguments, and return values can be collect via a bracket (from a special type ft.ReturnValuesPack ). Intermediate variables are not always have to be saved to the \"tape\" from the forward function. If a variable is need in the backward function but not saved, it will be re-computed, which is sometimes even faster than saving it due to better locality. By default, FreeTensor uses heuristics to determine which variable to save. To get better performance, you may want to control which intermediate variables should be saved by setting an optional tapes parameter in ft.grad . tapes can either be a different mode, or a explicit list of AST node IDs of all VarDef nodes of the variables you want to save. Providing Your Custom Gradients \u00b6 Why or When do We Need Custom Gradients \u00b6 Sometimes neither reverse-mode or forward-mode AD produces the most elegant form of gradients. FreeTensor allows you to provide your own gradients for part of the program. Take softmax as an example: The \\(\\mathbf{y} = softmax(\\mathbf{x})\\) function is mathematically defined by the following steps: \\[\\begin{align} e_i &= \\mathrm{e}^{x_i} \\label{eq:softmax-1} \\\\ s &= \\sum_i{e_i} \\label{eq:softmax-2} \\\\ y_i &= \\frac{e_i}{s} \\label{eq:softmax-3} \\end{align}\\] Suppose the final output of the program (the loss) is \\(z\\) . If using reverse-mode AD, the gradient of the input: \\(\\frac{\\partial z}{\\partial x}\\) can be computed by the following steps: \\[\\begin{align} \\frac{\\partial z}{\\partial s} &= -\\sum_i{\\frac{\\partial z}{\\partial y_i} \\frac{y_i}{s}} \\label{eq:softmax-grad-1} \\\\ \\frac{\\partial z}{\\partial e_i} &= \\frac{\\partial z}{\\partial y_i} \\frac{1}{s} + \\frac{\\partial z}{\\partial s} \\label{eq:softmax-grad-2} \\\\ \\frac{\\partial z}{\\partial x_i} &= \\frac{\\partial z}{\\partial e_i} e_i \\label{eq:softmax-grad-3} \\end{align}\\] However, usually we can NOT compute softmax by Equation \\(\\eqref{eq:softmax-1}\\eqref{eq:softmax-2}\\eqref{eq:softmax-3}\\) for numerical stability issues. Pratically, we compute softmax with additional normalization on \\(\\mathbf{x}\\) : \\[\\begin{align} m &= \\max_i{x_i} \\label{eq:softmax-norm-1} \\\\ e_i &= \\mathrm{e}^{x_i - m} \\label{eq:softmax-norm-2} \\\\ s &= \\sum_i{e_i} \\label{eq:softmax-norm-3} \\\\ y_i &= \\frac{e_i}{s} \\label{eq:softmax-norm-4} \\end{align}\\] If we directly apply reverse-mode AD on Equation \\(\\eqref{eq:softmax-norm-1}\\eqref{eq:softmax-norm-2}\\eqref{eq:softmax-norm-3}\\eqref{eq:softmax-norm-4}\\) , the backward program will be like: \\[\\begin{align} \\frac{\\partial z}{\\partial s} &= -\\sum_i{\\frac{\\partial z}{\\partial y_i} \\frac{y_i}{s}} \\\\ \\frac{\\partial z}{\\partial e_i} &= \\frac{\\partial z}{\\partial y_i} \\frac{1}{s} + \\frac{\\partial z}{\\partial s} \\\\ \\frac{\\partial z}{\\partial m} &= -\\sum_i{\\frac{\\partial z}{\\partial e_i}e_i} \\\\ \\frac{\\partial z}{\\partial x_i} &= \\frac{\\partial z}{\\partial e_i} e_i + \\begin{cases}\\frac{\\partial z}{\\partial m}, &i = \\arg\\max_j{x_j} \\\\ 0, &i \\neq \\arg\\max_j{x_j}\\end{cases} \\end{align}\\] You may have found that there is an extra \\(\\frac{\\partial z}{\\partial m}\\) involved. Apparently, the gradient should be the same no matter if we do the normalization. This is because \\(\\frac{\\partial z}{\\partial m}\\) actually always equals to \\(0\\) . FreeTensor can not dig out this mathematical property, so the computation on \\(\\frac{\\partial z}{\\partial m}\\) will remain and will be wasted. How to Write Custom Gradients in FreeTensor \u00b6 The following examples will demonstrate how to provide your own custom gradients, to override the default AD behaviour. Please note that this is only for demonstration. If you are just going to use softmax, call it from libop.softmax , which has already implemented the following code. First we show a softmax implementation with full AD: import freetensor as ft import torch n = 4 def test(x: ft.Var[(n,), \"float32\"]): # Automatically decide gradients for this statement m = ft.reduce_max(x, axes=[-1]) e = ft.exp(x - m) s = ft.reduce_sum(e, axes=[-1]) y = e / s return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['x'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) # Set verbose=1 to see the code # Check forward result x = torch.rand(n, dtype=torch.float32) x.requires_grad = True y_ft = fwd(x).torch() y_torch = torch.softmax(x, axis=-1) assert torch.all(torch.isclose(y_ft, y_torch)) # Check backward result y_torch.grad = dzdy = torch.rand(n, dtype=torch.float32) dzdx_ft = bwd(**{output_grads[ft.Return()]: dzdy}).torch() y_torch.backward(y_torch.grad) dzdx_torch = x.grad assert torch.all(torch.isclose(dzdx_ft, dzdx_torch, 1e-4, 1e-7)) Then, we add our own gradient to it: import freetensor as ft import torch n = 4 def test(x: ft.Var[(n,), \"float32\"]): # Mark the range that you want to provide graident for, with `StmtRange` with ft.StmtRange() as rng: m = ft.reduce_max(x, axes=[-1]) e = ft.exp(x - m) s = ft.reduce_sum(e, axes=[-1]) y = e / s # Call `push_for_backward` so we can use forward values in backward e_now = ft.push_for_backward(e) s_now = ft.push_for_backward(s) y_now = ft.push_for_backward(y) # Define gradient in `UserGrad` with ft.UserGrad(x, y, stmt_range=rng) as (dzdx, dzdy): # Retrieve forward value from `y_now`, NOT `y` dzds = -ft.reduce_sum(dzdy * y_now, axes=[-1]) / s_now dzde = dzdy / s_now + dzds dzdx[...] += dzde * e_now # Use `+=` here return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['x'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) # Set verbose=1 to see the code # Check forward result x = torch.rand(n, dtype=torch.float32) x.requires_grad = True y_ft = fwd(x).torch() y_torch = torch.softmax(x, axis=-1) assert torch.all(torch.isclose(y_ft, y_torch)) # Check backward result y_torch.grad = dzdy = torch.rand(n, dtype=torch.float32) dzdx_ft = bwd(**{output_grads[ft.Return()]: dzdy}).torch() y_torch.backward(y_torch.grad) dzdx_torch = x.grad assert torch.all(torch.isclose(dzdx_ft, dzdx_torch, 1e-4, 1e-7)) First, we mark the range of code that we want to provide gradient for, with ft.StmtRange , as a name rng . In the range, we write the code to compute softmax as usual. Additionaly, for the values that we want to reuse in the gradient, we call ft.push_for_backward to save it. push_for_backward returns a handle that you can use as a usual tensor in the gradient code. If your StmtRange is inside an outer loop, the handle will always reflect the correct iteration (see the next example). Besides, push_for_backward does not mean the value will be physically saved in tape: it only means the value will be logically reused in the backward, no matter by saving or by recomputing. push_for_backward is orthogonal with the tapes parameter in ft.grad . Next, we define our custom gradient with a ft.UserGrad scope. The scopes receives a special parameter stmt_range , which should be set to the StmtRange we have just defined. Beside stmt_range , UserGrand receives an arbitrary number of parameters, in this case, x and y , and returns the same number of variables, dzdx and dzdy , so we have the mapping between each variable and its gradient. What we are going to do is update dzdx from dzdy . We define our gradient code in the UserGrad code of Equation \\(\\eqref{eq:softmax-grad-1}\\eqref{eq:softmax-grad-2}\\eqref{eq:softmax-grad-3}\\) . We want to use the forward value y , s and e . But do NOT directly use its name, use the push_for_backward handler y_now , s_now and e_now instead. Finally, plase note that we update dzdx with += instead of = , because we may be only computing a partial derivative: there may be other functions of x other than y . And it is all done. Additional Descriptions on push_for_backward \u00b6 We have mentioned push_for_backward will automatically handle multiple versions of a variable. If you are familiar with PyTorch, you may have found the name is similar to PyTorch's save_for_backward . Here, versioning is the major difference: ft.push_for_backward can be called multiple times on a variable, to save multiple version (or snapshot of it), while the variable can keep changing. Here is an additional example: a softmax written in a loop form, where we receives a 2-d input, and apply softmax on the second dimension. Again, this is only for demonstration, and there are multiple ways to implement a softmax. import freetensor as ft import torch n = 4 def test(x: ft.Var[(n, n), \"float32\"]): y = ft.empty((n, n), \"float32\") for i in range(n): # Mark the range that you want to provide graident for, with `StmtRange` with ft.StmtRange() as rng: # `m`, `e` and `s` are local to `i` m = ft.reduce_max(x[i], axes=[-1]) e = ft.exp(x[i] - m) s = ft.reduce_sum(e, axes=[-1]) y[i] = e / s # Call `push_for_backward` so we can use forward values in backward e_now = ft.push_for_backward(e) s_now = ft.push_for_backward(s) y_now = ft.push_for_backward(y) # Define gradient in `UserGrad` with ft.UserGrad(x, y, stmt_range=rng) as (dzdx, dzdy): # Retrieve forward value from `y_now`, NOT `y` dzds = -ft.reduce_sum(dzdy[i] * y_now[i], axes=[-1]) / s_now dzde = dzdy[i] / s_now + dzds dzdx[i] += dzde * e_now # Use `+=` here return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['x'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) # Set verbose=1 to see the code # Check forward result x = torch.rand(n, n, dtype=torch.float32) x.requires_grad = True y_ft = fwd(x).torch() y_torch = torch.softmax(x, axis=-1) assert torch.all(torch.isclose(y_ft, y_torch)) # Check backward result y_torch.grad = dzdy = torch.rand(n, n, dtype=torch.float32) dzdx_ft = bwd(**{output_grads[ft.Return()]: dzdy}).torch() y_torch.backward(y_torch.grad) dzdx_torch = x.grad assert torch.all(torch.isclose(dzdx_ft, dzdx_torch, 1e-4, 1e-7)) Here our gradient scope is inside a loop, where m , e and s are local to the loop iteration. When we load the value from their push_for_backward handlers, we get the version of value at the exact iteration we need.","title":"Automatic Differentiation"},{"location":"guide/ad/#reverse-mode-ad","text":"Suppose there is a program x -> y -> z -> w that computes an output w from intermediate variables z and y , and an input variable x . Reverse-Mode AD generates a gradient program dw/dw=1 -> dw/dz -> dw/dy -> dw/dx that computes dw/dx by Chain Rule. y , z and w may be saved in a \"tape\" when evaluation the original program, to be reused in the gradient one. If FreeTensor is built with WITH_PYTORCH=ON , you can skip this section and turn to the @optimize_to_pytorch integration , which integrates seamlessly with PyTorch's autograd mechanism, but will incur some runtime overhead. Here is an example of Reverse-Mode AD in FreeTensor: import freetensor as ft import numpy as np n = 4 def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.zeros((), \"float32\") for i in range(n): y[()] += a[i] * b[i] return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['a', 'b'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) a = np.array([0, 1, 2, 3], dtype=\"float32\") b = np.array([3, 2, 1, 0], dtype=\"float32\") y = fwd(a, b) print(y.numpy()) dzdy = np.array(1, dtype='float32') dzda, dzdb = bwd(**{output_grads[ft.Return()]: dzdy})[input_grads['a'], input_grads['b']] print(dzda.numpy()) print(dzdb.numpy()) You need to call ft.grad (or the inplace version ft.grad_ ) to generate a forward function and a backward function. Please note that the forward function fwd is not the same as the original function test , because fwd may save some intermediate tensors to a global tape , and fwd must be executed before the backward one bwd . After that, you call ft.optimize to optimize and compile the program just as in previous examples, but for both fwd and bwd this time. Finally, you execute fwd and bwd . The parameters and return values of bwd are the gradients of a , b and y , which have their own names. To set and get these parameters and return values, you look up for them in two dictionaries input_grads and output_grads returned from ft.grad (in type ft.ArgRetDict . input_grads and output_grads accept either a name of a parameter, or a special ft.Return to specify a return value. When invoking bwd , parameters can be set via keyword arguments, and return values can be collect via a bracket (from a special type ft.ReturnValuesPack ). Intermediate variables are not always have to be saved to the \"tape\" from the forward function. If a variable is need in the backward function but not saved, it will be re-computed, which is sometimes even faster than saving it due to better locality. By default, FreeTensor uses heuristics to determine which variable to save. To get better performance, you may want to control which intermediate variables should be saved by setting an optional tapes parameter in ft.grad . tapes can either be a different mode, or a explicit list of AST node IDs of all VarDef nodes of the variables you want to save.","title":"Reverse-Mode AD"},{"location":"guide/ad/#providing-your-custom-gradients","text":"","title":"Providing Your Custom Gradients"},{"location":"guide/ad/#why-or-when-do-we-need-custom-gradients","text":"Sometimes neither reverse-mode or forward-mode AD produces the most elegant form of gradients. FreeTensor allows you to provide your own gradients for part of the program. Take softmax as an example: The \\(\\mathbf{y} = softmax(\\mathbf{x})\\) function is mathematically defined by the following steps: \\[\\begin{align} e_i &= \\mathrm{e}^{x_i} \\label{eq:softmax-1} \\\\ s &= \\sum_i{e_i} \\label{eq:softmax-2} \\\\ y_i &= \\frac{e_i}{s} \\label{eq:softmax-3} \\end{align}\\] Suppose the final output of the program (the loss) is \\(z\\) . If using reverse-mode AD, the gradient of the input: \\(\\frac{\\partial z}{\\partial x}\\) can be computed by the following steps: \\[\\begin{align} \\frac{\\partial z}{\\partial s} &= -\\sum_i{\\frac{\\partial z}{\\partial y_i} \\frac{y_i}{s}} \\label{eq:softmax-grad-1} \\\\ \\frac{\\partial z}{\\partial e_i} &= \\frac{\\partial z}{\\partial y_i} \\frac{1}{s} + \\frac{\\partial z}{\\partial s} \\label{eq:softmax-grad-2} \\\\ \\frac{\\partial z}{\\partial x_i} &= \\frac{\\partial z}{\\partial e_i} e_i \\label{eq:softmax-grad-3} \\end{align}\\] However, usually we can NOT compute softmax by Equation \\(\\eqref{eq:softmax-1}\\eqref{eq:softmax-2}\\eqref{eq:softmax-3}\\) for numerical stability issues. Pratically, we compute softmax with additional normalization on \\(\\mathbf{x}\\) : \\[\\begin{align} m &= \\max_i{x_i} \\label{eq:softmax-norm-1} \\\\ e_i &= \\mathrm{e}^{x_i - m} \\label{eq:softmax-norm-2} \\\\ s &= \\sum_i{e_i} \\label{eq:softmax-norm-3} \\\\ y_i &= \\frac{e_i}{s} \\label{eq:softmax-norm-4} \\end{align}\\] If we directly apply reverse-mode AD on Equation \\(\\eqref{eq:softmax-norm-1}\\eqref{eq:softmax-norm-2}\\eqref{eq:softmax-norm-3}\\eqref{eq:softmax-norm-4}\\) , the backward program will be like: \\[\\begin{align} \\frac{\\partial z}{\\partial s} &= -\\sum_i{\\frac{\\partial z}{\\partial y_i} \\frac{y_i}{s}} \\\\ \\frac{\\partial z}{\\partial e_i} &= \\frac{\\partial z}{\\partial y_i} \\frac{1}{s} + \\frac{\\partial z}{\\partial s} \\\\ \\frac{\\partial z}{\\partial m} &= -\\sum_i{\\frac{\\partial z}{\\partial e_i}e_i} \\\\ \\frac{\\partial z}{\\partial x_i} &= \\frac{\\partial z}{\\partial e_i} e_i + \\begin{cases}\\frac{\\partial z}{\\partial m}, &i = \\arg\\max_j{x_j} \\\\ 0, &i \\neq \\arg\\max_j{x_j}\\end{cases} \\end{align}\\] You may have found that there is an extra \\(\\frac{\\partial z}{\\partial m}\\) involved. Apparently, the gradient should be the same no matter if we do the normalization. This is because \\(\\frac{\\partial z}{\\partial m}\\) actually always equals to \\(0\\) . FreeTensor can not dig out this mathematical property, so the computation on \\(\\frac{\\partial z}{\\partial m}\\) will remain and will be wasted.","title":"Why or When do We Need Custom Gradients"},{"location":"guide/ad/#how-to-write-custom-gradients-in-freetensor","text":"The following examples will demonstrate how to provide your own custom gradients, to override the default AD behaviour. Please note that this is only for demonstration. If you are just going to use softmax, call it from libop.softmax , which has already implemented the following code. First we show a softmax implementation with full AD: import freetensor as ft import torch n = 4 def test(x: ft.Var[(n,), \"float32\"]): # Automatically decide gradients for this statement m = ft.reduce_max(x, axes=[-1]) e = ft.exp(x - m) s = ft.reduce_sum(e, axes=[-1]) y = e / s return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['x'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) # Set verbose=1 to see the code # Check forward result x = torch.rand(n, dtype=torch.float32) x.requires_grad = True y_ft = fwd(x).torch() y_torch = torch.softmax(x, axis=-1) assert torch.all(torch.isclose(y_ft, y_torch)) # Check backward result y_torch.grad = dzdy = torch.rand(n, dtype=torch.float32) dzdx_ft = bwd(**{output_grads[ft.Return()]: dzdy}).torch() y_torch.backward(y_torch.grad) dzdx_torch = x.grad assert torch.all(torch.isclose(dzdx_ft, dzdx_torch, 1e-4, 1e-7)) Then, we add our own gradient to it: import freetensor as ft import torch n = 4 def test(x: ft.Var[(n,), \"float32\"]): # Mark the range that you want to provide graident for, with `StmtRange` with ft.StmtRange() as rng: m = ft.reduce_max(x, axes=[-1]) e = ft.exp(x - m) s = ft.reduce_sum(e, axes=[-1]) y = e / s # Call `push_for_backward` so we can use forward values in backward e_now = ft.push_for_backward(e) s_now = ft.push_for_backward(s) y_now = ft.push_for_backward(y) # Define gradient in `UserGrad` with ft.UserGrad(x, y, stmt_range=rng) as (dzdx, dzdy): # Retrieve forward value from `y_now`, NOT `y` dzds = -ft.reduce_sum(dzdy * y_now, axes=[-1]) / s_now dzde = dzdy / s_now + dzds dzdx[...] += dzde * e_now # Use `+=` here return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['x'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) # Set verbose=1 to see the code # Check forward result x = torch.rand(n, dtype=torch.float32) x.requires_grad = True y_ft = fwd(x).torch() y_torch = torch.softmax(x, axis=-1) assert torch.all(torch.isclose(y_ft, y_torch)) # Check backward result y_torch.grad = dzdy = torch.rand(n, dtype=torch.float32) dzdx_ft = bwd(**{output_grads[ft.Return()]: dzdy}).torch() y_torch.backward(y_torch.grad) dzdx_torch = x.grad assert torch.all(torch.isclose(dzdx_ft, dzdx_torch, 1e-4, 1e-7)) First, we mark the range of code that we want to provide gradient for, with ft.StmtRange , as a name rng . In the range, we write the code to compute softmax as usual. Additionaly, for the values that we want to reuse in the gradient, we call ft.push_for_backward to save it. push_for_backward returns a handle that you can use as a usual tensor in the gradient code. If your StmtRange is inside an outer loop, the handle will always reflect the correct iteration (see the next example). Besides, push_for_backward does not mean the value will be physically saved in tape: it only means the value will be logically reused in the backward, no matter by saving or by recomputing. push_for_backward is orthogonal with the tapes parameter in ft.grad . Next, we define our custom gradient with a ft.UserGrad scope. The scopes receives a special parameter stmt_range , which should be set to the StmtRange we have just defined. Beside stmt_range , UserGrand receives an arbitrary number of parameters, in this case, x and y , and returns the same number of variables, dzdx and dzdy , so we have the mapping between each variable and its gradient. What we are going to do is update dzdx from dzdy . We define our gradient code in the UserGrad code of Equation \\(\\eqref{eq:softmax-grad-1}\\eqref{eq:softmax-grad-2}\\eqref{eq:softmax-grad-3}\\) . We want to use the forward value y , s and e . But do NOT directly use its name, use the push_for_backward handler y_now , s_now and e_now instead. Finally, plase note that we update dzdx with += instead of = , because we may be only computing a partial derivative: there may be other functions of x other than y . And it is all done.","title":"How to Write Custom Gradients in FreeTensor"},{"location":"guide/ad/#additional-descriptions-on-push_for_backward","text":"We have mentioned push_for_backward will automatically handle multiple versions of a variable. If you are familiar with PyTorch, you may have found the name is similar to PyTorch's save_for_backward . Here, versioning is the major difference: ft.push_for_backward can be called multiple times on a variable, to save multiple version (or snapshot of it), while the variable can keep changing. Here is an additional example: a softmax written in a loop form, where we receives a 2-d input, and apply softmax on the second dimension. Again, this is only for demonstration, and there are multiple ways to implement a softmax. import freetensor as ft import torch n = 4 def test(x: ft.Var[(n, n), \"float32\"]): y = ft.empty((n, n), \"float32\") for i in range(n): # Mark the range that you want to provide graident for, with `StmtRange` with ft.StmtRange() as rng: # `m`, `e` and `s` are local to `i` m = ft.reduce_max(x[i], axes=[-1]) e = ft.exp(x[i] - m) s = ft.reduce_sum(e, axes=[-1]) y[i] = e / s # Call `push_for_backward` so we can use forward values in backward e_now = ft.push_for_backward(e) s_now = ft.push_for_backward(s) y_now = ft.push_for_backward(y) # Define gradient in `UserGrad` with ft.UserGrad(x, y, stmt_range=rng) as (dzdx, dzdy): # Retrieve forward value from `y_now`, NOT `y` dzds = -ft.reduce_sum(dzdy[i] * y_now[i], axes=[-1]) / s_now dzde = dzdy[i] / s_now + dzds dzdx[i] += dzde * e_now # Use `+=` here return y fwd, bwd, input_grads, output_grads = ft.grad(test, ['x'], [ft.Return()]) fwd = ft.optimize(fwd) bwd = ft.optimize(bwd) # Set verbose=1 to see the code # Check forward result x = torch.rand(n, n, dtype=torch.float32) x.requires_grad = True y_ft = fwd(x).torch() y_torch = torch.softmax(x, axis=-1) assert torch.all(torch.isclose(y_ft, y_torch)) # Check backward result y_torch.grad = dzdy = torch.rand(n, n, dtype=torch.float32) dzdx_ft = bwd(**{output_grads[ft.Return()]: dzdy}).torch() y_torch.backward(y_torch.grad) dzdx_torch = x.grad assert torch.all(torch.isclose(dzdx_ft, dzdx_torch, 1e-4, 1e-7)) Here our gradient scope is inside a loop, where m , e and s are local to the loop iteration. When we load the value from their push_for_backward handlers, we get the version of value at the exact iteration we need.","title":"Additional Descriptions on push_for_backward"},{"location":"guide/build-and-run/","text":"Build and Run \u00b6 Dependencies Build Run a Program with FreeTensor Global Configurations Run the Tests Build this Document Dependencies \u00b6 Linux Python (>= 3.8, for the Python frontend) GCC (>= 10, to support C++20 and the \"unroll\" pragma) CUDA (>= 11.4.1, to support GCC 10, Optional) MKL (Optional) PyTorch (Optional, see below) Java (= 11, Build-time dependency only) Other Python dependencies: pip3 install --user numpy sourceinspect astor Pygments Note on Python version Because we are analyzing Python AST, which is sensitive to Python version, there may be potential bugs for Python strictly later than 3.8. Please file an issue if something goes wrong PyTorch support FreeTensor can optionally link PyTorch to support a copy-free interface between FreeTensor and PyTorch. Please note that, if you are using CUDA, FreeTensor and PyTorch should link CUDA of the same version . PyTorch can be installed in any way you like, see PyTorch's guide . If you are installing a CUDA-supporting release of PyTorch via pip , you need to tell pip where to find the release, for example by a -i <url-to-some-pypi-index> argument, or a -f https://download.pytorch.org/whl/torch_stable.html argument. Tested python dependencies You can also install Python dependencies of the versions we have tested, instead of the latest, by pip3 install --user -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html . This also includes optional dependencies and dependencies only for development. Build \u00b6 First, clone this repo. Don't forget there are some submodules. git clone --recursive <path/to/this/repo> Then, build. mkdir build cd build cmake .. make -j # Or use Ninja There are some options to cmake : -DFT_WITH_CUDA=ON/OFF : build with/without CUDA (defaults to ON ). -DFT_WITH_MKL=<path/to/mkl/root> : build with MKL (path to MKL is required, defaults to building without it). The path accepts by CMake should be a raw unescaped path; i.e. -DFT_WITH_MKL=\"/some path\" is good since the quotes are resolved by the shell but -DFT_WITH_MKL=\\\"/some\\ path\\\" is not. -DFT_WITH_PYTORCH=ON/OFF : build with/without copy-free interface from/to PyTorch, requring PyTorch installed on the system (defaults to OFF ). -DFT_DEBUG_LOG_NODE=ON (for developers): enables tracing to tell by which pass a specific AST node is modified. -DFT_DEBUG_PROFILE=ON (for developers): profiles some heavy functions in the compiler. -DFT_DEBUG_SANITIZE=<sanitizer_name> (for developers): build with GCC sanitizer (set it to a sanitizer name to use, e.g. address). It will build a shared library with a name like freetensor_ffi.cpython-37m-x86_64-linux-gnu.so , which can be used in Python via import freetensor . Run a Program with FreeTensor \u00b6 To run any program with FreeTensor, one should add the python/ and build/ directory to PYTHONPATH first. E.g. to run a python program a.py with FreeTensor in the build/ directory, PYTHONPATH=../python:../build:$PYTHONPATH python3 a.py Global Configurations \u00b6 There are serveral global configurations can be set via environment variables: FT_PRETTY_PRINT=ON/OFF . Enable/disable colored printing. FT_PRINT_ALL_ID=ON/OFF . Print (or not) IDs of all statements in an AST. FT_WERROR=ON/OFF . Treat warnings as errors (or not). FT_BACKEND_COMPILER_CXX=<path/to/compiler> . The C++ compiler used to compiler the optimized program. Default to the same compiler found when building FreeTensor itself, and compilers found in the PATH enviroment variable. This environment variable should be set to a colon-separated list of paths, in which the paths are searched from left to right. FT_BACKEND_COMPILER_NVCC=<path/to/compiler> . The CUDA compiler used to compiler the optimized program (if built with CUDA). Default to the same compiler found when building FreeTensor itself, and compilers found in the PATH enviroment variable. This environment variable should be set to a colon-separated list of paths, in which the paths are searched from left to right. FT_DEBUG_RUNTIME_CHECK . Check out-of-bound access and integer overflow at the generated code at runtime. This option is only for debugging, and will introduce significant runtime overhead. Currently the checker cannot print the error site, please also enable FT_DEBUG_BINARY and then use GDB to locate the error site. FT_DEBUG_BINARY=ON (for developers). Compile with -g at backend. Do not delete the binary file after loaded. FT_DEBUG_CUDA_WITH_UM . Allocate CUDA buffers on Unified Memory, for faster (debugging) access of GPU Array from CPU, but with slower Array allocations and more synchronizations. No performance effect on normal in-kernel computations. This configurations can also set at runtime in ft.config . Run the Tests \u00b6 To run the test, first change into the test/ directory, then PYTHONPATH=../python:../build:$PYTHONPATH pytest To run a single test case, specify the test case name, and optionally use pytest -s to display the standard output. E.g, PYTHONPATH=../python:../build:$PYTHONPATH pytest -s 00.hello_world/test_basic.py::test_hello_world Debugging (for developers) If using GDB, one should invoke PyTest with python3 -m : PYTHONPATH=../python:../build:$PYTHONPATH gdb --args python3 -m pytest If using Valgrind, one should set Python to use the system malloc: PYTHONPATH=../python:../build:$PYTHONPATH PYTHONMALLOC=malloc valgrind python3 -m pytest Sometimes Valgrind is not enough to detect some errors. An alternative is to use the sanitizer from GCC. For example, if you are using the \"address\" sanitizer, first set -DFT_DEBUG_SANITIZE=address to cmake , and then: PYTHONPATH=../python:../build:$PYTHONPATH LD_PRELOAD=`gcc -print-file-name=libasan.so` pytest -s If you are using another sanitizer, change the string set to FT_DEBUG_SANITIZE and the library's name. For example, -DFT_DEBUG_SANITIZE=undefined and libubsan.so . Build this Document \u00b6 First install some dependencies: pip3 install --user mkdocs \"mkdocstrings[python]\" From the root directory of FreeTensor, run a HTTP server to serve the document (recommended, but without document on C++ interface due to a limitation ): PYTHONPATH=./python:./build:$PYTHONPATH mkdocs serve Or build and save the pages (with document on C++ interface, requiring Doxygen and Graphviz): doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs build Publish the documents to GitHub Pages (for developers) doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs gh-deploy","title":"Build and Run"},{"location":"guide/build-and-run/#dependencies","text":"Linux Python (>= 3.8, for the Python frontend) GCC (>= 10, to support C++20 and the \"unroll\" pragma) CUDA (>= 11.4.1, to support GCC 10, Optional) MKL (Optional) PyTorch (Optional, see below) Java (= 11, Build-time dependency only) Other Python dependencies: pip3 install --user numpy sourceinspect astor Pygments Note on Python version Because we are analyzing Python AST, which is sensitive to Python version, there may be potential bugs for Python strictly later than 3.8. Please file an issue if something goes wrong PyTorch support FreeTensor can optionally link PyTorch to support a copy-free interface between FreeTensor and PyTorch. Please note that, if you are using CUDA, FreeTensor and PyTorch should link CUDA of the same version . PyTorch can be installed in any way you like, see PyTorch's guide . If you are installing a CUDA-supporting release of PyTorch via pip , you need to tell pip where to find the release, for example by a -i <url-to-some-pypi-index> argument, or a -f https://download.pytorch.org/whl/torch_stable.html argument. Tested python dependencies You can also install Python dependencies of the versions we have tested, instead of the latest, by pip3 install --user -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html . This also includes optional dependencies and dependencies only for development.","title":"Dependencies"},{"location":"guide/build-and-run/#build","text":"First, clone this repo. Don't forget there are some submodules. git clone --recursive <path/to/this/repo> Then, build. mkdir build cd build cmake .. make -j # Or use Ninja There are some options to cmake : -DFT_WITH_CUDA=ON/OFF : build with/without CUDA (defaults to ON ). -DFT_WITH_MKL=<path/to/mkl/root> : build with MKL (path to MKL is required, defaults to building without it). The path accepts by CMake should be a raw unescaped path; i.e. -DFT_WITH_MKL=\"/some path\" is good since the quotes are resolved by the shell but -DFT_WITH_MKL=\\\"/some\\ path\\\" is not. -DFT_WITH_PYTORCH=ON/OFF : build with/without copy-free interface from/to PyTorch, requring PyTorch installed on the system (defaults to OFF ). -DFT_DEBUG_LOG_NODE=ON (for developers): enables tracing to tell by which pass a specific AST node is modified. -DFT_DEBUG_PROFILE=ON (for developers): profiles some heavy functions in the compiler. -DFT_DEBUG_SANITIZE=<sanitizer_name> (for developers): build with GCC sanitizer (set it to a sanitizer name to use, e.g. address). It will build a shared library with a name like freetensor_ffi.cpython-37m-x86_64-linux-gnu.so , which can be used in Python via import freetensor .","title":"Build"},{"location":"guide/build-and-run/#run-a-program-with-freetensor","text":"To run any program with FreeTensor, one should add the python/ and build/ directory to PYTHONPATH first. E.g. to run a python program a.py with FreeTensor in the build/ directory, PYTHONPATH=../python:../build:$PYTHONPATH python3 a.py","title":"Run a Program with FreeTensor"},{"location":"guide/build-and-run/#global-configurations","text":"There are serveral global configurations can be set via environment variables: FT_PRETTY_PRINT=ON/OFF . Enable/disable colored printing. FT_PRINT_ALL_ID=ON/OFF . Print (or not) IDs of all statements in an AST. FT_WERROR=ON/OFF . Treat warnings as errors (or not). FT_BACKEND_COMPILER_CXX=<path/to/compiler> . The C++ compiler used to compiler the optimized program. Default to the same compiler found when building FreeTensor itself, and compilers found in the PATH enviroment variable. This environment variable should be set to a colon-separated list of paths, in which the paths are searched from left to right. FT_BACKEND_COMPILER_NVCC=<path/to/compiler> . The CUDA compiler used to compiler the optimized program (if built with CUDA). Default to the same compiler found when building FreeTensor itself, and compilers found in the PATH enviroment variable. This environment variable should be set to a colon-separated list of paths, in which the paths are searched from left to right. FT_DEBUG_RUNTIME_CHECK . Check out-of-bound access and integer overflow at the generated code at runtime. This option is only for debugging, and will introduce significant runtime overhead. Currently the checker cannot print the error site, please also enable FT_DEBUG_BINARY and then use GDB to locate the error site. FT_DEBUG_BINARY=ON (for developers). Compile with -g at backend. Do not delete the binary file after loaded. FT_DEBUG_CUDA_WITH_UM . Allocate CUDA buffers on Unified Memory, for faster (debugging) access of GPU Array from CPU, but with slower Array allocations and more synchronizations. No performance effect on normal in-kernel computations. This configurations can also set at runtime in ft.config .","title":"Global Configurations"},{"location":"guide/build-and-run/#run-the-tests","text":"To run the test, first change into the test/ directory, then PYTHONPATH=../python:../build:$PYTHONPATH pytest To run a single test case, specify the test case name, and optionally use pytest -s to display the standard output. E.g, PYTHONPATH=../python:../build:$PYTHONPATH pytest -s 00.hello_world/test_basic.py::test_hello_world Debugging (for developers) If using GDB, one should invoke PyTest with python3 -m : PYTHONPATH=../python:../build:$PYTHONPATH gdb --args python3 -m pytest If using Valgrind, one should set Python to use the system malloc: PYTHONPATH=../python:../build:$PYTHONPATH PYTHONMALLOC=malloc valgrind python3 -m pytest Sometimes Valgrind is not enough to detect some errors. An alternative is to use the sanitizer from GCC. For example, if you are using the \"address\" sanitizer, first set -DFT_DEBUG_SANITIZE=address to cmake , and then: PYTHONPATH=../python:../build:$PYTHONPATH LD_PRELOAD=`gcc -print-file-name=libasan.so` pytest -s If you are using another sanitizer, change the string set to FT_DEBUG_SANITIZE and the library's name. For example, -DFT_DEBUG_SANITIZE=undefined and libubsan.so .","title":"Run the Tests"},{"location":"guide/build-and-run/#build-this-document","text":"First install some dependencies: pip3 install --user mkdocs \"mkdocstrings[python]\" From the root directory of FreeTensor, run a HTTP server to serve the document (recommended, but without document on C++ interface due to a limitation ): PYTHONPATH=./python:./build:$PYTHONPATH mkdocs serve Or build and save the pages (with document on C++ interface, requiring Doxygen and Graphviz): doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs build Publish the documents to GitHub Pages (for developers) doxygen Doxyfile && PYTHONPATH=./python:./build:$PYTHONPATH mkdocs gh-deploy","title":"Build this Document"},{"location":"guide/first-program/","text":"Your First Program with FreeTenor \u00b6 Example: Vector addition Declare and Define Tensors Manipulating Tensors Dynamic or Static Dynamic Tensor Shapes Copy-free interface from/to PyTorch In this page, we introduce some basic concepts of FreeTensor. Example: Vector addition \u00b6 import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is a basic example program in FreeTensor. You write a Python function that manipulates FreeTensor's tensor type ft.Var , decorate the function with ft.optimize , and finally invoke the decorated function. FreeTensor will generate C++ code for this vector addition, compile it using a native compiler, and finally load it back to Python. Set verbose = 1 to optimize if you are interested in the generated native code. To write such a function, you need to follow some basic concept described in this page. Declare and Define Tensors \u00b6 All tensors, including function parameters, intermediate tensors and return values should be properly declared or defined. Scalars are 0-D tensors in FreeTensor. Declare or define a tensor with an empty shape, and you will get a scalar. Function parameters should be declared like x : ft.Var[shape, data_type] . Declaring a parameter either in the function signature or as a stand-alone statment is acceptable. If your parameter uses another parameter as shape, you will need the latter manner. An optional parameter atype can be set to \"output\" or \"inout\" if you want to mutate a function argument. Intermediate and returning tensors can be created by ft.empty , ft.var or ft.zeros . If you are using FreeTensor for GPU computing, an optional parameter mtype can be set to specify where to store the tensor. It defaults to the main memory of your currently chosen computing device. All tensors and their slices are implemented by an internal ft.VarRef type. If you are looking for a tensor's API, ft.VarRef is the right place. Manipulating Tensors \u00b6 To read or write tensors in a function, just write for ... in range(...) loops that iterate through elements in the tensors, and do arithmetic operations on them. We also provide some functions that operates on a whole tensor or a tensor slice in libop . Special note on tensor assignments We follow Python convention for tensor assignments, but sometimes it is a little counterintuitive. Suppose you have two list s in Python: a and b . a = b replaces the object a with the object b , while a[...] = b assigns data in b to a . FreeTensor does not support replacing a tensor object with another one. It supports assignments only. Therefore, we need to write a[...] = b to assign tensor. a[:] = b (for non-scalars), a[None] = b and a[()] = b is also supported. Dynamic or Static \u00b6 Another concept is that statements and expressions in your program are divided into two categories: dynamic and static . Dynamic statements or expressions are restricted to a small subset of Python, and are compiled to native code. Static statements or expressions can be any Python statements or expressions, and are executed before compilation. In other words, static statements or expressions are like macros or templates in C++, while dynamic ones are actually quotations in Multi-Stage Programming . The following statements and expressions are considered dynamic: Declarations, definitions and operations of FreeTensor's tensor type ft.Var (or its internal implementation ft.VarRef ). if statements, for ... in range(...) and assert statements that have a ft.Var condition or range. All other statements and expressions are considered static. With the help of dynamic and static categories, you can utilize complex Python functions as the static part, while still generate high-performance native code using dynamic loops. For example, the following code combines static and dynamic code to sum multiple vectors together: import freetensor as ft import numpy as np n = 4 @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"], c: ft.Var[(n,), \"int32\"]): inputs = [a, b, c] # Static y = ft.empty((n,), \"int32\") # Dynamic for i in range(n): # Dyanmic y[i] = 0 # Dynamic for item in inputs: # Static y[i] += item[i] # Dynamic return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\"), np.array([3, 4, 5, 6], dtype=\"int32\")).numpy() print(y) However, there might be some counterintuitive behaviours when using static statments or expressions. Please remember that static static statements or expressions are executed before compilation, so the following piece of code will result in a list containing only one item: the expression i , instead of 10 numbers: lst = [] for i in range(10): # Dynamic lst.append(i) # Static. Appends only once Dynamic Tensor Shapes \u00b6 In the example of vector addition above, we support any vector length, but only in a static way. This means each time you change the vector length n , you need to recompile (run optimize again) the function. FreeTensor supports defining tensors with dynamic shapes, just by setting their shapes to a dynamic values. The following code shows an example: import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) In this way, in only have to compile your program once. But you will expect a longer compiling time, and some optimizations are not possible with dynamic shapes. Copy-free interface from/to PyTorch \u00b6 If FreeTensor is built with WITH_PYTORCH=ON , you can directly pass PyTorch tensors to or get them from FreeTensor. For example, import freetensor as ft import torch n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(torch.tensor([1, 2, 3, 4], dtype=torch.int32), torch.tensor([2, 3, 4, 5], dtype=torch.int32)).torch() print(y) FreeTensor also supports integration with PyTorch's \"function\" interface. You can use @ft.optimize_to_pytorch to directly generate a PyTorch \"function\" (specifically, a function wrapper around PyTorch's Function.invoke , just like usual PyTorch functions). This approach seamlessly integrates with PyTorch's autograd mechanism, but incurs some more runtime overhead. Please also note that, because we do not know whether we need to do autograd and which input tensors need gradients until we first run a function, compiling of the FreeTensor code will be delayed to run time. The compiled binary code will be cached and reused if following runs requires the same set of inputs to be derived. The following code shows an example of this approach: import freetensor as ft import torch n = 4 # Change this line to ft.optimize_to_pytorch(verbose=1) to see the resulting # native code @ft.optimize_to_pytorch def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.empty((n,), \"float32\") for i in range(n): y[i] = a[i] * b[i] return y # Forward a = torch.tensor([1, 2, 3, 4], requires_grad=True, dtype=torch.float32) b = torch.tensor([2, 3, 4, 5], requires_grad=True, dtype=torch.float32) y = test(a, b) print(\"y = \", y) # Backward y.grad = torch.tensor([1, 1, 1, 1], dtype=torch.float32) y.backward(y.grad) print(\"a.grad = \", a.grad) print(\"b.grad = \", b.grad)","title":"Your First Program with FreeTenor"},{"location":"guide/first-program/#example-vector-addition","text":"import freetensor as ft import numpy as np n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is a basic example program in FreeTensor. You write a Python function that manipulates FreeTensor's tensor type ft.Var , decorate the function with ft.optimize , and finally invoke the decorated function. FreeTensor will generate C++ code for this vector addition, compile it using a native compiler, and finally load it back to Python. Set verbose = 1 to optimize if you are interested in the generated native code. To write such a function, you need to follow some basic concept described in this page.","title":"Example: Vector addition"},{"location":"guide/first-program/#declare-and-define-tensors","text":"All tensors, including function parameters, intermediate tensors and return values should be properly declared or defined. Scalars are 0-D tensors in FreeTensor. Declare or define a tensor with an empty shape, and you will get a scalar. Function parameters should be declared like x : ft.Var[shape, data_type] . Declaring a parameter either in the function signature or as a stand-alone statment is acceptable. If your parameter uses another parameter as shape, you will need the latter manner. An optional parameter atype can be set to \"output\" or \"inout\" if you want to mutate a function argument. Intermediate and returning tensors can be created by ft.empty , ft.var or ft.zeros . If you are using FreeTensor for GPU computing, an optional parameter mtype can be set to specify where to store the tensor. It defaults to the main memory of your currently chosen computing device. All tensors and their slices are implemented by an internal ft.VarRef type. If you are looking for a tensor's API, ft.VarRef is the right place.","title":"Declare and Define Tensors"},{"location":"guide/first-program/#manipulating-tensors","text":"To read or write tensors in a function, just write for ... in range(...) loops that iterate through elements in the tensors, and do arithmetic operations on them. We also provide some functions that operates on a whole tensor or a tensor slice in libop . Special note on tensor assignments We follow Python convention for tensor assignments, but sometimes it is a little counterintuitive. Suppose you have two list s in Python: a and b . a = b replaces the object a with the object b , while a[...] = b assigns data in b to a . FreeTensor does not support replacing a tensor object with another one. It supports assignments only. Therefore, we need to write a[...] = b to assign tensor. a[:] = b (for non-scalars), a[None] = b and a[()] = b is also supported.","title":"Manipulating Tensors"},{"location":"guide/first-program/#dynamic-or-static","text":"Another concept is that statements and expressions in your program are divided into two categories: dynamic and static . Dynamic statements or expressions are restricted to a small subset of Python, and are compiled to native code. Static statements or expressions can be any Python statements or expressions, and are executed before compilation. In other words, static statements or expressions are like macros or templates in C++, while dynamic ones are actually quotations in Multi-Stage Programming . The following statements and expressions are considered dynamic: Declarations, definitions and operations of FreeTensor's tensor type ft.Var (or its internal implementation ft.VarRef ). if statements, for ... in range(...) and assert statements that have a ft.Var condition or range. All other statements and expressions are considered static. With the help of dynamic and static categories, you can utilize complex Python functions as the static part, while still generate high-performance native code using dynamic loops. For example, the following code combines static and dynamic code to sum multiple vectors together: import freetensor as ft import numpy as np n = 4 @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"], c: ft.Var[(n,), \"int32\"]): inputs = [a, b, c] # Static y = ft.empty((n,), \"int32\") # Dynamic for i in range(n): # Dyanmic y[i] = 0 # Dynamic for item in inputs: # Static y[i] += item[i] # Dynamic return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\"), np.array([3, 4, 5, 6], dtype=\"int32\")).numpy() print(y) However, there might be some counterintuitive behaviours when using static statments or expressions. Please remember that static static statements or expressions are executed before compilation, so the following piece of code will result in a list containing only one item: the expression i , instead of 10 numbers: lst = [] for i in range(10): # Dynamic lst.append(i) # Static. Appends only once","title":"Dynamic or Static"},{"location":"guide/first-program/#dynamic-tensor-shapes","text":"In the example of vector addition above, we support any vector length, but only in a static way. This means each time you change the vector length n , you need to recompile (run optimize again) the function. FreeTensor supports defining tensors with dynamic shapes, just by setting their shapes to a dynamic values. The following code shows an example: import freetensor as ft import numpy as np @ft.optimize def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) assert np.array_equal(y, [3, 5, 7, 9]) In this way, in only have to compile your program once. But you will expect a longer compiling time, and some optimizations are not possible with dynamic shapes.","title":"Dynamic Tensor Shapes"},{"location":"guide/first-program/#copy-free-interface-fromto-pytorch","text":"If FreeTensor is built with WITH_PYTORCH=ON , you can directly pass PyTorch tensors to or get them from FreeTensor. For example, import freetensor as ft import torch n = 4 # Change this line to ft.optimize(verbose=1) to see the resulting native code @ft.optimize def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") for i in range(n): y[i] = a[i] + b[i] return y y = test(torch.tensor([1, 2, 3, 4], dtype=torch.int32), torch.tensor([2, 3, 4, 5], dtype=torch.int32)).torch() print(y) FreeTensor also supports integration with PyTorch's \"function\" interface. You can use @ft.optimize_to_pytorch to directly generate a PyTorch \"function\" (specifically, a function wrapper around PyTorch's Function.invoke , just like usual PyTorch functions). This approach seamlessly integrates with PyTorch's autograd mechanism, but incurs some more runtime overhead. Please also note that, because we do not know whether we need to do autograd and which input tensors need gradients until we first run a function, compiling of the FreeTensor code will be delayed to run time. The compiled binary code will be cached and reused if following runs requires the same set of inputs to be derived. The following code shows an example of this approach: import freetensor as ft import torch n = 4 # Change this line to ft.optimize_to_pytorch(verbose=1) to see the resulting # native code @ft.optimize_to_pytorch def test(a: ft.Var[(n,), \"float32\"], b: ft.Var[(n,), \"float32\"]): y = ft.empty((n,), \"float32\") for i in range(n): y[i] = a[i] * b[i] return y # Forward a = torch.tensor([1, 2, 3, 4], requires_grad=True, dtype=torch.float32) b = torch.tensor([2, 3, 4, 5], requires_grad=True, dtype=torch.float32) y = test(a, b) print(\"y = \", y) # Backward y.grad = torch.tensor([1, 1, 1, 1], dtype=torch.float32) y.backward(y.grad) print(\"a.grad = \", a.grad) print(\"b.grad = \", b.grad)","title":"Copy-free interface from/to PyTorch"},{"location":"guide/gpu/","text":"Running on a GPU \u00b6 Example: Vector addition on a GPU mtype=\"byvalue\" for Dynamic Tensor Shapes Example: Vector addition on a GPU \u00b6 If FreeTensor is built with a CUDA backend, you can compile your program to a GPU. We still take a vector addition as an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.GPU(0): n = 4 # Add verbose=1 to see the resulting native code @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize('Li', 'threadIdx.x')) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! label: Li # Label the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Similar to parallelizing to OpenMP threads , in this example, we parallelize Loop Li to the threadIdx.x dimension of CUDA. There are two major differences: You are now calling parallelize schedule with a threadIdx.x parameter, instead of openmp . All the code are enclosed by a with ft.GPU(0) scope. Usually, you not only parallelize your loops to threadIdx.x , but also other CUDA dimensions like blockIdx.x . To achieve this, you either parallelize different loops in a loop nests to different CUDA dimensions, or split your loops before parallelizing them. As for the with ft.GPU(0) scope, ft.GPU(0) specifies a Device (a specific hardware device of GPU). By calling with on a device, default values of several classes and functions are set, but currently you only need to be aware of two things: It sets the Device of optimize . It sets the default mtype of all tensors in the program, which is an optional parameter of ft.Var , ft.empty , etc. mtype refers to memory type. It controls where a tensor is stored. It defaults to \"cpu\" for a CPU program, and \"gpu/global\" for a GPU program. You probably GPU requires putting each variable to a right place (global memory, shared memory, registers, etc.), and this can be done by setting mtype s of each tensor. There are several ways to set mtype s: (Recommended) Leave them to the default \"gpu/global\" first, and modify them with the set_mem_type schedule. In this way, you write some architecture-dependent schedules, but keep your function architecture-independent. (Experimental) Leave them to the default \"gpu/global\" first, and modify them automatically using auto_schedule , or the auto_set_mem_type schedule (which is a part of auto_schedule ). Set them explicitly in the program by setting an optional mtype parameter of ft.Var , ft.empty , etc. mtype=\"byvalue\" for Dynamic Tensor Shapes \u00b6 Tensors with normal mtypes ( \"cpu\" , \"gpu/global\" , etc.) are passed by references, which means a \"cpu\" tensor can only be accessed from a CPU, and a \"gpu/global\" tensor can only be accessed from a GPU. However, sometimes, and especially for dynamic tensor shapes, we want the shapes to be passed by values, and accessible from both CPUs and GPUs (remember we need tensor's shape both when launching a kernel from the CPU side, and during actual computatoin on the GPU side). In this case, we can set the shape-related tensors a \"byvalue\" mtype , and here is an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.GPU(0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li # Label the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y)","title":"Running on a GPU"},{"location":"guide/gpu/#example-vector-addition-on-a-gpu","text":"If FreeTensor is built with a CUDA backend, you can compile your program to a GPU. We still take a vector addition as an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.GPU(0): n = 4 # Add verbose=1 to see the resulting native code @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize('Li', 'threadIdx.x')) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! label: Li # Label the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Similar to parallelizing to OpenMP threads , in this example, we parallelize Loop Li to the threadIdx.x dimension of CUDA. There are two major differences: You are now calling parallelize schedule with a threadIdx.x parameter, instead of openmp . All the code are enclosed by a with ft.GPU(0) scope. Usually, you not only parallelize your loops to threadIdx.x , but also other CUDA dimensions like blockIdx.x . To achieve this, you either parallelize different loops in a loop nests to different CUDA dimensions, or split your loops before parallelizing them. As for the with ft.GPU(0) scope, ft.GPU(0) specifies a Device (a specific hardware device of GPU). By calling with on a device, default values of several classes and functions are set, but currently you only need to be aware of two things: It sets the Device of optimize . It sets the default mtype of all tensors in the program, which is an optional parameter of ft.Var , ft.empty , etc. mtype refers to memory type. It controls where a tensor is stored. It defaults to \"cpu\" for a CPU program, and \"gpu/global\" for a GPU program. You probably GPU requires putting each variable to a right place (global memory, shared memory, registers, etc.), and this can be done by setting mtype s of each tensor. There are several ways to set mtype s: (Recommended) Leave them to the default \"gpu/global\" first, and modify them with the set_mem_type schedule. In this way, you write some architecture-dependent schedules, but keep your function architecture-independent. (Experimental) Leave them to the default \"gpu/global\" first, and modify them automatically using auto_schedule , or the auto_set_mem_type schedule (which is a part of auto_schedule ). Set them explicitly in the program by setting an optional mtype parameter of ft.Var , ft.empty , etc.","title":"Example: Vector addition on a GPU"},{"location":"guide/gpu/#mtypebyvalue-for-dynamic-tensor-shapes","text":"Tensors with normal mtypes ( \"cpu\" , \"gpu/global\" , etc.) are passed by references, which means a \"cpu\" tensor can only be accessed from a CPU, and a \"gpu/global\" tensor can only be accessed from a GPU. However, sometimes, and especially for dynamic tensor shapes, we want the shapes to be passed by values, and accessible from both CPUs and GPUs (remember we need tensor's shape both when launching a kernel from the CPU side, and during actual computatoin on the GPU side). In this case, we can set the shape-related tensors a \"byvalue\" mtype , and here is an example: import freetensor as ft import numpy as np # Using the 0-th GPU device with ft.GPU(0): @ft.optimize( # Parallel Loop Li as GPU threads schedule_callback=lambda s: s.parallelize(\"Li\", \"threadIdx.x\")) # Use \"byvalue\" for `n` so it can be used both during kernel launching # and inside a kernel def test(n: ft.Var[(), \"int32\", \"input\", \"byvalue\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li # Label the loop below as \"Li\" for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(4, dtype=\"int32\"), np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y)","title":"mtype=\"byvalue\" for Dynamic Tensor Shapes"},{"location":"guide/hint/","text":"Optimize a Program with Hints \u00b6 Types with Sign Information Provide Information by Assertions Expressions and statements in a program do not always provide enough mathematical information for the compiler. Since the compiler must ensure safety for all possible cases, optimizations might be missed. In FreeTensor, you may provide additional information in some ways to guide the compiler, in other words, guide FreeTensor. Types with Sign Information \u00b6 Suppose you are filling a n by m matrix from 0 to n * m - 1 in row-major order, you may loop from 0 to n * m - 1 with a single loop, and the iterator i by m to find each element in the i // m -th row and i % m -th column: y = ft.empty((n, m), \"int32\") for i in range(n * m): y[i // m, i % m] = i Definitely there are other solutions, for example using two loops, but we are going to use the single-loop program to show a common but unobvious performance pitfall: Integer division in Python (including in FreeTensor) rounds to negative infinity, but integer division in most target instructions and target languages like C++ or CUDA rounds to 0. There is only a difference when dividend is negative, but compiling a general Python division to target architectures has to involve an extra branch to check it. In our example, n and m refer to the shape of a matrix, so it cannot be negative. If we can hint FreeTensor, we can avoid the redundant branch. FreeTensor supports adding a suffix to the data type string to show the sign of a number. Simply changing \"int32\" to \"int32>=0\" will make a difference. All supported suffices are \">0\" , >=0 , <0 , <=0 , !=0 and ==0 . A complete example is below: import freetensor as ft print(\"Without hint\") @ft.optimize(verbose=1) # `verbose=1` prints the code def test_no_hint(n: ft.Var[(), \"int32\"], m: ft.Var[(), \"int32\"]): y = ft.empty((n, m), \"int32\") for i in range(n * m): y[i // m, i % m] = i return y # You will find `runtime_mod` in the code, which involves additional branching assert \"runtime_mod\" in test_no_hint.native_code() assert \"%\" not in test_no_hint.native_code() print(\"With hint\") @ft.optimize(verbose=1) # `verbose=1` prints the code def test_hint(n: ft.Var[(), \"int32\"], m: ft.Var[(), \"int32>=0\"]): y = ft.empty((n, m), \"int32\") for i in range(n * m): y[i // m, i % m] = i return y # You will find native C++ `%` in the code, which compiles directly to mod # instructions assert \"runtime_mod\" not in test_hint.native_code() assert \"%\" in test_hint.native_code() The sign hint also works for other optimizations. One example is ft.sqrt(x * x) can be automatically optimized to x if x is non-negative. Another example is ft.min(a, b) can be automatically optimized to a if a is negative while b is positive. Provide Information by Assertions \u00b6 Another way to hint FreeTensor is to add some assert statements in the program. In this way, you can add some more precise hints, which reveals mathematical properties among specifc elements, instead of the whole tensor. Here is an example of adding two n -length vectors, and the program is scheduled to execute in parallel. def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') @ft.optimize(schedule_callback=sch, verbose=1) def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li for i in range(n): y[i] = a[i] + b[i] return y The algorithm is simple: we use (at most) n // 32 threads, each computing 32 elements. However, if you look the code, you will find the length of the serial loop is not as simple as 32. Instead, it is a complex expression that results in 31 or 32. This is because n is not always divisible by 32 . Suppose in our case, n is really divisible by 32, we can add an assert statement to hint FreeTensor: assert n % 32 == 0 , and the serial loop will have a neat length 32. A complete example is below: import freetensor as ft import re def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') @ft.optimize(schedule_callback=sch, verbose=1) def test_no_hint(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li for i in range(n): y[i] = a[i] + b[i] return y # You will not find a 32-length loop assert not re.search(r\".* = 0; .* < 32; .*\\+\\+\", test_no_hint.native_code()) @ft.optimize(schedule_callback=sch, verbose=1) def test_hint(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") assert n % 32 == 0 #! label: Li for i in range(n): y[i] = a[i] + b[i] return y # You will find a 32-length loop assert re.search(r\".* = 0; .* < 32; .*\\+\\+\", test_hint.native_code())","title":"Optimize a Program with Hints"},{"location":"guide/hint/#types-with-sign-information","text":"Suppose you are filling a n by m matrix from 0 to n * m - 1 in row-major order, you may loop from 0 to n * m - 1 with a single loop, and the iterator i by m to find each element in the i // m -th row and i % m -th column: y = ft.empty((n, m), \"int32\") for i in range(n * m): y[i // m, i % m] = i Definitely there are other solutions, for example using two loops, but we are going to use the single-loop program to show a common but unobvious performance pitfall: Integer division in Python (including in FreeTensor) rounds to negative infinity, but integer division in most target instructions and target languages like C++ or CUDA rounds to 0. There is only a difference when dividend is negative, but compiling a general Python division to target architectures has to involve an extra branch to check it. In our example, n and m refer to the shape of a matrix, so it cannot be negative. If we can hint FreeTensor, we can avoid the redundant branch. FreeTensor supports adding a suffix to the data type string to show the sign of a number. Simply changing \"int32\" to \"int32>=0\" will make a difference. All supported suffices are \">0\" , >=0 , <0 , <=0 , !=0 and ==0 . A complete example is below: import freetensor as ft print(\"Without hint\") @ft.optimize(verbose=1) # `verbose=1` prints the code def test_no_hint(n: ft.Var[(), \"int32\"], m: ft.Var[(), \"int32\"]): y = ft.empty((n, m), \"int32\") for i in range(n * m): y[i // m, i % m] = i return y # You will find `runtime_mod` in the code, which involves additional branching assert \"runtime_mod\" in test_no_hint.native_code() assert \"%\" not in test_no_hint.native_code() print(\"With hint\") @ft.optimize(verbose=1) # `verbose=1` prints the code def test_hint(n: ft.Var[(), \"int32\"], m: ft.Var[(), \"int32>=0\"]): y = ft.empty((n, m), \"int32\") for i in range(n * m): y[i // m, i % m] = i return y # You will find native C++ `%` in the code, which compiles directly to mod # instructions assert \"runtime_mod\" not in test_hint.native_code() assert \"%\" in test_hint.native_code() The sign hint also works for other optimizations. One example is ft.sqrt(x * x) can be automatically optimized to x if x is non-negative. Another example is ft.min(a, b) can be automatically optimized to a if a is negative while b is positive.","title":"Types with Sign Information"},{"location":"guide/hint/#provide-information-by-assertions","text":"Another way to hint FreeTensor is to add some assert statements in the program. In this way, you can add some more precise hints, which reveals mathematical properties among specifc elements, instead of the whole tensor. Here is an example of adding two n -length vectors, and the program is scheduled to execute in parallel. def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') @ft.optimize(schedule_callback=sch, verbose=1) def test(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li for i in range(n): y[i] = a[i] + b[i] return y The algorithm is simple: we use (at most) n // 32 threads, each computing 32 elements. However, if you look the code, you will find the length of the serial loop is not as simple as 32. Instead, it is a complex expression that results in 31 or 32. This is because n is not always divisible by 32 . Suppose in our case, n is really divisible by 32, we can add an assert statement to hint FreeTensor: assert n % 32 == 0 , and the serial loop will have a neat length 32. A complete example is below: import freetensor as ft import re def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') @ft.optimize(schedule_callback=sch, verbose=1) def test_no_hint(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") #! label: Li for i in range(n): y[i] = a[i] + b[i] return y # You will not find a 32-length loop assert not re.search(r\".* = 0; .* < 32; .*\\+\\+\", test_no_hint.native_code()) @ft.optimize(schedule_callback=sch, verbose=1) def test_hint(n: ft.Var[(), \"int32\"], a, b): a: ft.Var[(n,), \"int32\"] b: ft.Var[(n,), \"int32\"] y = ft.empty((n,), \"int32\") assert n % 32 == 0 #! label: Li for i in range(n): y[i] = a[i] + b[i] return y # You will find a 32-length loop assert re.search(r\".* = 0; .* < 32; .*\\+\\+\", test_hint.native_code())","title":"Provide Information by Assertions"},{"location":"guide/schedules/","text":"Optimize a Program with Schedules \u00b6 Example: Parallel Vector addition Combining Multiple Schdules Specify What to Schedule by Selectors Auto Scheduling (Experimental) Oftentimes, only compiling your programs to native code is not enough, and you need further optimizations. This can be done by applying \"schedules\" (explicit program transformations) to you program. Example: Parallel Vector addition \u00b6 import freetensor as ft import numpy as np n = 4 # Add verbose=1 to see the resulting native code @ft.optimize(schedule_callback=lambda s: s.parallelize('Li', 'openmp') ) # <-- 2. Apply the schedule def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! label: Li # <-- 1. Label the loop as Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is an example of a parallel vector addition executed with OpenMP multithreading. Each element is computed by one thread. To achieve this, there are two steps: Label the loop to be parallelized with a #! label: comment. Here label refers to label of an AST node, which is not required to be unique. Apply a parallelize schedule to Li in the schedule_callback argument to optimize ; since the Li label is unambiguous here, the only Li loop is selectd and parallelized. And you are done. You can have a look at the generated OpenMP multithreaded code by setting verbose=1 . Parameter s in schedule_callback is a Schedule object. Besides parallelize , there are more supported scheduling primitives. If you are using the @optimize_to_pytorch integration , you need to set schedules for the forward pass and the backward pass separately. Combining Multiple Schdules \u00b6 Some optimizations can be done by applying multiple schedules. For example, a tiled matrix-multiplication can be done by first split the loops, then reorder them, and finally apply cache s to create tile tensors. In order to demonstrate the idea, we show a simplier example here: still a vector addtion, but with the loop split and only the outer one parallelize d. Please note that this is an example only for demonstration. Usually you do not need it because OpenMP has its own \"schedule(static)\" for parallelized loops. import freetensor as ft import numpy as np n = 1024 def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') # Set verbose=1 to see the resulting native code # Set verbose=2 to see the code after EVERY schedule @ft.optimize(schedule_callback=sch) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! label: Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(np.arange(1024), dtype=\"int32\"), np.array(np.arange(1024), dtype=\"int32\")).numpy() print(y) One important thing is to track labels of the loops, because the labels will change after schedules. You get labels (to be precise, IDs, which is can be looked-up by labels) of new loops generated from one schedule from its return values ( outer and inner in this case), and pass them to a next schedule. Specify What to Schedule by Selectors \u00b6 In the example above, we label a loop Li and apply schedules on it. It is straight-forward in a tiny example, but as programs grow, it often gets hard to track each statement by a unique label, especially there are inlined function calls. To make things easy, FreeTensor supports specifying a statement by a selector, written in the following rules: A label is a selector. E.g., Li matches a statement with a label Li . (For debugging only) A numerical ID is also a selector. E.g., #31 . A node type surrounded in angle brackets ( <> ) is also a selector. E.g., <For> matches for-loop statements. A selector can be extended to match a new statement produced by a previous schedule. E.g., $split.0{Li} matches the outer loop split from the loop Li . This is useful when return values from schedules are hard to track. Please refer the API document for detailed grammar. Selectors can be combined to match a statement by nesting order. A<-B matches a statement A DIRECTLY NESTED IN another statement B . A<<-B matches a statement DIRECTLY or INDIRECTLY nested in another statement B . A<-(B<-)*C matches a statement A DIRECTLY or INDIRECTLY nested in another statement C with intermedaite nesting statements satisfying the condition in B . B->A matches a statement B directly OUT OF another statement A . B->>A and C->(B->)*A are alike. ( A , B , C can be nested selectors.) Use <-| for the root node, and ->| for a leaf node. Selectors can be combined to match a statement by DFS order. A<:B matches a statement A DIRECTLY BEFORE another statement B . A<<:B matches a statement A DIRECTLY or INDIRECTLY before another statement B . B:>A matches a statment B directly AFTER another statement A . B:>>A matches a statement B directly or indirectly after another statement A . Selectors can be combined to match a statement in a function call. A<~B matches a statement A DIRECTLY called by a call site B . A<<~B matches a statement DIRECTLY or INDIRECTLY called by a call site B . A<~(B<~)*C matches a statement A DIRECTLY or INDIRECTLY called by a call site C with intermediate call sites satisfying the condition in B . ( A , B , C can be nested selectors.) Use <~| for the root function. All the arrow-like selectors ( <- , <~ , <: , etc.) are right-associated. For example, A<-B<-C matches A nested in B , where B is nested in C . All the arrow-like selectors can be used with the first argument omitted. For example, <-B matches ALL statements nested in B . Selectors can be combined with logical \"and\" ( & ), \"or\" ( | ), \"not\" ( ! ) and parentheses. E.g., Li|Lj matches a statement labeled Li OR Lj . Li&Lj matches a statement labeled Li&Lj . All schedules support passing selectors. Auto Scheduling (Experimental) \u00b6 Manually scheduling a program requires a lot of efforts. We provide an experimental automatic scheduling functions in Schedule . You can call s.auto_schedule to pick schedules fully automatically. s.auto_schedule calls other s.auto_xxxxxx functions internally, you can also call one or some of them instead. Please note that these auto-scheduling functions are experimental, and their API is subject to changes.","title":"Optimize a Program with Schedules"},{"location":"guide/schedules/#example-parallel-vector-addition","text":"import freetensor as ft import numpy as np n = 4 # Add verbose=1 to see the resulting native code @ft.optimize(schedule_callback=lambda s: s.parallelize('Li', 'openmp') ) # <-- 2. Apply the schedule def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! label: Li # <-- 1. Label the loop as Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array([1, 2, 3, 4], dtype=\"int32\"), np.array([2, 3, 4, 5], dtype=\"int32\")).numpy() print(y) Here is an example of a parallel vector addition executed with OpenMP multithreading. Each element is computed by one thread. To achieve this, there are two steps: Label the loop to be parallelized with a #! label: comment. Here label refers to label of an AST node, which is not required to be unique. Apply a parallelize schedule to Li in the schedule_callback argument to optimize ; since the Li label is unambiguous here, the only Li loop is selectd and parallelized. And you are done. You can have a look at the generated OpenMP multithreaded code by setting verbose=1 . Parameter s in schedule_callback is a Schedule object. Besides parallelize , there are more supported scheduling primitives. If you are using the @optimize_to_pytorch integration , you need to set schedules for the forward pass and the backward pass separately.","title":"Example: Parallel Vector addition"},{"location":"guide/schedules/#combining-multiple-schdules","text":"Some optimizations can be done by applying multiple schedules. For example, a tiled matrix-multiplication can be done by first split the loops, then reorder them, and finally apply cache s to create tile tensors. In order to demonstrate the idea, we show a simplier example here: still a vector addtion, but with the loop split and only the outer one parallelize d. Please note that this is an example only for demonstration. Usually you do not need it because OpenMP has its own \"schedule(static)\" for parallelized loops. import freetensor as ft import numpy as np n = 1024 def sch(s): outer, inner = s.split('Li', 32) s.parallelize(outer, 'openmp') # Set verbose=1 to see the resulting native code # Set verbose=2 to see the code after EVERY schedule @ft.optimize(schedule_callback=sch) def test(a: ft.Var[(n,), \"int32\"], b: ft.Var[(n,), \"int32\"]): y = ft.empty((n,), \"int32\") #! label: Li for i in range(n): y[i] = a[i] + b[i] return y y = test(np.array(np.arange(1024), dtype=\"int32\"), np.array(np.arange(1024), dtype=\"int32\")).numpy() print(y) One important thing is to track labels of the loops, because the labels will change after schedules. You get labels (to be precise, IDs, which is can be looked-up by labels) of new loops generated from one schedule from its return values ( outer and inner in this case), and pass them to a next schedule.","title":"Combining Multiple Schdules"},{"location":"guide/schedules/#specify-what-to-schedule-by-selectors","text":"In the example above, we label a loop Li and apply schedules on it. It is straight-forward in a tiny example, but as programs grow, it often gets hard to track each statement by a unique label, especially there are inlined function calls. To make things easy, FreeTensor supports specifying a statement by a selector, written in the following rules: A label is a selector. E.g., Li matches a statement with a label Li . (For debugging only) A numerical ID is also a selector. E.g., #31 . A node type surrounded in angle brackets ( <> ) is also a selector. E.g., <For> matches for-loop statements. A selector can be extended to match a new statement produced by a previous schedule. E.g., $split.0{Li} matches the outer loop split from the loop Li . This is useful when return values from schedules are hard to track. Please refer the API document for detailed grammar. Selectors can be combined to match a statement by nesting order. A<-B matches a statement A DIRECTLY NESTED IN another statement B . A<<-B matches a statement DIRECTLY or INDIRECTLY nested in another statement B . A<-(B<-)*C matches a statement A DIRECTLY or INDIRECTLY nested in another statement C with intermedaite nesting statements satisfying the condition in B . B->A matches a statement B directly OUT OF another statement A . B->>A and C->(B->)*A are alike. ( A , B , C can be nested selectors.) Use <-| for the root node, and ->| for a leaf node. Selectors can be combined to match a statement by DFS order. A<:B matches a statement A DIRECTLY BEFORE another statement B . A<<:B matches a statement A DIRECTLY or INDIRECTLY before another statement B . B:>A matches a statment B directly AFTER another statement A . B:>>A matches a statement B directly or indirectly after another statement A . Selectors can be combined to match a statement in a function call. A<~B matches a statement A DIRECTLY called by a call site B . A<<~B matches a statement DIRECTLY or INDIRECTLY called by a call site B . A<~(B<~)*C matches a statement A DIRECTLY or INDIRECTLY called by a call site C with intermediate call sites satisfying the condition in B . ( A , B , C can be nested selectors.) Use <~| for the root function. All the arrow-like selectors ( <- , <~ , <: , etc.) are right-associated. For example, A<-B<-C matches A nested in B , where B is nested in C . All the arrow-like selectors can be used with the first argument omitted. For example, <-B matches ALL statements nested in B . Selectors can be combined with logical \"and\" ( & ), \"or\" ( | ), \"not\" ( ! ) and parentheses. E.g., Li|Lj matches a statement labeled Li OR Lj . Li&Lj matches a statement labeled Li&Lj . All schedules support passing selectors.","title":"Specify What to Schedule by Selectors"},{"location":"guide/schedules/#auto-scheduling-experimental","text":"Manually scheduling a program requires a lot of efforts. We provide an experimental automatic scheduling functions in Schedule . You can call s.auto_schedule to pick schedules fully automatically. s.auto_schedule calls other s.auto_xxxxxx functions internally, you can also call one or some of them instead. Please note that these auto-scheduling functions are experimental, and their API is subject to changes.","title":"Auto Scheduling (Experimental)"}]}